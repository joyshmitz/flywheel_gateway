{"id":"flywheel_gateway-0wr","title":"Mobile Optimization","description":"## Background\n\nMobile users represent a significant and growing portion of web traffic. The Flywheel Gateway dashboard must provide a first-class mobile experience to enable administrators and developers to monitor and manage their AI agent infrastructure from any device. This includes responsive layouts, touch-optimized interactions, and mobile-specific navigation patterns.\n\n## Reasoning\n\nModern dashboards often neglect mobile experiences, forcing users to pinch-zoom and struggle with tiny touch targets. By implementing mobile optimization from the ground up, we ensure:\n\n1. **Accessibility**: Users can manage their agents on-the-go\n2. **Emergency Response**: Critical alerts can be addressed from mobile devices\n3. **Professional Quality**: Demonstrates attention to detail and user experience\n4. **Quality Bar**: Many dashboards have poor mobile support; we aim for a first-class experience\n\n## Technical Considerations\n\n### Responsive Breakpoints\n```typescript\n// apps/web/src/styles/breakpoints.ts\nexport const BREAKPOINTS = {\n  xs: 320,   // Small phones\n  sm: 480,   // Large phones\n  md: 768,   // Tablets portrait\n  lg: 1024,  // Tablets landscape / small laptops\n  xl: 1280,  // Desktops\n  xxl: 1536  // Large screens\n} as const;\n\nexport const mediaQueries = {\n  mobile: `(max-width: ${BREAKPOINTS.md - 1}px)`,\n  tablet: `(min-width: ${BREAKPOINTS.md}px) and (max-width: ${BREAKPOINTS.lg - 1}px)`,\n  desktop: `(min-width: ${BREAKPOINTS.lg}px)`\n};\n```\n\n### Touch Target Guidelines\n- Minimum touch target: 44x44px (Apple HIG recommendation)\n- Adequate spacing between interactive elements (8px minimum)\n- Visual feedback on touch (active states, ripple effects)\n\n### Mobile Navigation Architecture\n```typescript\n// Bottom tab bar navigation for mobile\ninterface MobileNavItem {\n  icon: React.ComponentType;\n  label: string;\n  path: string;\n  badge?: number; // For notifications\n}\n\nconst mobileNavItems: MobileNavItem[] = [\n  { icon: HomeIcon, label: 'Dashboard', path: '/' },\n  { icon: AgentsIcon, label: 'Agents', path: '/agents' },\n  { icon: TerminalIcon, label: 'Sessions', path: '/sessions' },\n  { icon: SettingsIcon, label: 'Settings', path: '/settings' }\n];\n```\n\n### Gesture Support Implementation\n```typescript\n// apps/web/src/hooks/useMobileGestures.ts\ninterface GestureConfig {\n  onSwipeLeft?: () =\u003e void;\n  onSwipeRight?: () =\u003e void;\n  onSwipeUp?: () =\u003e void;\n  onSwipeDown?: () =\u003e void;\n  onPullToRefresh?: () =\u003e Promise\u003cvoid\u003e;\n  swipeThreshold?: number; // Default: 50px\n  pullThreshold?: number;  // Default: 80px\n}\n\nexport function useMobileGestures(config: GestureConfig): {\n  handlers: {\n    onTouchStart: TouchEventHandler;\n    onTouchMove: TouchEventHandler;\n    onTouchEnd: TouchEventHandler;\n  };\n  isRefreshing: boolean;\n}\n```\n\n### Mobile-Optimized Agent Cards\n- Collapsible details to save vertical space\n- Swipe actions (archive, restart, view details)\n- Compact status indicators\n- Touch-friendly action buttons\n\n### Safe Area Handling\n```css\n/* Handle notch and home indicator on modern phones */\n.mobile-container {\n  padding-top: env(safe-area-inset-top);\n  padding-bottom: env(safe-area-inset-bottom);\n  padding-left: env(safe-area-inset-left);\n  padding-right: env(safe-area-inset-right);\n}\n\n.bottom-nav {\n  padding-bottom: max(16px, env(safe-area-inset-bottom));\n}\n```\n\n## File Locations\n\n### Components\n- `apps/web/src/components/mobile/MobileLayout.tsx` - Main mobile layout wrapper\n- `apps/web/src/components/mobile/BottomTabBar.tsx` - Bottom navigation\n- `apps/web/src/components/mobile/MobileAgentCard.tsx` - Touch-optimized agent cards\n- `apps/web/src/components/mobile/PullToRefresh.tsx` - Pull-to-refresh component\n- `apps/web/src/components/mobile/SwipeableListItem.tsx` - Swipeable list items\n- `apps/web/src/components/mobile/MobileHeader.tsx` - Mobile-specific header\n- `apps/web/src/components/mobile/MobileDrawer.tsx` - Slide-out drawer menu\n\n### Hooks\n- `apps/web/src/hooks/useMobileGestures.ts` - Gesture detection hook\n- `apps/web/src/hooks/useMediaQuery.ts` - Responsive breakpoint detection\n- `apps/web/src/hooks/useSwipeActions.ts` - Swipe action management\n- `apps/web/src/hooks/useSafeArea.ts` - Safe area inset detection\n\n### Styles\n- `apps/web/src/styles/breakpoints.ts` - Breakpoint constants\n- `apps/web/src/styles/mobile.css` - Mobile-specific styles\n\n## Acceptance Criteria\n\n### Responsive Design\n- [ ] All pages render correctly at 320px width (minimum supported)\n- [ ] Smooth transitions between breakpoints\n- [ ] No horizontal scrolling on mobile devices\n- [ ] Text remains readable without zooming\n\n### Touch Targets\n- [ ] All interactive elements are at least 44x44px\n- [ ] Adequate spacing prevents accidental taps\n- [ ] Visual feedback on all touch interactions\n- [ ] No hover-only interactions\n\n### Navigation\n- [ ] Bottom tab bar visible on mobile viewports\n- [ ] Current route clearly indicated\n- [ ] Badge counts display for notifications\n- [ ] Smooth page transitions\n\n### Gestures\n- [ ] Swipe left/right on agent cards for quick actions\n- [ ] Pull-to-refresh works on list views\n- [ ] Gestures don't interfere with scrolling\n- [ ] Gesture hints for discoverability\n\n### Agent Cards\n- [ ] Compact view shows essential information\n- [ ] Tap to expand for full details\n- [ ] Swipe actions work smoothly\n- [ ] Status changes animate appropriately\n\n### Safe Areas\n- [ ] Content not obscured by notch\n- [ ] Bottom nav above home indicator\n- [ ] Landscape orientation handled correctly\n- [ ] Works on iOS and Android browsers\n\n### Performance\n- [ ] 60fps animations and transitions\n- [ ] Touch response under 100ms\n- [ ] No jank during gestures\n- [ ] Efficient re-renders during interaction\n\n## Testing Requirements\n\n- Test on real devices (iOS Safari, Chrome Android)\n- Test with browser dev tools device emulation\n- Verify touch targets with accessibility tools\n- Test gesture interactions with touch simulation\n- Visual regression tests for each breakpoint\n\n## Reference\n\nPLAN.md §23 - Mobile Optimization\n","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:57:51.71254107-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:59:39.906612435-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-0wr","depends_on_id":"flywheel_gateway-r3p","type":"blocks","created_at":"2026-01-08T14:01:54.756840251-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-1hv","title":"FEAT: CM Memory Integration","description":"## Background\n\nClaude Memory (CM) provides persistent memory and learning capabilities for AI assistants within the Flywheel ecosystem. This integration enables Flywheel Gateway to leverage CM for context-aware assistance, outcome recording, and adaptive behavior based on past interactions.\n\n## Reasoning\n\nWithout persistent memory, AI assistants:\n- Repeat mistakes they've made before\n- Cannot learn user preferences over time\n- Lack context about project conventions\n- Cannot apply lessons from past sessions\n\nCM solves this by maintaining structured memory (rules, preferences, outcomes) that can be queried to enhance AI responses and recorded to improve future interactions.\n\n## Technical Considerations\n\n### Client Architecture\n- Follow flywheel-clients pattern\n- Support both read and write operations\n- Handle privacy settings appropriately\n- Implement local caching with sync\n\n### API Design\n```typescript\ninterface CMClient {\n  // Context Rules\n  getContextRules(context: TaskContext): Promise\u003cContextRule[]\u003e;\n  getApplicableRules(query: RuleQuery): Promise\u003cContextRule[]\u003e;\n  \n  // Memory Rules (CRUD)\n  listMemoryRules(filters?: RuleFilters): Promise\u003cMemoryRule[]\u003e;\n  getMemoryRule(id: string): Promise\u003cMemoryRule\u003e;\n  createMemoryRule(rule: MemoryRuleCreate): Promise\u003cMemoryRule\u003e;\n  updateMemoryRule(id: string, updates: MemoryRuleUpdate): Promise\u003cMemoryRule\u003e;\n  deleteMemoryRule(id: string): Promise\u003cvoid\u003e;\n  \n  // Outcome Recording\n  recordOutcome(outcome: OutcomeRecord): Promise\u003cvoid\u003e;\n  getOutcomeHistory(filters?: OutcomeFilters): Promise\u003cOutcomeRecord[]\u003e;\n  getOutcomeStats(): Promise\u003cOutcomeStats\u003e;\n  \n  // Privacy Management\n  getPrivacySettings(): Promise\u003cPrivacySettings\u003e;\n  updatePrivacySettings(settings: PrivacySettingsUpdate): Promise\u003cPrivacySettings\u003e;\n  exportData(): Promise\u003cDataExport\u003e;\n  deleteAllData(): Promise\u003cvoid\u003e;\n}\n\ninterface TaskContext {\n  projectId?: string;\n  fileTypes?: string[];\n  currentFile?: string;\n  taskType?: 'coding' | 'debugging' | 'review' | 'documentation' | 'other';\n  technologies?: string[];\n}\n\ninterface ContextRule {\n  id: string;\n  content: string;\n  confidence: number;\n  source: 'explicit' | 'learned' | 'inferred';\n  applicableContexts: string[];\n  lastApplied?: Date;\n}\n\ninterface OutcomeRecord {\n  sessionId: string;\n  taskType: string;\n  success: boolean;\n  rulesApplied: string[];\n  feedback?: string;\n  duration?: number;\n  metadata?: Record\u003cstring, unknown\u003e;\n}\n```\n\n### Memory Rule Types\n1. **Explicit Rules** - User-defined preferences (\"Always use TypeScript strict mode\")\n2. **Learned Rules** - Derived from outcome patterns (\"In this project, prefer functional components\")\n3. **Inferred Rules** - Extracted from successful sessions (\"User prefers verbose error messages\")\n\n### Privacy Considerations\n- All memory operations must respect privacy settings\n- Support data export for GDPR compliance\n- Clear deletion with confirmation\n- Option to exclude sensitive projects from memory\n- Audit log of memory access (configurable)\n\n### Learning Pipeline\n```\nSession → Outcome Recording → Pattern Detection → Rule Proposal → User Approval → Active Rule\n```\n\n## Acceptance Criteria\n\n1. **CM Client Implementation**\n   - [ ] CMClient class with full TypeScript typing\n   - [ ] All CRUD operations for memory rules\n   - [ ] Context rule querying functional\n   - [ ] Error handling with typed exceptions\n   - [ ] Unit tests with \u003e80% coverage\n\n2. **Context Rules**\n   - [ ] getContextRules returns rules matching task context\n   - [ ] Rules include confidence scores\n   - [ ] Rules sorted by relevance and confidence\n   - [ ] Caching with configurable TTL\n\n3. **Memory Rules Management**\n   - [ ] List rules with filtering (type, source, status)\n   - [ ] Create custom rules with validation\n   - [ ] Update rules (content, applicability)\n   - [ ] Soft delete with restore option\n   - [ ] Rule versioning for audit trail\n\n4. **Outcome Recording**\n   - [ ] Record session outcomes with metadata\n   - [ ] Link outcomes to applied rules\n   - [ ] Aggregate statistics available\n   - [ ] Batch recording for performance\n\n5. **Privacy Settings**\n   - [ ] View current privacy configuration\n   - [ ] Toggle memory collection on/off\n   - [ ] Exclude specific projects\n   - [ ] Data export in standard format (JSON)\n   - [ ] Complete data deletion with confirmation\n\n6. **Memory Service Integration**\n   - [ ] Service layer in gateway for CM operations\n   - [ ] Caching layer for frequent queries\n   - [ ] Background sync for offline support\n   - [ ] Health checks for CM connectivity\n\n## File Locations\n\n### Client Package\n- `packages/flywheel-clients/src/cm/index.ts` - Main exports\n- `packages/flywheel-clients/src/cm/client.ts` - CMClient implementation\n- `packages/flywheel-clients/src/cm/types.ts` - TypeScript interfaces\n- `packages/flywheel-clients/src/cm/cache.ts` - Local caching layer\n- `packages/flywheel-clients/src/cm/__tests__/` - Unit tests\n\n### Gateway Service\n- `apps/gateway/src/services/memory.service.ts` - Main memory service\n- `apps/gateway/src/services/memory/context-resolver.ts` - Context rule resolution\n- `apps/gateway/src/services/memory/outcome-recorder.ts` - Outcome recording\n- `apps/gateway/src/services/memory/privacy-manager.ts` - Privacy operations\n- `apps/gateway/src/services/memory/__tests__/` - Service tests\n\n### Web Components (if applicable)\n- `apps/web/src/components/settings/MemorySettings.tsx` - Privacy settings UI\n- `apps/web/src/components/settings/MemoryRulesManager.tsx` - Rule management UI\n- `apps/web/src/hooks/useCMClient.ts` - React hook for CM operations\n\n## References\n\n- PLAN.md §14: CM Memory Integration specifications\n- Claude Memory API documentation (internal)\n- GDPR compliance requirements for data handling\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b` (shared test harness + structured test logging).\n\n### Unit Tests\n- [ ] CM client: request/response schema validation, retries/backoff, and timeout handling\n- [ ] CM adapter: caching TTL + cache invalidation rules\n- [ ] Context rule selection/ranking is deterministic for the same inputs\n\n### Integration Tests\n- [ ] CM unavailable → graceful degradation with actionable error code + hint (no hangs)\n- [ ] CM available (mock server) → context retrieval returns normalized shape and preserves rule IDs\n\n### Failure Mode Tests\n- [ ] Non-JSON response / schema mismatch / timeout → mapped error taxonomy and safe logs\n\n### Logging\n- [ ] Logs include correlationId + operation name + latencyMs; secrets/tokens are redacted\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] CMClient.context: sends task description\n- [ ] CMClient.context: parses response structure\n- [ ] CMClient.playbook.list: returns all rules\n- [ ] CMClient.playbook.add: creates new rule\n- [ ] CMClient.onboard.status: returns progress\n- [ ] CMClient.onboard.sample: returns sessions\n- [ ] Context response: relevantBullets extracted\n- [ ] Context response: antiPatterns extracted\n- [ ] Context response: historySnippets extracted\n- [ ] Context response: suggestedCassQueries parsed\n- [ ] Rule categories: validated against enum\n- [ ] Rule references: IDs formatted correctly\n\n### Integration Tests\n- [ ] Context query returns relevant rules\n- [ ] Playbook add persists rule\n- [ ] Onboard status reflects actual progress\n- [ ] Sample returns unprocessed sessions\n- [ ] Mark done updates session status\n- [ ] Empty playbook returns empty arrays\n- [ ] Multiple categories returned\n\n### E2E Tests\n- [ ] Agent queries context before task\n- [ ] Retrieved rules improve agent behavior (qualitative)\n- [ ] Feedback from agent updates playbook\n- [ ] Full onboarding workflow\n\n### Performance Tests\n- [ ] Context query \u003c300ms\n- [ ] Playbook list \u003c100ms\n- [ ] Onboard sample \u003c500ms\n- [ ] Concurrent context queries scale\n\n### Failure Mode Tests\n- [ ] CM unavailable: continue without context\n- [ ] Empty task description: reasonable response\n- [ ] Large playbook: paginated response\n- [ ] Invalid rule category: validation error","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:46:00.682332809-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:03:38.386581071-05:00","dependencies":[{"issue_id":"flywheel_gateway-1hv","depends_on_id":"flywheel_gateway-45c","type":"blocks","created_at":"2026-01-08T14:01:48.390042304-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-2ao","title":"EPIC: Phase 1 - Foundation","description":"## Overview\nPhase 1 establishes the foundation for Flywheel Gateway with basic agent spawning, durable output streaming, and API parity infrastructure.\n\n## Phase 1 Goal\nBasic agent spawning and durable output streaming with API parity\n\n## Key Deliverables\n\n### Infrastructure\n- Monorepo scaffolding with Bun workspaces\n- Shared packages (types, schemas, utils)\n- Biome configuration for linting/formatting\n- TypeScript strict mode configuration\n\n### Command Registry \u0026 API Parity\n- Command Registry pattern implementation\n- Codegen for REST/tRPC/OpenAPI/WebSocket\n- Parity gate tests enforcing all commands have REST, AI hints, examples\n- OpenAPI 3.1 spec generation with x-ai-hints extensions\n\n### Core Services\n- Shared error taxonomy with AI hints (GatewayError)\n- Database schema with Drizzle ORM (SQLite)\n- Structured logging with correlation IDs\n- Audit event pipeline (initial)\n\n### Agent Execution\n- SDK Agent Driver (Claude, Codex, Gemini)\n- Agent lifecycle state machine (pending → spawning → ready → executing → terminated)\n- Status endpoints with WebSocket events\n\n### Real-Time Communication\n- WebSocket infrastructure with durable ring buffers\n- Per-channel configuration (output, state, conflicts, mail)\n- Cursor-based replay for reconnection\n- Heartbeat protocol\n\n### REST API\n- Basic REST API generated from registry\n  - POST /agents (spawn)\n  - GET /agents (list with filters)\n  - GET /agents/:id (details)\n  - DELETE /agents/:id (terminate)\n  - POST /agents/:id/send\n  - POST /agents/:id/interrupt\n  - GET /agents/:id/output\n  - GET /health, GET /health/ready\n- Correlation ID middleware\n- Error response formatting\n- Rate limiting\n\n### Web UI\n- Basic web UI shell with mock-data mode\n- React 19.2 + Vite 7.3 + Tailwind 4.1\n- TanStack Router + Query\n- Design system foundation (colors, typography, spacing)\n\n### Safety\n- DCG integration (Destructive Command Guard)\n  - Pre-execution hook setup\n  - Block event capture\n  - Basic dashboard\n- Developer utilities auto-install (giil, csctf)\n\n## Phase Completion Criteria\n- [ ] Spawn a Claude agent via REST API\n- [ ] Send prompts and receive streaming output via WebSocket\n- [ ] Output persists across WebSocket reconnection (cursor-based replay)\n- [ ] All APIs pass parity gate tests (REST binding, AI hints, examples)\n- [ ] Web UI shell displays mock agent data\n- [ ] DCG blocks destructive commands with event capture\n- [ ] Developer utilities detected and auto-install offered\n\n## Testing Requirements\n- Unit test coverage \u003e80% for all services\n- Integration tests for all REST endpoints\n- WebSocket integration tests for subscription/replay\n- Parity gate runs in CI and fails on violations\n- Structured test logging + artifact capture per `flywheel_gateway-d8b`\n\n\n## Success Criteria\n\n- [ ] End-to-end demo: spawn agent via REST, stream output via WebSocket, resume via cursor after reconnect\n- [ ] Parity gate passing for all Phase 1 commands (registry ↔ REST ↔ OpenAPI ↔ WS events)\n- [ ] Core safety plumbing: DCG block events ingested + visible in UI (basic dashboard)\n- [ ] Baseline observability: correlation IDs + structured logs wired through key request paths\n- [ ] Test coverage + reliability: critical paths covered by unit + integration + WS replay tests per `flywheel_gateway-d8b`\n\n","notes":"## Constituent Beads\n\nThis EPIC encompasses the following beads:\n\n### Infrastructure\n- flywheel_gateway-hnv: Project Scaffolding and Monorepo Setup [P0]\n- flywheel_gateway-d8b: Testing Infrastructure and Standards [P1]\n\n### Command Registry \u0026 API Parity\n- flywheel_gateway-2kf: Command Registry + Codegen System [P1]\n- flywheel_gateway-lil: Parity Gate Tests [P1]\n\n### Core Services\n- flywheel_gateway-ls4: Shared Error Taxonomy + AI Hints [P1]\n- flywheel_gateway-6mn: Database Schema and Drizzle Setup [P1]\n- flywheel_gateway-d18: Structured Logging + Correlation IDs + Audit Pipeline [P1]\n\n### Agent Execution\n- flywheel_gateway-w55: SDK Agent Driver Implementation [P1]\n- flywheel_gateway-398: Agent Lifecycle State Model + Status Endpoints [P1]\n\n### Real-Time Communication\n- flywheel_gateway-46c: WebSocket Infrastructure with Durable Ring Buffers [P1]\n- flywheel_gateway-6ix: Output Streaming System [P1]\n\n### REST API\n- flywheel_gateway-w4g: Basic REST API (Spawn, Terminate, List, Send) [P1]\n\n### Web UI\n- flywheel_gateway-r3p: Basic Web UI Shell with Mock-Data Mode [P2]\n\n### Safety\n- flywheel_gateway-5nq: DCG Integration (Destructive Command Guard) [P1]\n- flywheel_gateway-dje: Developer Utilities Auto-Install (giil, csctf) [P1]\n\n---\n**Total: 15 beads** (12 P1, 2 P2, 1 P0)\n\n## Testing Requirements\nEvery constituent bead must include testing requirements that reference flywheel_gateway-d8b standards:\n- Unit test coverage \u003e80%\n- Integration tests for API endpoints\n- E2E tests for critical user journeys\n- Failure mode tests for error handling\n- Detailed structured logging in all tests for debugging","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-08T13:29:04.717263502-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:32:06.335778806-05:00","dependencies":[{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-hnv","type":"blocks","created_at":"2026-01-08T18:15:19.178588153-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-d8b","type":"blocks","created_at":"2026-01-08T18:15:24.233405408-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T18:15:29.266691866-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-2kf","type":"blocks","created_at":"2026-01-08T18:15:34.300360515-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-lil","type":"blocks","created_at":"2026-01-08T18:15:39.335639485-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T18:15:44.368151005-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-d18","type":"blocks","created_at":"2026-01-08T18:15:49.403740109-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-w55","type":"blocks","created_at":"2026-01-08T18:15:54.436065899-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-46c","type":"blocks","created_at":"2026-01-08T18:15:59.467224151-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-398","type":"blocks","created_at":"2026-01-08T18:16:04.499133938-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-6ix","type":"blocks","created_at":"2026-01-08T18:16:09.531900689-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T18:16:14.563659692-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-r3p","type":"blocks","created_at":"2026-01-08T18:16:19.598540482-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-5nq","type":"blocks","created_at":"2026-01-08T18:16:24.632862812-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2ao","depends_on_id":"flywheel_gateway-dje","type":"blocks","created_at":"2026-01-08T18:16:29.665420478-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-2kf","title":"FEAT: Command Registry + Codegen System","description":"## Overview\n\nThe Command Registry is the **single source of truth** for all API surfaces in flywheel_gateway. Every command definition drives code generation for REST routes, tRPC procedures, OpenAPI specifications, WebSocket event schemas, and TypeScript client SDKs. This pattern ensures API parity across all surfaces and eliminates the possibility of drift between implementations.\n\n## Background \u0026 Reasoning\n\n### Why Command Registry?\n\nTraditional API development often leads to drift between different API surfaces:\n- REST endpoints may accept different parameters than tRPC procedures\n- WebSocket events may have different payload shapes than HTTP responses\n- Client SDKs may fall out of sync with server implementations\n- OpenAPI specs may not reflect actual behavior\n\nThe Command Registry pattern solves this by:\n1. **Single Definition**: Each command is defined once with full type information\n2. **Generated Surfaces**: All API surfaces are generated from command definitions\n3. **Compile-Time Safety**: Type mismatches are caught at build time, not runtime\n4. **Automatic Parity**: Changes to a command automatically propagate to all surfaces\n\n## Technical Architecture\n\n### Command Definition Schema (Zod-based)\n\nEach command is defined using a Zod schema that captures:\n- **name**: Unique command identifier (e.g., `agent.spawn`, `checkpoint.create`)\n- **input**: Zod schema for input validation\n- **output**: Zod schema for output validation\n- **metadata**: Permissions, rate limits, audit requirements\n- **aiHints**: Structured hints for AI-assisted usage\n\n```typescript\nconst spawnAgentCommand = defineCommand({\n  name: 'agent.spawn',\n  input: z.object({\n    repoUrl: z.string().url(),\n    task: z.string(),\n    model: z.enum(['opus-4', 'sonnet-4']).default('sonnet-4'),\n  }),\n  output: z.object({\n    agentId: z.string().uuid(),\n    status: z.enum(['spawning', 'running', 'idle']),\n  }),\n  metadata: {\n    permissions: ['agent:write'],\n    rateLimit: { requests: 10, window: '1m' },\n    audit: true,\n  },\n  aiHints: {\n    whenToUse: 'Use when starting a new agent to work on a task',\n    examples: ['Spawn an agent to fix the login bug', 'Create an agent for the new feature'],\n    relatedCommands: ['agent.stop', 'agent.status'],\n  },\n});\n```\n\n### Registration Mechanism\n\nCommands are registered in a central registry that:\n1. Validates command definitions at startup\n2. Detects naming conflicts\n3. Builds lookup indexes for runtime dispatch\n4. Triggers codegen when definitions change\n\n```typescript\n// packages/shared/src/commands/registry.ts\nexport const commandRegistry = createCommandRegistry([\n  agentCommands,\n  checkpointCommands,\n  accountCommands,\n  // ... other command groups\n]);\n```\n\n### Codegen Targets\n\nThe codegen system produces the following outputs:\n\n| Target | Output Location | Description |\n|--------|-----------------|-------------|\n| REST Routes | `apps/gateway/src/routes/generated/` | Hono route handlers with validation |\n| tRPC Procedures | `apps/gateway/src/trpc/generated/` | Type-safe tRPC router |\n| OpenAPI Spec | `apps/gateway/openapi.json` | Full OpenAPI 3.1 specification |\n| WebSocket Schemas | `apps/gateway/src/ws/generated/` | Event type definitions |\n| TypeScript Client | `packages/client/src/generated/` | Fully typed SDK |\n\n### AI Hints Structure\n\nThe `aiHints` field provides structured guidance for AI-assisted usage:\n\n```typescript\ninterface AIHints {\n  /** When this command should be used */\n  whenToUse: string;\n  /** Example natural language requests that map to this command */\n  examples: string[];\n  /** Related commands the AI should consider */\n  relatedCommands: string[];\n  /** Common mistakes to avoid */\n  pitfalls?: string[];\n  /** Prerequisites that must be met */\n  prerequisites?: string[];\n}\n```\n\n## File Locations\n\n```\npackages/shared/src/commands/\n├── registry.ts          # Central command registry\n├── define.ts            # defineCommand helper\n├── types.ts             # Command type definitions\n├── codegen/\n│   ├── rest.ts          # REST route generator\n│   ├── trpc.ts          # tRPC procedure generator\n│   ├── openapi.ts       # OpenAPI spec generator\n│   ├── websocket.ts     # WebSocket schema generator\n│   └── client.ts        # TypeScript client generator\n└── commands/\n    ├── agent.ts         # Agent-related commands\n    ├── checkpoint.ts    # Checkpoint commands\n    ├── account.ts       # Account commands\n    └── index.ts         # Command group exports\n```\n\n## Testing Requirements\n\n### Unit Tests\n\n- [ ] Command schema validation tests\n  - Valid command definitions are accepted\n  - Invalid definitions throw descriptive errors\n  - Zod schema compilation works correctly\n- [ ] Each codegen target has dedicated tests\n  - REST generator produces valid Hono routes\n  - tRPC generator produces valid procedures\n  - OpenAPI generator produces valid spec\n  - WebSocket generator produces valid schemas\n  - Client generator produces compilable TypeScript\n\n### Integration Tests\n\n- [ ] Parity tests verify all surfaces accept identical inputs\n- [ ] Parity tests verify all surfaces return identical outputs\n- [ ] Round-trip tests: client -\u003e server -\u003e client type safety\n- [ ] Cross-surface tests: REST and tRPC produce identical results\n\n### Parity Gate Tests\n\nReference: flywheel_gateway-3tp (Parity Gate) implements automated parity verification that runs in CI. The Command Registry codegen must produce outputs that pass these gates.\n\n## Logging Requirements\n\n### Structured Logging for Codegen\n\n```typescript\nlogger.info('codegen:start', {\n  target: 'rest',\n  commandCount: 42,\n  outputPath: 'apps/gateway/src/routes/generated/',\n});\n\nlogger.info('codegen:complete', {\n  target: 'rest',\n  filesGenerated: 12,\n  durationMs: 156,\n});\n```\n\n### Error Reporting\n\n```typescript\nlogger.error('codegen:invalid-command', {\n  commandName: 'agent.spawn',\n  error: 'Input schema references undefined type',\n  location: 'packages/shared/src/commands/agent.ts:42',\n});\n```\n\n## Acceptance Criteria\n\n- [ ] Command Registry accepts valid command definitions\n- [ ] Registry rejects invalid definitions with helpful errors\n- [ ] REST codegen produces working Hono routes\n- [ ] tRPC codegen produces working procedures\n- [ ] OpenAPI codegen produces valid 3.1 spec\n- [ ] WebSocket codegen produces type definitions\n- [ ] Client codegen produces compilable TypeScript SDK\n- [ ] All generated surfaces pass parity tests\n- [ ] AI hints are included in generated documentation\n- [ ] Codegen runs complete in \u003c5 seconds\n- [ ] Changes to commands trigger regeneration in watch mode\n\n## References\n\n- PLAN.md §4.4 - Command Registry Architecture\n- flywheel_gateway-3tp - Parity Gate (consumes codegen outputs)\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] defineCommand: returns valid CommandDefinition\n- [ ] defineCommand: validates required fields\n- [ ] CommandRegistry: registers command by name\n- [ ] CommandRegistry: retrieves command by name\n- [ ] CommandRegistry: lists all commands by category\n- [ ] REST binding: method and path are required\n- [ ] REST binding: pathParams parsed from path template\n- [ ] WebSocket binding: emitsEvents is array\n- [ ] AI hints: whenToUse is non-empty string\n- [ ] AI hints: commonMistakes is array\n- [ ] Zod schema: inputSchema validates correctly\n- [ ] Zod schema: outputSchema validates correctly\n- [ ] Codegen: generates Hono routes from registry\n- [ ] Codegen: generates tRPC procedures from registry\n- [ ] Codegen: generates OpenAPI spec from registry\n- [ ] Codegen: generates TypeScript client from registry\n\n### Integration Tests\n- [ ] Generated routes match REST binding paths\n- [ ] Generated routes apply Zod validation\n- [ ] Generated OpenAPI includes all commands\n- [ ] Generated OpenAPI includes AI hints as x-ai-hints\n- [ ] Generated OpenAPI examples are valid\n- [ ] Generated client calls correct endpoints\n- [ ] Command handler receives validated input\n- [ ] Command handler output matches schema\n\n### Parity Gate Tests\n- [ ] Every command has REST binding\n- [ ] Every command has AI hints\n- [ ] DELETE commands not marked as 'safe'\n- [ ] Long-running commands return jobId\n- [ ] All commands have examples\n- [ ] OpenAPI spec validates against JSON Schema\n- [ ] No duplicate command names\n- [ ] No conflicting REST paths\n\n### E2E Tests\n- [ ] API call through generated client succeeds\n- [ ] Error from generated client matches schema\n- [ ] Streaming endpoint works through client\n\n### Build Tests\n- [ ] Codegen runs without errors\n- [ ] Generated files compile without errors\n- [ ] Parity check passes in CI","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:29:26.480233251-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:39:23.526415888-05:00","dependencies":[{"issue_id":"flywheel_gateway-2kf","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T14:01:41.014046581-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-2pl","title":"FEAT: First-Class Session Handoff Protocol","description":"## Overview\n\nStructured protocol for agent-to-agent work transfer that ensures seamless context preservation, resource handover, and coordination when one agent passes work to another.\n\n## Background \u0026 Reasoning\n\nAgent handoffs are inevitable in multi-agent systems:\n- **Session limits**: Claude sessions have context window limits requiring fresh agents\n- **Specialization**: Different agents may excel at different task types\n- **Availability**: Agents may become unavailable (crashes, timeouts, user interruption)\n- **Load balancing**: Work may need redistribution across available agents\n\nWithout a first-class handoff protocol, these transitions suffer from:\n\n1. **Context loss**: Receiving agent lacks knowledge of decisions made, approaches tried, dead ends encountered\n2. **Resource conflicts**: File reservations, checkpoints, and locks don't transfer cleanly\n3. **Coordination gaps**: No clear acknowledgment that handoff succeeded\n4. **Audit trail breaks**: Ownership history becomes unclear\n\nThe Session Handoff Protocol treats handoffs as a formal state machine with explicit phases, ensuring nothing is lost in transition.\n\n## Technical Architecture\n\n### Handoff Phases\n\n```\n┌──────────────────────────────────────────────────────────────────────┐\n│                      Handoff State Machine                            │\n├──────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  ┌─────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐        │\n│  │ INITIATE│───▶│  PENDING │───▶│ TRANSFER │───▶│ COMPLETE │        │\n│  └─────────┘    └──────────┘    └──────────┘    └──────────┘        │\n│       │              │               │               │               │\n│       │              ▼               ▼               │               │\n│       │         ┌─────────┐    ┌─────────┐          │               │\n│       │         │ REJECTED│    │ FAILED  │          │               │\n│       │         └─────────┘    └─────────┘          │               │\n│       │              │               │               │               │\n│       ▼              ▼               ▼               ▼               │\n│  ┌─────────────────────────────────────────────────────────┐        │\n│  │                    CANCELLED                             │        │\n│  └─────────────────────────────────────────────────────────┘        │\n│                                                                       │\n└──────────────────────────────────────────────────────────────────────┘\n```\n\n| Phase | Description | Initiator Action | Receiver Action |\n|-------|-------------|------------------|-----------------|\n| `INITIATE` | Source agent requests handoff | Creates HandoffRequest | - |\n| `PENDING` | Awaiting receiver acceptance | Waits (with timeout) | Reviews, accepts/rejects |\n| `TRANSFER` | Active context/resource transfer | Streams context | Receives and validates |\n| `COMPLETE` | Handoff successful | Releases resources | Assumes ownership |\n| `REJECTED` | Receiver declined | Seeks alternate receiver | Provides rejection reason |\n| `FAILED` | Transfer failed mid-stream | Retains ownership | Discards partial context |\n| `CANCELLED` | Initiator cancelled | Resumes work | Discards any partial data |\n\n### Context Transfer Contents\n\nThe handoff context package includes everything the receiving agent needs:\n\n```typescript\ninterface HandoffContext {\n  // Work state\n  bvId: string;\n  taskDescription: string;\n  currentPhase: string;\n  progressPercentage: number;\n  \n  // Files and changes\n  filesModified: FileModification[];\n  filesCreated: string[];\n  filesDeleted: string[];\n  pendingChanges: UncommittedChange[];\n  \n  // Decision history\n  decisionsMade: Decision[];\n  approachesAttempted: AttemptRecord[];\n  deadEndsEncountered: DeadEnd[];\n  \n  // Conversation context\n  conversationSummary: string;\n  keyUserRequirements: string[];\n  userPreferences: UserPreference[];\n  \n  // Working memory\n  workingHypotheses: Hypothesis[];\n  todoItems: TodoItem[];\n  blockers: Blocker[];\n  \n  // Technical context\n  environmentState: EnvironmentSnapshot;\n  testResults: TestResult[];\n  buildState: BuildState;\n}\n```\n\n### Resource Transfer\n\nResources are transferred atomically to prevent conflicts:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                   Resource Transfer Flow                     │\n├─────────────────────────────────────────────────────────────┤\n│                                                              │\n│  Source Agent                        Target Agent            │\n│  ────────────                        ────────────            │\n│       │                                   │                  │\n│       │  1. Lock resources for transfer   │                  │\n│       │──────────────────────────────────▶│                  │\n│       │                                   │                  │\n│       │  2. Transfer file reservations    │                  │\n│       │──────────────────────────────────▶│                  │\n│       │                                   │                  │\n│       │  3. Transfer checkpoint ownership │                  │\n│       │──────────────────────────────────▶│                  │\n│       │                                   │                  │\n│       │  4. Forward pending Agent Mail    │                  │\n│       │──────────────────────────────────▶│                  │\n│       │                                   │                  │\n│       │  5. Acknowledge receipt           │                  │\n│       │◀──────────────────────────────────│                  │\n│       │                                   │                  │\n│       │  6. Release source locks          │                  │\n│       │──────────────────────────────────▶│                  │\n│       │                                   │                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Transferred resources:**\n- File reservations (exclusive and shared)\n- Checkpoint ownership and history\n- Pending Agent Mail messages\n- Active subscriptions (file watches, event listeners)\n- Queue positions (if waiting for resources)\n\n### Agent Mail Integration\n\nHandoffs integrate with Agent Mail for notifications:\n\n```typescript\n// Handoff initiation notification\nagentMail.send({\n  to: targetAgentId,\n  type: 'handoff_request',\n  priority: 'high',\n  payload: {\n    handoffId: handoff.id,\n    fromAgent: sourceAgentId,\n    bvId: context.bvId,\n    summary: context.conversationSummary,\n    estimatedContextSize: calculateSize(context),\n    expiresAt: handoff.expiresAt\n  }\n});\n\n// Handoff completion notification\nagentMail.send({\n  to: sourceAgentId,\n  type: 'handoff_complete',\n  payload: {\n    handoffId: handoff.id,\n    acceptedBy: targetAgentId,\n    acknowledgment: ack\n  }\n});\n```\n\n## Key Interfaces\n\n### HandoffRequest\n\n```typescript\ninterface HandoffRequest {\n  handoffId: string;\n  sourceAgentId: string;\n  targetAgentId: string | null; // null = broadcast to available agents\n  bvId: string;\n  reason: HandoffReason;\n  urgency: 'low' | 'normal' | 'high' | 'critical';\n  context: HandoffContext;\n  resourceManifest: ResourceManifest;\n  preferences: HandoffPreferences;\n  expiresAt: Date;\n  createdAt: Date;\n}\n\ntype HandoffReason = \n  | 'session_limit'\n  | 'specialization_needed'\n  | 'agent_unavailable'\n  | 'load_balancing'\n  | 'user_requested'\n  | 'error_recovery';\n\ninterface HandoffPreferences {\n  requireAcknowledgment: boolean;\n  allowPartialTransfer: boolean;\n  timeoutMs: number;\n  fallbackBehavior: 'retry' | 'broadcast' | 'escalate' | 'abort';\n  priorityAgents: string[]; // Preferred receivers\n}\n```\n\n### HandoffContext\n\n```typescript\ninterface HandoffContext {\n  // Core work state\n  bvId: string;\n  taskDescription: string;\n  currentPhase: TaskPhase;\n  progressPercentage: number;\n  startedAt: Date;\n  \n  // File changes\n  filesModified: Array\u003c{\n    path: string;\n    originalHash: string;\n    currentHash: string;\n    changeDescription: string;\n  }\u003e;\n  filesCreated: string[];\n  filesDeleted: string[];\n  uncommittedChanges: Array\u003c{\n    path: string;\n    diff: string;\n    reason: string;\n  }\u003e;\n  \n  // Decision trail\n  decisionsMade: Array\u003c{\n    timestamp: Date;\n    decision: string;\n    reasoning: string;\n    alternatives: string[];\n    outcome?: string;\n  }\u003e;\n  \n  // Conversation summary\n  conversationSummary: string;\n  keyPoints: string[];\n  userRequirements: string[];\n  constraints: string[];\n  \n  // Working state\n  workingMemory: Record\u003cstring, unknown\u003e;\n  hypotheses: Array\u003c{\n    hypothesis: string;\n    confidence: number;\n    evidence: string[];\n  }\u003e;\n  todoItems: Array\u003c{\n    task: string;\n    priority: number;\n    status: 'pending' | 'in_progress' | 'blocked';\n    blockedBy?: string;\n  }\u003e;\n  \n  // Environment\n  environmentSnapshot: {\n    workingDirectory: string;\n    gitBranch: string;\n    gitCommit: string;\n    uncommittedFiles: string[];\n    envVars: Record\u003cstring, string\u003e; // sanitized\n  };\n}\n```\n\n### HandoffAcknowledgment\n\n```typescript\ninterface HandoffAcknowledgment {\n  handoffId: string;\n  receivingAgentId: string;\n  status: 'accepted' | 'rejected' | 'partial';\n  \n  // For accepted\n  acceptedAt?: Date;\n  contextReceived?: {\n    filesModified: number;\n    decisionsReceived: number;\n    resourcesTransferred: number;\n  };\n  \n  // For rejected\n  rejectedAt?: Date;\n  rejectionReason?: string;\n  suggestedAlternative?: string;\n  \n  // For partial\n  partialDetails?: {\n    accepted: string[];\n    rejected: string[];\n    reasons: Record\u003cstring, string\u003e;\n  };\n  \n  // Receiver's commitment\n  estimatedResumeTime?: Date;\n  receiverNotes?: string;\n}\n```\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `apps/gateway/src/services/handoff.service.ts` | Core handoff orchestration |\n| `apps/gateway/src/services/handoff-context.service.ts` | Context packaging and validation |\n| `apps/gateway/src/services/handoff-transfer.service.ts` | Resource transfer logic |\n| `apps/gateway/src/interfaces/handoff.interfaces.ts` | Type definitions |\n| `apps/web/src/components/handoffs/HandoffPanel.tsx` | UI for viewing active handoffs |\n| `apps/web/src/components/handoffs/HandoffHistory.tsx` | Historical handoff viewer |\n| `apps/web/src/components/handoffs/HandoffRequest.tsx` | Manual handoff request UI |\n| `libs/shared/src/types/handoff.types.ts` | Shared handoff types |\n\n## Testing Requirements\n\n### Unit Tests\n\n- [ ] **Handoff state machine tests** (`handoff.service.spec.ts`)\n  - Test all valid state transitions\n  - Test invalid transition rejection\n  - Test timeout handling in each state\n  - Test cancellation from each state\n\n- [ ] **Context serialization tests** (`handoff-context.service.spec.ts`)\n  - Test context packaging with all field types\n  - Test context size calculation\n  - Test sensitive data sanitization\n  - Test context validation on receive\n  - Test partial context handling\n\n- [ ] **Resource transfer tests** (`handoff-transfer.service.spec.ts`)\n  - Test file reservation transfer\n  - Test checkpoint ownership transfer\n  - Test Agent Mail forwarding\n  - Test atomic rollback on failure\n\n### Integration Tests\n\n- [ ] **Full handoff cycle** (`handoff.integration.spec.ts`)\n  - Test initiate -\u003e accept -\u003e transfer -\u003e complete flow\n  - Test initiate -\u003e reject -\u003e broadcast -\u003e accept flow\n  - Test context integrity across transfer\n  - Test resource ownership verification post-transfer\n\n- [ ] **Agent Mail integration** (`handoff-mail.integration.spec.ts`)\n  - Test notification delivery on handoff events\n  - Test message forwarding during transfer\n  - Test notification on handoff completion\n\n### E2E Tests\n\n- [ ] **UI workflow** (`handoff-ui.e2e.spec.ts`)\n  - Test manual handoff initiation from UI\n  - Test handoff acceptance/rejection from UI\n  - Test handoff history display\n  - Test real-time status updates\n\n- [ ] **Failure recovery tests** (`handoff-recovery.e2e.spec.ts`)\n  - Test network failure during context transfer\n  - Test source agent crash during transfer\n  - Test target agent crash during transfer\n  - Test timeout recovery\n  - Test partial transfer recovery\n\n## Logging Requirements\n\n### Handoff Lifecycle Events\n\nAll handoff state transitions must be logged with correlation IDs:\n\n```typescript\nlogger.info('Handoff state transition', {\n  correlationId: handoff.correlationId,\n  handoffId: handoff.id,\n  previousState: previousState,\n  newState: newState,\n  sourceAgentId: handoff.sourceAgentId,\n  targetAgentId: handoff.targetAgentId,\n  bvId: handoff.context.bvId,\n  reason: handoff.reason,\n  transitionTrigger: trigger,\n  timestamp: new Date().toISOString()\n});\n```\n\n### Context Transfer Audit Trail\n\n```typescript\nlogger.info('Handoff context transfer', {\n  correlationId: handoff.correlationId,\n  handoffId: handoff.id,\n  transferPhase: phase, // 'started' | 'progress' | 'completed' | 'failed'\n  contextStats: {\n    filesModified: context.filesModified.length,\n    decisionsIncluded: context.decisionsMade.length,\n    conversationSummaryLength: context.conversationSummary.length,\n    totalSizeBytes: calculateSize(context)\n  },\n  resourcesTransferred: {\n    fileReservations: reservations.length,\n    checkpoints: checkpoints.length,\n    pendingMessages: messages.length\n  },\n  transferDurationMs: elapsed,\n  integrityHash: computeHash(context)\n});\n```\n\n### Failure Logging\n\n```typescript\nlogger.error('Handoff transfer failed', {\n  correlationId: handoff.correlationId,\n  handoffId: handoff.id,\n  failurePhase: phase,\n  errorCode: error.code,\n  errorMessage: error.message,\n  recoveryAction: recoveryAction,\n  resourcesRolledBack: rolledBack,\n  sourceAgentNotified: notified\n});\n```\n\n## Acceptance Criteria\n\n- [ ] Handoff state machine implements all phases (initiate, pending, transfer, complete, rejected, failed, cancelled)\n- [ ] Context transfer includes all specified contents (files, decisions, conversation, working memory)\n- [ ] Resource transfer is atomic (all-or-nothing with rollback on failure)\n- [ ] Agent Mail notifications sent for all handoff lifecycle events\n- [ ] Handoff requests can target specific agent or broadcast to available agents\n- [ ] Timeout handling implemented for pending and transfer phases\n- [ ] UI components display active handoffs and history\n- [ ] Full audit trail logged with correlation IDs\n- [ ] Unit test coverage \u003e= 90% for handoff services\n- [ ] Integration tests verify full handoff cycle\n- [ ] E2E tests verify UI workflow and failure recovery\n\n## References\n\n- PLAN.md §7.8 - Session Handoff Protocol\n- Related: flywheel_gateway-2pk (Agent Mail)\n- Related: flywheel_gateway-2ph (Checkpoint service)\n- Related: flywheel_gateway-2pi (File reservation service)\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] HandoffPackage: includes session state\n- [ ] HandoffPackage: includes pending work queue\n- [ ] HandoffPackage: includes file reservations\n- [ ] HandoffPackage: includes context summary\n- [ ] HandoffPackage: serializes to JSON\n- [ ] HandoffPackage: deserializes correctly\n- [ ] Handoff validation: source agent active\n- [ ] Handoff validation: target agent ready\n- [ ] Handoff validation: package complete\n- [ ] Resource transfer: reservations moved\n- [ ] Resource transfer: bead assignments moved\n- [ ] Audit trail: handoff recorded\n\n### Integration Tests\n- [ ] POST /agents/:id/handoff initiates handoff\n- [ ] Source agent receives handoff-out event\n- [ ] Target agent receives handoff-in event\n- [ ] Reservations transferred to target\n- [ ] Pending beads assigned to target\n- [ ] Handoff appears in audit log\n- [ ] Rollback on handoff failure\n- [ ] Multiple handoffs in sequence\n\n### E2E Tests\n- [ ] Context window limit triggers handoff\n- [ ] New agent continues work seamlessly\n- [ ] User sees handoff in UI\n- [ ] Handoff history viewable\n\n### Performance Tests\n- [ ] Handoff completes \u003c2s\n- [ ] Context pack transfer \u003c1s\n- [ ] Reservation transfer \u003c100ms\n- [ ] No message loss during handoff\n\n### Failure Mode Tests\n- [ ] Target agent unavailable: retry or fail\n- [ ] Source crashes mid-handoff: cleanup\n- [ ] Partial transfer: rolled back\n- [ ] Handoff timeout: handled gracefully","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:48:11.759461998-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:56:21.589125958-05:00","dependencies":[{"issue_id":"flywheel_gateway-2pl","depends_on_id":"flywheel_gateway-36m","type":"blocks","created_at":"2026-01-08T14:01:54.29406304-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-2pl","depends_on_id":"flywheel_gateway-5nm","type":"blocks","created_at":"2026-01-08T14:01:55.605177191-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-350","title":"Idempotency Middleware","description":"## Background\n\nIn distributed systems, network failures, client retries, and load balancer timeouts can cause duplicate requests. Without idempotency protection, these duplicates can result in:\n- Duplicate agent invocations (wasted tokens/cost)\n- Inconsistent state (e.g., double-creating resources)\n- Race conditions between concurrent identical requests\n- Poor user experience with unexpected behavior\n\nThe Flywheel Gateway needs robust idempotency middleware to ensure that retrying a request produces the same result as the original, without re-executing the underlying operation.\n\n## Technical Approach\n\n### Idempotency Key Strategy\n\nClients include an `Idempotency-Key` header with a unique identifier (typically UUID v4). The middleware:\n\n1. **On first request**: Execute handler, cache response with key\n2. **On duplicate request**: Return cached response without re-execution\n3. **On concurrent duplicate**: Block until first completes, return same result\n\n```typescript\n// apps/gateway/src/middleware/idempotency.ts\ninterface IdempotencyRecord {\n  key: string;\n  workspaceId: string;\n  \n  // Request fingerprint\n  method: string;\n  path: string;\n  bodyHash: string;\n  \n  // Response cache\n  statusCode: number;\n  headers: Record\u003cstring, string\u003e;\n  body: string;\n  \n  // State\n  status: 'processing' | 'completed' | 'failed';\n  \n  // Timing\n  createdAt: Date;\n  expiresAt: Date;\n  completedAt?: Date;\n}\n```\n\n### Request Fingerprinting\n\nTo detect mismatched requests using the same key:\n- Hash the request body (SHA-256)\n- Compare method and path\n- Return 422 if key reused with different request\n\n### Concurrency Handling\n\nWhen a duplicate request arrives while the original is processing:\n\n```typescript\nasync function handleConcurrentRequest(key: string): Promise\u003cResponse\u003e {\n  const maxWaitMs = 30000;  // 30 second timeout\n  const pollIntervalMs = 100;\n  \n  for (let elapsed = 0; elapsed \u003c maxWaitMs; elapsed += pollIntervalMs) {\n    const record = await getIdempotencyRecord(key);\n    \n    if (record.status === 'completed') {\n      return reconstructResponse(record);\n    }\n    \n    if (record.status === 'failed') {\n      // Allow retry on failure\n      return null;  \n    }\n    \n    await sleep(pollIntervalMs);\n  }\n  \n  throw new GatewayTimeoutError('Original request still processing');\n}\n```\n\n### TTL Configuration\n\nIdempotency records have configurable time-to-live:\n- Default: 24 hours\n- Minimum: 1 hour  \n- Maximum: 7 days\n- Configurable per-workspace via settings\n\nAfter TTL expiration, the same key can be reused for a new request.\n\n### Storage Backend\n\nOptions for idempotency record storage:\n1. **Redis** (preferred): Fast, built-in TTL, atomic operations\n2. **PostgreSQL**: Fallback if Redis unavailable, requires cleanup job\n3. **Memory**: Development only, not suitable for multi-instance\n\n```typescript\ninterface IdempotencyStore {\n  get(key: string): Promise\u003cIdempotencyRecord | null\u003e;\n  set(key: string, record: IdempotencyRecord): Promise\u003cvoid\u003e;\n  setIfNotExists(key: string, record: IdempotencyRecord): Promise\u003cboolean\u003e;\n  update(key: string, updates: Partial\u003cIdempotencyRecord\u003e): Promise\u003cvoid\u003e;\n  delete(key: string): Promise\u003cvoid\u003e;\n}\n```\n\n### Scope of Protection\n\nIdempotency middleware applies to mutating endpoints:\n- POST requests (all)\n- PUT requests (all)\n- PATCH requests (all)\n- DELETE requests (configurable)\n\nGET and HEAD requests are naturally idempotent and excluded.\n\n## File Locations\n\n### Core Implementation\n- `apps/gateway/src/middleware/idempotency.ts` - Main middleware\n- `apps/gateway/src/middleware/idempotency.store.ts` - Storage abstraction\n- `apps/gateway/src/middleware/idempotency.redis.ts` - Redis implementation\n- `apps/gateway/src/middleware/idempotency.postgres.ts` - PostgreSQL fallback\n- `apps/gateway/src/types/idempotency.types.ts` - TypeScript interfaces\n\n### Configuration\n- `apps/gateway/src/config/idempotency.config.ts` - TTL and behavior settings\n\n### Tests\n- `apps/gateway/src/middleware/__tests__/idempotency.test.ts`\n- `apps/gateway/src/middleware/__tests__/idempotency.integration.test.ts`\n\n## API Behavior\n\n### Headers\n\nRequest:\n```\nPOST /api/agents/invoke\nIdempotency-Key: 550e8400-e29b-41d4-a716-446655440000\n```\n\nResponse (first request):\n```\nHTTP/1.1 200 OK\nIdempotency-Key: 550e8400-e29b-41d4-a716-446655440000\nIdempotency-Replayed: false\n```\n\nResponse (duplicate request):\n```\nHTTP/1.1 200 OK\nIdempotency-Key: 550e8400-e29b-41d4-a716-446655440000\nIdempotency-Replayed: true\n```\n\n### Error Cases\n\n```\nHTTP/1.1 422 Unprocessable Entity\n{\n  \"error\": \"idempotency_mismatch\",\n  \"message\": \"Idempotency key already used with different request parameters\"\n}\n\nHTTP/1.1 409 Conflict  \n{\n  \"error\": \"idempotency_conflict\",\n  \"message\": \"Request with this idempotency key is currently processing\"\n}\n```\n\n## Acceptance Criteria\n\n1. [ ] Middleware intercepts all POST/PUT/PATCH requests\n2. [ ] Idempotency-Key header is parsed and validated (UUID format)\n3. [ ] First request executes normally and caches response\n4. [ ] Duplicate request returns cached response without re-execution\n5. [ ] Idempotency-Replayed header indicates whether response was cached\n6. [ ] Request fingerprinting detects mismatched key reuse (422 error)\n7. [ ] Concurrent duplicates block until original completes\n8. [ ] TTL is configurable per-workspace (1h to 7d range)\n9. [ ] Expired records are automatically cleaned up\n10. [ ] Redis storage works with automatic TTL expiration\n11. [ ] PostgreSQL fallback works when Redis unavailable\n12. [ ] Failed requests allow retry with same key\n13. [ ] Streaming responses are handled correctly (cache final state)\n14. [ ] Performance overhead is minimal (\u003c5ms for cache check)\n15. [ ] Multi-workspace isolation (keys scoped to workspace)\n\n## Edge Cases\n\n- **Large response bodies**: Compress before caching, max 10MB\n- **Streaming responses**: Buffer complete response before caching\n- **Request timeout**: Mark as failed, allow retry\n- **Server restart**: Redis persistence preserves records\n- **Clock skew**: Use Redis server time for TTL\n\n## Dependencies\n\n- Redis connection (primary storage)\n- PostgreSQL (fallback storage)\n- Request body parsing middleware\n- Tenant authentication middleware\n\n## Reference\n\nPLAN.md §8 - Idempotency and Request Deduplication\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Idempotency key parsing + normalization (header + body variants)\n- [ ] Request fingerprinting (method/path/body hash) prevents cross-endpoint replay\n- [ ] Storage adapter: TTL expiry, overwrite rules, and concurrent access behavior\n\n### Integration Tests\n- [ ] Repeat the same mutating request with same idempotency key → no duplicate side effects and identical response\n- [ ] Same idempotency key with different request fingerprint → 409/4xx with actionable error code\n\n### Failure Mode Tests\n- [ ] Storage unavailable → safe fallback (configurable) with clear error + no partial writes\n\n### Logging\n- [ ] Logs include correlationId + idempotencyKeyHash (never raw key) + replay=true/false\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] IdempotencyKey: parses from header\n- [ ] IdempotencyKey: generates if missing (optional)\n- [ ] IdempotencyKey: validates format\n- [ ] Cache: stores response by key\n- [ ] Cache: retrieves cached response\n- [ ] Cache: expires after TTL\n- [ ] Middleware: checks cache first\n- [ ] Middleware: executes if miss\n- [ ] Middleware: stores after execution\n- [ ] Middleware: returns cached on hit\n- [ ] Conflict: detects in-flight duplicate\n- [ ] Conflict: waits for original to complete\n\n### Integration Tests\n- [ ] Duplicate request returns same response\n- [ ] Different key executes independently\n- [ ] In-flight duplicate waits\n- [ ] Expired key re-executes\n- [ ] Error response not cached\n- [ ] Success response cached\n- [ ] All mutating endpoints covered\n\n### E2E Tests\n- [ ] Double-click submit safe\n- [ ] Network retry returns same result\n- [ ] Concurrent requests handled\n\n### Performance Tests\n- [ ] Cache lookup \u003c1ms\n- [ ] Cache store \u003c5ms\n- [ ] Minimal latency overhead\n- [ ] High concurrency stable\n\n### Failure Mode Tests\n- [ ] Cache unavailable: pass-through\n- [ ] Invalid key format: 400 error\n- [ ] Key collision: detected\n- [ ] Timeout waiting: error returned","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:37:54.340641515-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:03:51.526338066-05:00","dependencies":[{"issue_id":"flywheel_gateway-350","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T14:01:56.644788491-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-35p","title":"Documentation","description":"## Background\n\nComprehensive documentation is essential for adoption, maintenance, and collaboration on the Flywheel Gateway project. This includes API documentation for developers integrating with the gateway, user guides for operators, architecture documentation for contributors, and deployment guides for DevOps teams. Good documentation reduces support burden and enables self-service.\n\n## Reasoning\n\nDocumentation serves multiple audiences with different needs:\n\n1. **API Consumers**: Need accurate, example-rich API docs to integrate quickly\n2. **Operators/Admins**: Need user guides to configure and manage the system\n3. **Contributors**: Need architecture docs to understand design decisions\n4. **DevOps/SRE**: Need deployment guides for reliable operations\n5. **AI Agents**: Need AGENTS.md to understand codebase conventions\n\nWell-maintained documentation:\n- Reduces onboarding time for new team members\n- Decreases support tickets and questions\n- Enables external adoption and contributions\n- Serves as a source of truth for system behavior\n\n## Technical Considerations\n\n### API Documentation (OpenAPI)\n\n```yaml\n# docs/openapi.yaml\nopenapi: 3.1.0\ninfo:\n  title: Flywheel Gateway API\n  version: 1.0.0\n  description: |\n    The Flywheel Gateway provides a unified API for managing AI agents,\n    sessions, and real-time communication.\n    \n    ## Authentication\n    All endpoints require Bearer token authentication.\n    \n    ## Rate Limiting\n    API requests are limited to 1000 requests per minute per API key.\n    \n    ## WebSocket\n    Real-time updates are available via WebSocket at `/ws`.\n  contact:\n    name: API Support\n    email: support@flywheel.dev\n  license:\n    name: MIT\n    \nservers:\n  - url: https://api.flywheel.dev/v1\n    description: Production\n  - url: https://staging-api.flywheel.dev/v1\n    description: Staging\n  - url: http://localhost:3000/v1\n    description: Local development\n\npaths:\n  /agents:\n    get:\n      summary: List all agents\n      description: |\n        Returns a paginated list of all agents accessible to the authenticated user.\n        Results can be filtered by status, type, and tags.\n      operationId: listAgents\n      tags:\n        - Agents\n      parameters:\n        - name: status\n          in: query\n          schema:\n            type: string\n            enum: [running, stopped, error, starting]\n          description: Filter by agent status\n        - name: limit\n          in: query\n          schema:\n            type: integer\n            default: 20\n            maximum: 100\n          description: Maximum number of agents to return\n        - name: cursor\n          in: query\n          schema:\n            type: string\n          description: Pagination cursor from previous response\n      responses:\n        '200':\n          description: Successful response\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/AgentListResponse'\n              examples:\n                default:\n                  summary: Typical response\n                  value:\n                    agents:\n                      - id: \"agent_abc123\"\n                        name: \"Code Assistant\"\n                        status: \"running\"\n                        createdAt: \"2024-01-15T10:30:00Z\"\n                        sessionCount: 5\n                    nextCursor: \"eyJpZCI6ImFnZW50X3h5ejc4OSJ9\"\n                    total: 42\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '429':\n          $ref: '#/components/responses/RateLimited'\n```\n\n### User Guides Structure\n\n```markdown\n# docs/user-guide/README.md\n\n# Flywheel Gateway User Guide\n\n## Table of Contents\n1. [Getting Started](./getting-started.md)\n2. [Dashboard Overview](./dashboard.md)\n3. [Managing Agents](./agents.md)\n4. [Working with Sessions](./sessions.md)\n5. [Configuration](./configuration.md)\n6. [Troubleshooting](./troubleshooting.md)\n\n---\n\n# docs/user-guide/agents.md\n\n# Managing Agents\n\n## Overview\nAgents are AI assistants that can be deployed and managed through the Flywheel Gateway.\n\n## Creating an Agent\n\n1. Navigate to **Agents** in the sidebar\n2. Click **Create Agent**\n3. Fill in the required fields:\n   - **Name**: A descriptive name for your agent\n   - **Type**: The agent type (assistant, tool, custom)\n   - **Model**: The underlying AI model to use\n4. Configure optional settings:\n   - **System Prompt**: Instructions for the agent\n   - **Tools**: Available tools/functions\n   - **Memory**: Context window settings\n5. Click **Create**\n\n### Example Configuration\n[Screenshot: Agent creation form]\n\n## Agent Lifecycle\n\n[Diagram: Agent states and transitions]\n\n| State | Description |\n|-------|-------------|\n| Starting | Agent is initializing |\n| Running | Agent is active and accepting sessions |\n| Stopped | Agent is inactive |\n| Error | Agent encountered an error |\n\n## Monitoring Agents\n\nThe agent detail page shows:\n- **Status**: Current state and uptime\n- **Sessions**: Active and recent sessions\n- **Metrics**: Request rate, latency, errors\n- **Logs**: Recent agent logs\n```\n\n### Architecture Documentation\n\n```markdown\n# docs/architecture/README.md\n\n# Flywheel Gateway Architecture\n\n## System Overview\n\n[Diagram: High-level architecture]\n\nThe Flywheel Gateway consists of three main components:\n\n1. **Gateway Server** (Hono/Bun): Handles HTTP/WebSocket requests\n2. **Web Dashboard** (React): Admin interface\n3. **Database** (SQLite/PostgreSQL): Persistent storage\n\n## Component Architecture\n\n### Gateway Server\n\n```\napps/gateway/\n├── src/\n│   ├── app.ts              # Application entry point\n│   ├── routes/             # HTTP route handlers\n│   │   ├── agents.ts       # Agent CRUD operations\n│   │   ├── sessions.ts     # Session management\n│   │   └── auth.ts         # Authentication\n│   ├── websocket/          # WebSocket handling\n│   │   ├── server.ts       # WS server setup\n│   │   ├── handlers/       # Message handlers\n│   │   └── rooms.ts        # Room/channel management\n│   ├── services/           # Business logic\n│   │   ├── AgentService.ts\n│   │   └── SessionService.ts\n│   └── lib/                # Utilities\n│       ├── auth/\n│       ├── database/\n│       └── validation/\n```\n\n### Data Flow\n\n[Sequence diagram: Request lifecycle]\n\n1. Client sends HTTP request\n2. Authentication middleware validates token\n3. Route handler receives request\n4. Service layer executes business logic\n5. Database operations performed\n6. Response returned to client\n7. WebSocket events broadcast if applicable\n\n## Design Decisions\n\n### Why Bun + Hono?\n- **Performance**: Bun's native HTTP server is 3-4x faster than Node.js\n- **Simplicity**: Hono provides Express-like DX with better types\n- **WebSockets**: Bun has native WebSocket support\n\n### Why SQLite for Development?\n- Zero configuration required\n- File-based, easy to reset\n- Sufficient for single-node deployments\n- PostgreSQL for production scaling\n\n### WebSocket Architecture\n[Diagram: WebSocket message flow]\n\n- Room-based subscription model\n- Server-initiated heartbeats\n- Automatic reconnection with backoff\n- Message acknowledgment for critical events\n```\n\n### AGENTS.md Enhancement\n\n```markdown\n# AGENTS.md\n\n# AI Agent Instructions for Flywheel Gateway\n\n## Project Overview\nFlywheel Gateway is a real-time dashboard for managing AI agents built with:\n- **Runtime**: Bun\n- **Backend**: Hono (TypeScript)\n- **Frontend**: React + Vite + TailwindCSS\n- **Database**: Drizzle ORM with SQLite/PostgreSQL\n- **Testing**: Bun test, Playwright\n\n## Codebase Conventions\n\n### File Organization\n- Feature-based structure in `apps/web/src/`\n- Shared types in `packages/shared/`\n- Tests co-located or in `tests/` directory\n\n### Naming Conventions\n- Components: PascalCase (`AgentCard.tsx`)\n- Hooks: camelCase with `use` prefix (`useAgentStatus.ts`)\n- Utils: camelCase (`formatDate.ts`)\n- Types: PascalCase with `T` or descriptive suffix (`AgentStatus`, `ApiResponse`)\n\n### Code Style\n- Prefer `const` over `let`\n- Use explicit return types on exported functions\n- Avoid `any` - use `unknown` with type guards\n- Use template literals for string interpolation\n\n### Component Patterns\n```typescript\n// Preferred: Functional components with explicit props\ninterface AgentCardProps {\n  agent: Agent;\n  onSelect?: (id: string) =\u003e void;\n}\n\nexport function AgentCard({ agent, onSelect }: AgentCardProps) {\n  return (/* ... */);\n}\n```\n\n### State Management\n- Local state: `useState`\n- Server state: React Query (`@tanstack/react-query`)\n- Global state: Zustand (minimal use)\n\n### API Patterns\n- Use Hono's typed routes\n- Validate with Zod schemas\n- Return consistent error format\n\n### Testing Requirements\n- Unit tests for utilities and hooks\n- Integration tests for API routes\n- E2E tests for critical paths\n- Aim for 80% coverage on new code\n\n## Common Tasks\n\n### Adding a New API Endpoint\n1. Define Zod schema in `packages/shared/src/schemas/`\n2. Add route handler in `apps/gateway/src/routes/`\n3. Update OpenAPI spec in `docs/openapi.yaml`\n4. Add tests in `tests/integration/api/`\n\n### Adding a New Component\n1. Create component in appropriate feature folder\n2. Export from feature's `index.ts`\n3. Add Storybook story if visual\n4. Add unit tests\n\n### Database Migrations\n1. Modify schema in `packages/database/src/schema/`\n2. Run `bun run db:generate` to create migration\n3. Run `bun run db:migrate` to apply\n\n## Important Files\n- `PLAN.md`: Project roadmap and requirements\n- `docs/architecture/`: System design documentation\n- `apps/gateway/src/app.ts`: Server entry point\n- `apps/web/src/main.tsx`: Frontend entry point\n```\n\n### Deployment Guide\n\n```markdown\n# docs/deployment/README.md\n\n# Deployment Guide\n\n## Prerequisites\n- Docker and Docker Compose\n- PostgreSQL 15+ (for production)\n- Domain with SSL certificate\n\n## Quick Start (Docker Compose)\n\n```bash\n# Clone repository\ngit clone https://github.com/flywheel/gateway.git\ncd gateway\n\n# Copy environment template\ncp .env.example .env\n# Edit .env with your configuration\n\n# Start services\ndocker compose up -d\n```\n\n## Production Configuration\n\n### Environment Variables\n\n| Variable | Required | Description | Example |\n|----------|----------|-------------|---------|\n| `DATABASE_URL` | Yes | PostgreSQL connection string | `postgresql://user:pass@host:5432/db` |\n| `JWT_SECRET` | Yes | Secret for JWT signing (32+ chars) | `your-secure-secret` |\n| `CORS_ORIGINS` | No | Allowed CORS origins | `https://app.example.com` |\n| `LOG_LEVEL` | No | Logging verbosity | `info` |\n\n### Database Setup\n\n```bash\n# Create database\ncreatedb flywheel_gateway\n\n# Run migrations\nDATABASE_URL=postgresql://... bun run db:migrate\n\n# (Optional) Seed initial data\nDATABASE_URL=postgresql://... bun run db:seed\n```\n\n### Nginx Configuration\n\n```nginx\nupstream gateway {\n    server 127.0.0.1:3000;\n    keepalive 32;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.example.com;\n    \n    ssl_certificate /etc/ssl/certs/api.example.com.crt;\n    ssl_certificate_key /etc/ssl/private/api.example.com.key;\n    \n    location / {\n        proxy_pass http://gateway;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\n## Monitoring\n\n### Health Check Endpoint\n```bash\ncurl https://api.example.com/health\n# {\"status\":\"healthy\",\"version\":\"1.0.0\",\"uptime\":12345}\n```\n\n### Metrics\nPrometheus metrics available at `/metrics`:\n- `gateway_requests_total`: Total HTTP requests\n- `gateway_request_duration_seconds`: Request latency histogram\n- `gateway_websocket_connections`: Active WebSocket connections\n\n## Scaling\n\n### Horizontal Scaling\n1. Use PostgreSQL instead of SQLite\n2. Configure Redis for session affinity\n3. Deploy multiple gateway instances behind load balancer\n\n### Load Balancer Configuration\n- Use sticky sessions for WebSocket connections\n- Configure health check on `/health`\n- Set connection timeout to 60s for WebSocket\n\n## Backup and Recovery\n\n### Database Backup\n```bash\n# Daily backup cron job\n0 3 * * * pg_dump $DATABASE_URL | gzip \u003e /backups/gateway-$(date +%Y%m%d).sql.gz\n```\n\n### Disaster Recovery\n1. Restore database from latest backup\n2. Deploy fresh gateway instances\n3. Verify health checks pass\n4. Update DNS/load balancer\n```\n\n## File Locations\n\n### API Documentation\n- `docs/openapi.yaml` - OpenAPI 3.1 specification\n- `docs/api/` - Generated API reference (from OpenAPI)\n- `docs/api/examples/` - Example requests/responses\n\n### User Guides\n- `docs/user-guide/README.md` - Guide table of contents\n- `docs/user-guide/getting-started.md` - Quick start guide\n- `docs/user-guide/agents.md` - Agent management guide\n- `docs/user-guide/sessions.md` - Session usage guide\n- `docs/user-guide/configuration.md` - Configuration reference\n- `docs/user-guide/troubleshooting.md` - Common issues and solutions\n\n### Architecture Documentation\n- `docs/architecture/README.md` - Architecture overview\n- `docs/architecture/components.md` - Component details\n- `docs/architecture/data-flow.md` - Data flow diagrams\n- `docs/architecture/decisions/` - Architecture Decision Records (ADRs)\n\n### Project Documentation\n- `README.md` - Project overview and quick start\n- `AGENTS.md` - AI agent coding instructions\n- `CONTRIBUTING.md` - Contribution guidelines\n- `CHANGELOG.md` - Version history\n\n### Deployment Documentation\n- `docs/deployment/README.md` - Deployment overview\n- `docs/deployment/docker.md` - Docker deployment\n- `docs/deployment/kubernetes.md` - Kubernetes deployment\n- `docs/deployment/monitoring.md` - Monitoring setup\n\n## Acceptance Criteria\n\n### API Documentation\n- [ ] OpenAPI spec covers all endpoints\n- [ ] All endpoints have descriptions\n- [ ] Request/response examples provided\n- [ ] Error responses documented\n- [ ] Authentication documented\n- [ ] Rate limiting documented\n- [ ] Interactive API explorer available (Swagger UI or similar)\n\n### User Guides\n- [ ] Getting started guide enables first deployment in \u003c15 minutes\n- [ ] All major features documented with screenshots\n- [ ] Step-by-step tutorials for common tasks\n- [ ] Troubleshooting section addresses common issues\n- [ ] Guides tested by someone unfamiliar with project\n\n### Architecture Documentation\n- [ ] High-level architecture diagram\n- [ ] Component interaction diagrams\n- [ ] Data flow documentation\n- [ ] Key design decisions recorded as ADRs\n- [ ] Database schema documented\n- [ ] WebSocket protocol documented\n\n### AGENTS.md\n- [ ] Project overview and tech stack\n- [ ] Codebase conventions documented\n- [ ] File organization explained\n- [ ] Common tasks with step-by-step instructions\n- [ ] Important files listed with descriptions\n- [ ] Testing requirements specified\n- [ ] Code patterns with examples\n\n### README Updates\n- [ ] Project description and purpose\n- [ ] Quick start instructions\n- [ ] Prerequisites listed\n- [ ] Development setup guide\n- [ ] Links to detailed documentation\n- [ ] Badge for build status, coverage, etc.\n- [ ] License information\n\n### Deployment Guide\n- [ ] Prerequisites clearly listed\n- [ ] Environment variables documented\n- [ ] Docker/Docker Compose setup\n- [ ] Production configuration guide\n- [ ] Nginx/reverse proxy configuration\n- [ ] SSL/TLS setup instructions\n- [ ] Monitoring and health checks\n- [ ] Backup and recovery procedures\n- [ ] Scaling guidance\n\n### Documentation Quality\n- [ ] No broken links\n- [ ] Consistent formatting\n- [ ] Up-to-date with current codebase\n- [ ] Spelling and grammar checked\n- [ ] Accessible (proper heading hierarchy, alt text)\n- [ ] Version controlled alongside code\n\n## Reference\n\nPLAN.md - Documentation requirements","notes":"## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Documentation Validation Tests\n- [ ] All API endpoints documented in OpenAPI spec are accessible\n- [ ] All code examples in documentation are syntactically valid\n- [ ] Internal links resolve correctly (no 404s)\n- [ ] External links are accessible (link checker)\n\n### Generated Documentation Tests\n- [ ] OpenAPI spec validates against OpenAPI 3.1 schema\n- [ ] TypeDoc generates without errors for all public APIs\n- [ ] API reference examples execute successfully\n\n### Content Tests\n- [ ] README quick start guide runs successfully on fresh clone\n- [ ] Deployment guide steps complete without errors\n- [ ] Configuration examples are valid YAML/JSON\n\n### Accessibility Tests\n- [ ] Documentation site meets WCAG 2.1 AA contrast requirements\n- [ ] Heading hierarchy is logical (no skipped levels)\n- [ ] Code blocks have appropriate language tags\n\n### Maintenance\n- [ ] Documentation CI job fails on broken links or invalid examples","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T13:57:53.888161146-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:38:33.932666899-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-35p","depends_on_id":"flywheel_gateway-tz4","type":"blocks","created_at":"2026-01-08T14:01:58.881151167-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-36m","title":"Checkpoint/Restore System with Delta-Based Progressive Checkpointing","description":"## Background\n\nThe Checkpoint/Restore System is a critical infrastructure component that enables session state persistence and recovery. This feature addresses the fundamental challenge of maintaining continuity in long-running agent sessions, where context can be lost due to crashes, timeouts, or intentional session transfers.\n\n### Why This Matters\n\n1. **Session Resilience**: Agent sessions can run for extended periods. Without checkpointing, any interruption means losing all accumulated context and progress.\n\n2. **Cost Efficiency**: Re-running prompts to reconstruct state is expensive both in tokens and time. Checkpoints allow instant restoration.\n\n3. **Multi-Agent Handoffs**: When rotating agents due to context window limits, checkpoints enable seamless state transfer.\n\n4. **Debugging and Replay**: Checkpoints provide snapshots for debugging failed sessions and replaying successful patterns.\n\n## Technical Design\n\n### Checkpoint Types\n\n```typescript\nenum CheckpointTrigger {\n  MANUAL = 'manual',           // User-initiated via API\n  AUTO = 'auto',               // Scheduled interval-based\n  ERROR = 'error',             // Pre-error state capture\n  ROTATION = 'rotation',       // Before agent rotation\n  MILESTONE = 'milestone'      // After significant progress\n}\n\ninterface Checkpoint {\n  id: string;                  // ULID for ordering\n  sessionId: string;\n  trigger: CheckpointTrigger;\n  type: 'full' | 'delta';\n  sequence: number;            // 1-indexed within session\n  parentId?: string;           // For deltas, reference to base\n  \n  // Storage\n  storagePath: string;\n  sizeBytes: number;\n  compressedSizeBytes: number;\n  \n  // Metadata\n  createdAt: Date;\n  expiresAt?: Date;\n  \n  // State summary\n  messageCount: number;\n  tokenCount: number;\n  beadReferences: string[];    // Beads touched in this session\n}\n```\n\n### Delta-Based Progressive Checkpointing\n\nThe system uses a delta-based approach to minimize storage while maintaining fast restore times:\n\n1. **Full Checkpoints**: Every 5th checkpoint (sequence % 5 === 0) stores complete state\n2. **Delta Checkpoints**: Intermediate checkpoints store only changes since the last checkpoint\n3. **Bounded Restore Time**: Maximum 4 deltas to apply ensures O(1) restore complexity\n\n```typescript\n// Delta calculation\ninterface DeltaContent {\n  addedMessages: Message[];\n  modifiedMetadata: Record\u003cstring, any\u003e;\n  newBeadRefs: string[];\n  removedBeadRefs: string[];\n  contextWindowDelta: {\n    tokensBefore: number;\n    tokensAfter: number;\n  };\n}\n\n// Restore algorithm\nasync function restore(checkpointId: string): Promise\u003cSessionState\u003e {\n  const checkpoint = await getCheckpoint(checkpointId);\n  \n  if (checkpoint.type === 'full') {\n    return decompress(await readStorage(checkpoint.storagePath));\n  }\n  \n  // Find nearest full checkpoint\n  const chain = await buildRestoreChain(checkpointId);\n  // chain = [fullCheckpoint, delta1, delta2, ..., targetDelta]\n  \n  let state = decompress(await readStorage(chain[0].storagePath));\n  for (let i = 1; i \u003c chain.length; i++) {\n    state = applyDelta(state, chain[i]);\n  }\n  \n  return state;\n}\n```\n\n### Compression Strategy\n\n```typescript\nconst compressionConfig = {\n  algorithm: 'zstd',           // Best ratio for JSON-like data\n  level: 3,                    // Balance between speed and ratio\n  dictionary: true,            // Use trained dictionary for messages\n  \n  // Expected ratios\n  // Full checkpoint: ~4:1 compression\n  // Delta checkpoint: ~10:1 compression (smaller, more repetitive)\n};\n```\n\n### Automatic Compaction\n\nOld delta chains are compacted to reduce storage and simplify restore:\n\n```typescript\ninterface CompactionPolicy {\n  // Keep last N full checkpoints\n  retainFullCheckpoints: number;  // Default: 5\n  \n  // Compact deltas older than threshold\n  compactAfterHours: number;      // Default: 24\n  \n  // Delete checkpoints older than threshold\n  deleteAfterDays: number;        // Default: 30\n  \n  // Minimum checkpoints to retain regardless of age\n  minimumRetained: number;        // Default: 3\n}\n\n// Compaction algorithm\nasync function compactSession(sessionId: string): Promise\u003cCompactionResult\u003e {\n  const checkpoints = await getSessionCheckpoints(sessionId);\n  const now = new Date();\n  \n  const result: CompactionResult = {\n    deleted: 0,\n    compacted: 0,\n    freedBytes: 0\n  };\n  \n  // Phase 1: Delete expired checkpoints\n  for (const cp of checkpoints) {\n    if (cp.expiresAt \u0026\u0026 cp.expiresAt \u003c now) {\n      await deleteCheckpoint(cp.id);\n      result.deleted++;\n      result.freedBytes += cp.sizeBytes;\n    }\n  }\n  \n  // Phase 2: Merge old delta chains into single full checkpoints\n  const oldChains = findCompactableChains(checkpoints, policy.compactAfterHours);\n  for (const chain of oldChains) {\n    const merged = await mergeChainToFull(chain);\n    result.compacted += chain.length - 1;\n    result.freedBytes += chain.reduce((sum, cp) =\u003e sum + cp.sizeBytes, 0) - merged.sizeBytes;\n  }\n  \n  return result;\n}\n```\n\n### Storage Backend\n\n```typescript\ninterface CheckpointStorage {\n  // Write checkpoint data\n  write(sessionId: string, checkpointId: string, data: Buffer): Promise\u003cstring\u003e;\n  \n  // Read checkpoint data\n  read(path: string): Promise\u003cBuffer\u003e;\n  \n  // Delete checkpoint\n  delete(path: string): Promise\u003cvoid\u003e;\n  \n  // List checkpoints for session\n  list(sessionId: string): Promise\u003cCheckpointMetadata[]\u003e;\n}\n\n// Default: Local filesystem with optional S3 tiering\nclass HybridCheckpointStorage implements CheckpointStorage {\n  constructor(\n    private localPath: string,\n    private s3Client?: S3Client,\n    private tierAfterHours: number = 24\n  ) {}\n  \n  // Hot checkpoints on local SSD\n  // Cold checkpoints tiered to S3\n}\n```\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Create manual checkpoint\nPOST /api/v1/sessions/:sessionId/checkpoints\nRequest: { trigger?: 'manual', metadata?: Record\u003cstring, any\u003e }\nResponse: { checkpointId: string, type: 'full' | 'delta', sequence: number }\n\n// List checkpoints\nGET /api/v1/sessions/:sessionId/checkpoints\nQuery: { limit?: number, before?: string, after?: string }\nResponse: { checkpoints: Checkpoint[], hasMore: boolean }\n\n// Get checkpoint details\nGET /api/v1/sessions/:sessionId/checkpoints/:checkpointId\nResponse: Checkpoint\n\n// Restore from checkpoint\nPOST /api/v1/sessions/:sessionId/restore\nRequest: { checkpointId: string, createNewSession?: boolean }\nResponse: { sessionId: string, restoredFrom: string, messageCount: number }\n\n// Delete checkpoint\nDELETE /api/v1/sessions/:sessionId/checkpoints/:checkpointId\nResponse: { deleted: true }\n```\n\n### WebSocket Events\n\n```typescript\n// Checkpoint created\n{\n  event: 'checkpoint.created',\n  data: {\n    checkpointId: string,\n    sessionId: string,\n    trigger: CheckpointTrigger,\n    type: 'full' | 'delta',\n    sequence: number\n  }\n}\n\n// Checkpoint restored\n{\n  event: 'checkpoint.restored',\n  data: {\n    checkpointId: string,\n    sessionId: string,\n    newSessionId?: string,\n    restorationTimeMs: number\n  }\n}\n\n// Compaction completed\n{\n  event: 'checkpoint.compacted',\n  data: {\n    sessionId: string,\n    deleted: number,\n    compacted: number,\n    freedBytes: number\n  }\n}\n```\n\n## Configuration\n\n```typescript\ninterface CheckpointConfig {\n  // Auto-checkpoint settings\n  autoCheckpoint: {\n    enabled: boolean;\n    intervalMinutes: number;      // Default: 5\n    onMessageCount: number;       // Checkpoint every N messages, default: 50\n    onTokenThreshold: number;     // Checkpoint when tokens exceed, default: 10000\n  };\n  \n  // Delta settings\n  delta: {\n    fullCheckpointInterval: number;  // Every Nth is full, default: 5\n    maxDeltaChainLength: number;     // Force full after N deltas, default: 4\n  };\n  \n  // Storage settings\n  storage: {\n    localPath: string;\n    maxLocalSizeGB: number;\n    compressionEnabled: boolean;\n    compressionLevel: number;\n  };\n  \n  // Compaction settings\n  compaction: {\n    enabled: boolean;\n    scheduleHour: number;         // Hour of day for scheduled compaction\n    retentionDays: number;\n  };\n}\n```\n\n## File Locations\n\n- **Primary Service**: `apps/gateway/src/services/checkpoint.service.ts`\n- **Storage Backend**: `apps/gateway/src/services/checkpoint-storage.service.ts`\n- **Types**: `apps/gateway/src/types/checkpoint.types.ts`\n- **Controller**: `apps/gateway/src/controllers/checkpoint.controller.ts`\n- **Tests**: `apps/gateway/src/services/__tests__/checkpoint.service.test.ts`\n\n## Dependencies\n\n- CAAM session store (for session metadata)\n- Compression library (zstd-wasm or similar)\n- Storage backend (filesystem + optional S3)\n\n## Acceptance Criteria\n\n1. **Manual Checkpoints**\n   - [ ] API endpoint creates checkpoint within 100ms for typical session\n   - [ ] Returns checkpoint ID and metadata\n   - [ ] Respects delta/full schedule\n\n2. **Auto Checkpoints**\n   - [ ] Triggers based on configured interval\n   - [ ] Triggers based on message count threshold\n   - [ ] Triggers based on token count threshold\n   - [ ] Does not create duplicate checkpoints within cooldown period\n\n3. **Error Checkpoints**\n   - [ ] Automatically captures state before error propagation\n   - [ ] Includes error context in checkpoint metadata\n   - [ ] Does not fail if checkpoint creation fails\n\n4. **Delta Storage**\n   - [ ] Correctly calculates delta between states\n   - [ ] Every 5th checkpoint is full\n   - [ ] Delta size is \u003c20% of full checkpoint size for typical sessions\n\n5. **Restoration**\n   - [ ] Restores from full checkpoint in \u003c50ms\n   - [ ] Restores from delta chain in \u003c200ms (4 deltas max)\n   - [ ] Correctly applies all deltas in order\n   - [ ] Validates restored state integrity\n\n6. **Compression**\n   - [ ] Achieves \u003e3:1 compression ratio for full checkpoints\n   - [ ] Achieves \u003e8:1 compression ratio for delta checkpoints\n   - [ ] Compression/decompression time \u003c10ms for typical checkpoint\n\n7. **Compaction**\n   - [ ] Runs on schedule without blocking operations\n   - [ ] Correctly merges delta chains\n   - [ ] Respects retention policy\n   - [ ] Reports freed storage\n\n8. **Observability**\n   - [ ] Emits WebSocket events for all checkpoint operations\n   - [ ] Logs checkpoint operations with timing metrics\n   - [ ] Exposes Prometheus metrics for checkpoint operations\n\n## Reference\n\n- PLAN.md Section 7.3 - Checkpoint/Restore System\n- PLAN.md Section 7.3.1 - Delta-Based Progressive Checkpointing\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Delta encoding/decoding is lossless across multiple sequential checkpoints\n- [ ] Progressive checkpoint compaction preserves the ability to restore any retained checkpoint\n- [ ] Retention policy deletes/compacts older checkpoints according to configured limits\n\n### Integration Tests\n- [ ] Create checkpoint → mutate agent state/output → restore checkpoint → status/output/history match expected snapshot\n- [ ] Restore emits the expected WebSocket events and appends a history/audit entry\n\n### Failure Mode Tests\n- [ ] Corrupted checkpoint data → restoration fails safely with actionable error and no partial state applied\n- [ ] Concurrent checkpoint + restore attempts are serialized (or rejected) deterministically\n\n### Logging\n- [ ] Logs include correlationId + agentId + checkpointId + bytes/tokens delta sizes; no sensitive prompt content\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Checkpoint.create: generates ULID id\n- [ ] Checkpoint.create: sets trigger type correctly\n- [ ] Checkpoint.create: calculates sequence number\n- [ ] Delta calculation: identifies added messages\n- [ ] Delta calculation: identifies modified metadata\n- [ ] Delta calculation: identifies new/removed bead refs\n- [ ] Full checkpoint: stores complete state\n- [ ] Compression: zstd achieves \u003e3:1 ratio\n- [ ] Decompression: restores exact bytes\n- [ ] Restore chain: builds correct chain from delta to full\n- [ ] Restore chain: max 4 deltas before full\n- [ ] Apply delta: correctly merges changes\n- [ ] Compaction policy: identifies expired checkpoints\n- [ ] Compaction policy: identifies compactable chains\n- [ ] Storage: write returns valid path\n- [ ] Storage: read returns exact bytes written\n\n### Integration Tests\n- [ ] POST /sessions/:id/checkpoints creates checkpoint\n- [ ] GET /sessions/:id/checkpoints returns list with pagination\n- [ ] GET /sessions/:id/checkpoints/:id returns details\n- [ ] POST /sessions/:id/restore restores state\n- [ ] DELETE /sessions/:id/checkpoints/:id removes checkpoint\n- [ ] Auto checkpoint triggers on interval\n- [ ] Auto checkpoint triggers on message count\n- [ ] Auto checkpoint triggers on token threshold\n- [ ] Every 5th checkpoint is full\n- [ ] Restore applies deltas in correct order\n- [ ] WebSocket checkpoint.created event fires\n- [ ] WebSocket checkpoint.restored event fires\n\n### E2E Tests\n- [ ] Full lifecycle: session -\u003e checkpoint -\u003e close -\u003e restore\n- [ ] Delta restore: multiple deltas applied correctly\n- [ ] Error checkpoint: captured before failure\n- [ ] Rotation checkpoint: seamless handoff\n\n### Performance Tests\n- [ ] Full checkpoint creation \u003c100ms\n- [ ] Delta checkpoint creation \u003c50ms\n- [ ] Full restore \u003c50ms\n- [ ] Delta chain restore (4 deltas) \u003c200ms\n- [ ] Compression time \u003c10ms for typical checkpoint\n- [ ] Storage tiering: hot -\u003e cold transition works\n\n### Failure Mode Tests\n- [ ] Restore missing checkpoint: clear error\n- [ ] Corrupted checkpoint data: detected and reported\n- [ ] Partial write recovery: checkpoint marked invalid\n- [ ] Storage full: graceful handling\n- [ ] Compaction failure: no data loss","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:43:00.40567824-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:04:05.601002891-05:00","dependencies":[{"issue_id":"flywheel_gateway-36m","depends_on_id":"flywheel_gateway-398","type":"blocks","created_at":"2026-01-08T14:01:49.203066221-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-36m","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:50.176966753-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-398","title":"FEAT: Agent Lifecycle State Model + Status Endpoints","description":"## Background\n\nAgent processes have complex lifecycles that must be carefully managed. Without a formal state model, race conditions and invalid state transitions lead to orphaned processes, resource leaks, and inconsistent behavior. The state machine provides a single source of truth for agent status.\n\n## Reasoning\n\n### Why a Formal State Machine?\n- **Correctness**: Only valid transitions are allowed (e.g., can't terminate an already-terminated agent)\n- **Debuggability**: Current and historical states provide clear operational picture\n- **Event-Driven**: State changes trigger appropriate side effects (cleanup, notifications)\n- **Testability**: State machines are easy to unit test exhaustively\n- **Documentation**: The state diagram serves as living documentation\n\n### Why Status Endpoints?\n- **Health Checks**: Load balancers and orchestrators need to check agent health\n- **UI Integration**: Web dashboard displays real-time agent status\n- **Debugging**: Operators can query agent state for troubleshooting\n- **Automation**: External systems can poll for state changes\n\n### Why WebSocket Events?\n- **Real-time Updates**: UI receives instant state change notifications\n- **Reduced Polling**: No need for clients to poll status endpoints\n- **Rich Context**: Events include metadata about state transitions\n- **Scalability**: Pub/sub pattern scales better than polling\n\n## Technical Considerations\n\n### State Machine Definition\n```typescript\nenum AgentState {\n  SPAWNING = 'spawning',     // Process starting, PTY initializing\n  INITIALIZING = 'initializing', // Agent loading, running init commands\n  READY = 'ready',           // Agent idle, waiting for input\n  EXECUTING = 'executing',   // Agent processing a command/prompt\n  PAUSED = 'paused',         // Agent temporarily suspended\n  TERMINATING = 'terminating', // Graceful shutdown in progress\n  TERMINATED = 'terminated', // Process ended normally\n  FAILED = 'failed',         // Process ended with error\n}\n\n// Valid transitions\nconst transitions = {\n  [AgentState.SPAWNING]: [AgentState.INITIALIZING, AgentState.FAILED],\n  [AgentState.INITIALIZING]: [AgentState.READY, AgentState.FAILED],\n  [AgentState.READY]: [AgentState.EXECUTING, AgentState.PAUSED, AgentState.TERMINATING],\n  [AgentState.EXECUTING]: [AgentState.READY, AgentState.PAUSED, AgentState.TERMINATING, AgentState.FAILED],\n  [AgentState.PAUSED]: [AgentState.READY, AgentState.TERMINATING],\n  [AgentState.TERMINATING]: [AgentState.TERMINATED, AgentState.FAILED],\n  [AgentState.TERMINATED]: [], // Terminal state\n  [AgentState.FAILED]: [],     // Terminal state\n};\n```\n\n### State Metadata\nEach state transition records:\n- Previous state and new state\n- Timestamp of transition\n- Reason for transition (user action, timeout, error, etc.)\n- Any error details for failure states\n\n### Status Endpoint Design\n```\nGET /api/v1/agents/:agentId/status\nResponse:\n{\n  \"agentId\": \"uuid\",\n  \"state\": \"ready\",\n  \"stateEnteredAt\": \"2024-01-15T10:30:00Z\",\n  \"uptime\": 3600,\n  \"lastActivity\": \"2024-01-15T11:25:00Z\",\n  \"healthChecks\": {\n    \"process\": \"healthy\",\n    \"pty\": \"healthy\",\n    \"memory\": \"healthy\"\n  },\n  \"metrics\": {\n    \"commandsExecuted\": 42,\n    \"totalOutputBytes\": 102400\n  }\n}\n```\n\n### WebSocket Event Schema\n```typescript\ninterface AgentStateEvent {\n  type: 'agent.state.changed';\n  agentId: string;\n  previousState: AgentState;\n  currentState: AgentState;\n  timestamp: string;\n  reason?: string;\n  error?: {\n    code: string;\n    message: string;\n  };\n}\n```\n\n### Health Check Strategy\n- **Process Health**: Is the PTY process still running?\n- **Responsiveness**: Did agent respond to last heartbeat?\n- **Memory**: Is agent within memory limits?\n- **Timeout Detection**: Auto-transition to FAILED if unresponsive\n\n## Acceptance Criteria\n\n- [ ] AgentState enum defines all valid states\n- [ ] State machine validates transitions, throws on invalid\n- [ ] All state transitions are logged with correlation ID\n- [ ] GET /api/v1/agents/:agentId/status returns current state and metadata\n- [ ] WebSocket emits `agent.state.changed` events\n- [ ] Health checks run on configurable interval (default 30s)\n- [ ] Failed health checks trigger state transition to FAILED\n- [ ] State history is queryable for debugging\n- [ ] Unit tests cover all valid transitions\n- [ ] Unit tests verify invalid transitions are rejected\n- [ ] Integration test for spawn -\u003e ready -\u003e executing -\u003e ready flow\n\n## File Locations\n\n### Core Service\n- `apps/gateway/src/services/agent.service.ts` - Agent lifecycle management\n\n### State Machine\n- `apps/gateway/src/models/agent-state.ts` - State enum and transition definitions\n- `apps/gateway/src/services/agent-state-machine.ts` - State machine implementation\n\n### Endpoints\n- `apps/gateway/src/routes/agent.routes.ts` - Status endpoint registration\n- `apps/gateway/src/controllers/agent.controller.ts` - Status endpoint handler\n\n### WebSocket\n- `apps/gateway/src/websocket/agent-events.ts` - State change event emission\n\n### Types\n- `packages/shared-types/src/agent.types.ts` - Shared agent state types\n\n## Reference\n\n- PLAN.md §7: Agent Lifecycle Management\n- XState patterns for state machine design\n- Kubernetes Pod lifecycle as conceptual model\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] State machine enforces valid transitions and rejects invalid ones with specific error codes\n- [ ] Busy/idle detection updates state consistently under concurrent events\n- [ ] Timeout handling moves agents into failed/terminated states with clear reason\n\n### Integration Tests\n- [ ] Spawn → running/idle transitions are reflected in REST responses and WS events\n- [ ] List/filter endpoints return consistent counts and pagination under concurrent state changes\n\n### Failure Mode Tests\n- [ ] Operations on terminated agents return the correct error taxonomy (not found vs gone)\n- [ ] Driver errors map to driver-related error codes and emit state-change events\n\n### Logging\n- [ ] Logs include correlationId + agentId + priorState/newState + driver; no raw secrets\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:31:56.91578968-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:29:07.469836268-05:00","dependencies":[{"issue_id":"flywheel_gateway-398","depends_on_id":"flywheel_gateway-w55","type":"blocks","created_at":"2026-01-08T14:01:52.042474977-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-398","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:52.783412679-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-3b1","title":"FEAT: Intelligent Conflict Resolution Assistant","description":"## Overview\n\nAI-powered conflict resolution suggestions that transform detected resource conflicts into actionable resolution strategies with confidence scoring and human-readable rationales.\n\n## Background \u0026 Reasoning\n\nConflict detection (Phase 2) identifies when multiple agents attempt to access the same resources, but detection alone is insufficient. Agents need intelligent guidance on **how** to resolve conflicts, not just notification that conflicts exist.\n\nKey challenges that require intelligent resolution:\n- **Priority ambiguity**: Multiple BVs may have similar urgency levels\n- **Progress asymmetry**: One agent may be 90% done while another just started\n- **Resource interdependence**: File A's conflict may cascade to files B, C, D\n- **Historical patterns**: CASS data reveals which resolution strategies worked before\n- **Human context**: Some conflicts require escalation to human decision-makers\n\nWithout intelligent resolution assistance, agents either deadlock waiting for each other, or humans must manually intervene in every conflict—neither scales.\n\n## Technical Architecture\n\n### Resolution Strategy Types\n\n| Strategy | Description | When Applied |\n|----------|-------------|--------------|\n| `wait` | Requesting agent waits for holder to complete | Holder near completion (\u003e80% progress) |\n| `split` | Divide resource into non-overlapping segments | File can be logically partitioned |\n| `transfer` | Current holder yields to higher-priority agent | Significant priority differential |\n| `coordinate` | Both agents collaborate on shared resource | Complementary work patterns detected |\n| `escalate` | Route to human decision-maker | High-risk or ambiguous situations |\n\n### Input Sources\n\nThe resolution engine synthesizes data from multiple sources:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                 Conflict Resolution Engine                   │\n├─────────────────────────────────────────────────────────────┤\n│  Inputs:                                                     │\n│  ├── BV Priorities (urgency, business value, deadlines)     │\n│  ├── Checkpoint Progress (% complete, time invested)         │\n│  ├── CASS History (past resolution outcomes, patterns)       │\n│  ├── Current Reservations (lock duration, scope)             │\n│  └── Agent Capabilities (can agent handle split work?)       │\n│                                                              │\n│  Processing:                                                 │\n│  ├── Strategy Scoring (each strategy scored 0-100)          │\n│  ├── Risk Assessment (what could go wrong?)                  │\n│  └── Evidence Compilation (why this recommendation?)         │\n│                                                              │\n│  Output:                                                     │\n│  └── ResolutionSuggestion (strategy + confidence + rationale)│\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Confidence Scoring (0-100)\n\nConfidence scores indicate how certain the system is about a recommendation:\n\n| Range | Interpretation | Auto-Resolution |\n|-------|----------------|-----------------|\n| 90-100 | Very high confidence | Auto-apply allowed |\n| 70-89 | High confidence | Auto-apply with notification |\n| 50-69 | Moderate confidence | Requires agent confirmation |\n| 30-49 | Low confidence | Requires human review |\n| 0-29 | Very low confidence | Escalate immediately |\n\n**Evidence categories** contributing to confidence:\n- Priority differential clarity (+/- 20 points)\n- Progress state certainty (+/- 15 points)\n- Historical pattern match (+/- 25 points)\n- Resource criticality assessment (+/- 20 points)\n- Time pressure factors (+/- 20 points)\n\n### Auto-Resolution Rules\n\nLow-risk conflicts can be resolved automatically when:\n1. Confidence score \u003e= 90\n2. Strategy is `wait` with ETA \u003c 5 minutes\n3. No files marked as `critical` or `protected`\n4. Both agents have auto-resolution enabled in preferences\n5. No prior failed resolution attempts for this conflict\n\n### Human-Readable Rationale Generation\n\nEvery suggestion includes a rationale explaining the decision:\n\n```\n\"Recommending WAIT strategy (confidence: 94/100):\n - Agent claude-session-7f2a holds reservation on src/auth/login.ts\n - Current progress: 87% complete (estimated 3 minutes remaining)\n - Your BV priority (P2) is lower than holder's (P1)\n - Historical data: 23/25 similar conflicts resolved successfully with WAIT\n - Risk: Low - no deadline pressure on your task\"\n```\n\n## Key Interfaces\n\n### ConflictResolutionRequest\n\n```typescript\ninterface ConflictResolutionRequest {\n  conflictId: string;\n  requestingAgentId: string;\n  requestingBvId: string;\n  contestedResources: ResourceIdentifier[];\n  urgencyOverride?: 'normal' | 'high' | 'critical';\n  preferredStrategies?: ResolutionStrategyType[];\n  context?: string; // Agent-provided context\n}\n```\n\n### ResolutionSuggestion\n\n```typescript\ninterface ResolutionSuggestion {\n  suggestionId: string;\n  conflictId: string;\n  recommendedStrategy: ResolutionStrategy;\n  alternativeStrategies: ResolutionStrategy[];\n  confidence: number; // 0-100\n  confidenceBreakdown: ConfidenceFactors;\n  rationale: string; // Human-readable explanation\n  autoResolutionEligible: boolean;\n  estimatedResolutionTime: number; // milliseconds\n  risks: RiskAssessment[];\n  createdAt: Date;\n  expiresAt: Date; // Suggestions expire as state changes\n}\n```\n\n### ResolutionStrategy\n\n```typescript\ninterface ResolutionStrategy {\n  type: 'wait' | 'split' | 'transfer' | 'coordinate' | 'escalate';\n  score: number; // 0-100 suitability score\n  params: StrategyParams;\n  prerequisites: Prerequisite[];\n  expectedOutcome: OutcomeProjection;\n}\n\ntype StrategyParams = \n  | WaitParams \n  | SplitParams \n  | TransferParams \n  | CoordinateParams \n  | EscalateParams;\n\ninterface WaitParams {\n  estimatedWaitMs: number;\n  pollingIntervalMs: number;\n  timeoutMs: number;\n  notifyOnProgress: boolean;\n}\n\ninterface SplitParams {\n  proposedPartitions: ResourcePartition[];\n  mergeStrategy: 'auto' | 'manual' | 'review';\n}\n\ninterface TransferParams {\n  fromAgentId: string;\n  toAgentId: string;\n  checkpointRequired: boolean;\n  gracePeriodMs: number;\n}\n\ninterface CoordinateParams {\n  coordinationProtocol: 'turn-based' | 'section-locked' | 'merge-on-complete';\n  communicationChannel: string;\n  syncIntervalMs: number;\n}\n\ninterface EscalateParams {\n  escalationTarget: 'project-lead' | 'system-admin' | 'custom';\n  customTargetId?: string;\n  urgency: 'normal' | 'high' | 'critical';\n  contextPackage: EscalationContext;\n}\n```\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `apps/gateway/src/services/conflict-resolution.service.ts` | Core resolution engine |\n| `apps/gateway/src/services/conflict-resolution.strategies.ts` | Strategy implementations |\n| `apps/gateway/src/services/confidence-scorer.ts` | Confidence calculation |\n| `apps/gateway/src/services/rationale-generator.ts` | Human-readable explanations |\n| `apps/gateway/src/interfaces/conflict-resolution.interfaces.ts` | Type definitions |\n| `libs/shared/src/types/resolution-strategies.ts` | Shared strategy types |\n\n## Testing Requirements\n\n### Unit Tests\n\n- [ ] **Strategy selection tests** (`conflict-resolution.service.spec.ts`)\n  - Test each strategy type selection logic\n  - Test strategy scoring algorithm\n  - Test prerequisite validation\n  - Test parameter generation for each strategy type\n\n- [ ] **Confidence scoring tests** (`confidence-scorer.spec.ts`)\n  - Test each evidence category contribution\n  - Test edge cases (missing data, conflicting signals)\n  - Test confidence threshold boundaries\n  - Test score normalization\n\n- [ ] **Rationale generation tests** (`rationale-generator.spec.ts`)\n  - Test template selection\n  - Test variable interpolation\n  - Test multi-language support (if applicable)\n\n### Integration Tests\n\n- [ ] **Mock conflict resolution** (`conflict-resolution.integration.spec.ts`)\n  - Test full resolution flow with mocked dependencies\n  - Test CASS history integration\n  - Test BV priority fetching\n  - Test checkpoint progress integration\n\n- [ ] **Auto-resolution triggers** (`auto-resolution.integration.spec.ts`)\n  - Test auto-resolution eligibility checking\n  - Test auto-resolution execution\n  - Test notification dispatch on auto-resolution\n\n### E2E Tests\n\n- [ ] **Resolution workflow** (`conflict-resolution.e2e.spec.ts`)\n  - Test conflict detection -\u003e resolution suggestion -\u003e application\n  - Test resolution rejection and re-suggestion\n  - Test escalation workflow end-to-end\n  - Test resolution expiration handling\n\n## Logging Requirements\n\n### Resolution Decision Audit Trail\n\nAll resolution decisions must be logged for accountability:\n\n```typescript\nlogger.info('Resolution suggestion generated', {\n  correlationId: request.correlationId,\n  conflictId: conflict.id,\n  recommendedStrategy: suggestion.recommendedStrategy.type,\n  confidence: suggestion.confidence,\n  autoResolutionEligible: suggestion.autoResolutionEligible,\n  inputSources: {\n    bvPriorityAvailable: true,\n    checkpointProgressAvailable: true,\n    cassHistoryRecords: 25,\n    activeReservations: 2\n  },\n  processingTimeMs: elapsed\n});\n```\n\n### Confidence Score Breakdown Logging\n\n```typescript\nlogger.debug('Confidence score calculated', {\n  correlationId: request.correlationId,\n  conflictId: conflict.id,\n  finalScore: 87,\n  breakdown: {\n    priorityDifferential: 18,\n    progressCertainty: 12,\n    historicalMatch: 22,\n    resourceCriticality: 15,\n    timePressure: 20\n  },\n  adjustments: [\n    { reason: 'missing_cass_data', delta: -5 },\n    { reason: 'high_stakes_resource', delta: +5 }\n  ]\n});\n```\n\n## Acceptance Criteria\n\n- [ ] Resolution engine accepts ConflictResolutionRequest and returns ResolutionSuggestion\n- [ ] All five strategy types (wait, split, transfer, coordinate, escalate) implemented\n- [ ] Confidence scores calculated with evidence breakdown\n- [ ] Auto-resolution triggers for eligible low-risk conflicts\n- [ ] Human-readable rationales generated for all suggestions\n- [ ] Resolution suggestions expire when conflict state changes\n- [ ] Full audit trail logged for all resolution decisions\n- [ ] Unit test coverage \u003e= 90% for resolution service\n- [ ] Integration tests pass with mock conflict scenarios\n- [ ] E2E tests verify complete resolution workflow\n\n## References\n\n- PLAN.md §12.6 - Conflict Resolution Strategies\n- Related: flywheel_gateway-3b0 (Resource Conflict Detection)\n- Related: flywheel_gateway-2ph (Checkpoint service)\n- Related: flywheel_gateway-2pj (CASS service)\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] ConflictAnalyzer: detects conflicting changes\n- [ ] ConflictAnalyzer: classifies conflict type\n- [ ] SemanticMerger: understands code semantics\n- [ ] SemanticMerger: suggests merge strategy\n- [ ] AutoResolver: applies simple rules\n- [ ] AutoResolver: respects user preferences\n- [ ] Conflict types: add/add classified\n- [ ] Conflict types: edit/edit classified\n- [ ] Conflict types: edit/delete classified\n- [ ] Merge suggestions: include both changes\n- [ ] Merge suggestions: prefer newer for imports\n- [ ] Merge suggestions: combine for additive changes\n- [ ] Confidence scoring: high for simple conflicts\n- [ ] Confidence scoring: low for complex conflicts\n\n### Integration Tests\n- [ ] POST /conflicts/:id/analyze returns suggestions\n- [ ] POST /conflicts/:id/resolve applies resolution\n- [ ] Auto-resolution applied when enabled\n- [ ] User preference learned from choices\n- [ ] Resolution appears in history\n- [ ] WebSocket conflict.resolved event\n\n### E2E Tests\n- [ ] Conflict detected in UI\n- [ ] Suggestions displayed with confidence\n- [ ] User selects resolution\n- [ ] Resolution applied to files\n- [ ] Future similar conflicts auto-resolved\n\n### Performance Tests\n- [ ] Conflict analysis \u003c500ms\n- [ ] Merge suggestion \u003c1s\n- [ ] Auto-resolution \u003c100ms\n- [ ] Large file conflict handled\n\n### Failure Mode Tests\n- [ ] Unresolvable conflict: marked as manual\n- [ ] AI service unavailable: basic suggestions\n- [ ] File deleted during resolution: error\n- [ ] Resolution creates new conflict: detected","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:48:10.416090079-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:56:21.596538604-05:00","dependencies":[{"issue_id":"flywheel_gateway-3b1","depends_on_id":"flywheel_gateway-msz","type":"blocks","created_at":"2026-01-08T14:01:50.535686399-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-3b1","depends_on_id":"flywheel_gateway-c4z","type":"blocks","created_at":"2026-01-08T14:01:51.629510079-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-3fq","title":"task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:46:53.040571068-05:00","created_by":"ubuntu","updated_at":"2026-01-08T14:00:25.40966292-05:00","closed_at":"2026-01-08T14:00:25.40966292-05:00","close_reason":"Empty placeholder beads created in error"}
{"id":"flywheel_gateway-41h","title":"CAAM Account Management (BYOA + Rotation)","description":"\n## Testing Requirements\n\n### Unit Tests\n- [ ] Account encryption/decryption roundtrips correctly\n- [ ] Pool rotation selects next healthy account\n- [ ] Rate limit detection parses provider responses\n- [ ] OAuth state generation is cryptographically secure\n\n### Integration Tests\n- [ ] Account linking flow completes successfully\n- [ ] Profile activation updates database\n- [ ] Cooldown status is enforced\n- [ ] Pool membership queries work correctly\n\n### E2E Tests\n- [ ] User can link an Anthropic account via device code\n- [ ] User can see account health status\n- [ ] User can rotate accounts manually\n\n### Security Tests\n- [ ] API keys are never logged\n- [ ] API keys are never returned in API responses (only masked)\n- [ ] Encryption key rotation works without data loss\n- [ ] OAuth PKCE flow is implemented correctly\n\n\n\n## Acceptance Criteria\n\n- [ ] Account records can be created/updated/disabled with encrypted-at-rest secrets and safe redaction in logs\n- [ ] Rotation strategy selects a healthy account deterministically (round-robin / least-recent / policy-based) and respects cooldowns\n- [ ] Provider failures are classified into actionable error codes (retryable vs terminal) with recovery hints\n- [ ] BYOA gating is enforced for execution paths that require provider credentials\n- [ ] Audit log captures all mutations (create/update/disable/rotate) with correlation IDs\n- [ ] UI flow makes it hard to misconfigure accounts and provides clear health/status indicators\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Account: encrypts API key at rest\n- [ ] Account: decrypts for use\n- [ ] Account: tracks quota usage\n- [ ] Account: calculates quota remaining\n- [ ] Rotation: selects next account\n- [ ] Rotation: respects priority order\n- [ ] Rotation: skips exhausted accounts\n- [ ] HealthCheck: validates credentials\n- [ ] HealthCheck: measures latency\n- [ ] BYOA: validates account format\n- [ ] BYOA: gates on verification\n- [ ] ProfileVault: manages multiple accounts\n\n### Integration Tests\n- [ ] POST /accounts creates account\n- [ ] GET /accounts lists accounts\n- [ ] PUT /accounts/:id updates account\n- [ ] DELETE /accounts/:id removes account\n- [ ] Rotation triggers on rate limit\n- [ ] Rotation triggers on quota exhausted\n- [ ] Health check runs periodically\n- [ ] BYOA required before agent spawn\n\n### E2E Tests\n- [ ] User adds BYOA account\n- [ ] Account used for agent spawn\n- [ ] Rate limit triggers rotation\n- [ ] Unhealthy account skipped\n\n### Performance Tests\n- [ ] Account selection \u003c10ms\n- [ ] Rotation \u003c100ms\n- [ ] Health check \u003c1s\n- [ ] Encryption/decryption \u003c5ms\n\n### Failure Mode Tests\n- [ ] All accounts exhausted: queue requests\n- [ ] Invalid credentials: mark unhealthy\n- [ ] Decryption fails: alert and disable\n- [ ] Rotation loop: circuit breaker","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:37:55.797237862-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:58:03.333093614-05:00","dependencies":[{"issue_id":"flywheel_gateway-41h","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:57.589329614-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-41h","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T14:01:59.825762362-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-41h","depends_on_id":"flywheel_gateway-r3p","type":"blocks","created_at":"2026-01-08T18:34:32.056040751-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-45c","title":"Context Pack Builder with Token Budgeting","description":"## Background\n\nThe Context Pack Builder is the core orchestration component that assembles optimized context for agent prompts. It pulls from multiple data sources (Bead Valuation, Collective Memory, CASS) and intelligently allocates token budget to maximize prompt effectiveness while respecting model limits.\n\n### Why This Matters\n\n1. **Agent Effectiveness**: Agents perform better with relevant, well-structured context. Random or poorly-prioritized context leads to confusion and errors.\n\n2. **Token Efficiency**: Model context windows are expensive. Every token must earn its place through relevance and utility.\n\n3. **Dynamic Adaptation**: Different tasks require different context mixes. A debugging task needs error history; a planning task needs project structure.\n\n4. **Budget Compliance**: Exceeding context limits causes truncation or errors. Strict budget management ensures predictable behavior.\n\n## Technical Design\n\n### Context Pack Structure\n\n```typescript\ninterface ContextPack {\n  id: string;                    // ULID for tracking\n  sessionId: string;\n  createdAt: Date;\n  \n  // Budget tracking\n  budget: {\n    total: number;               // Total tokens available\n    used: number;                // Tokens used\n    remaining: number;           // Tokens remaining\n    breakdown: TokenBreakdown;   // Per-section allocation\n  };\n  \n  // Context sections\n  sections: {\n    triage: TriageSection;       // From Bead Valuation\n    memory: MemorySection;       // From Collective Memory\n    search: SearchSection;       // From CASS\n    history: HistorySection;     // Recent conversation\n    system: SystemSection;       // System prompts\n  };\n  \n  // Metadata\n  metadata: {\n    buildTimeMs: number;\n    sourcesQueried: string[];\n    truncations: TruncationRecord[];\n  };\n}\n\ninterface TokenBreakdown {\n  system: number;                // System prompt allocation\n  triage: number;                // Triage beads allocation\n  memory: number;                // Memory rules allocation\n  search: number;                // Search results allocation\n  history: number;               // Conversation history allocation\n  reserved: number;              // Reserved for response\n}\n```\n\n### Token Budget Allocation Strategy\n\n```typescript\ninterface BudgetStrategy {\n  // Fixed allocations (absolute tokens)\n  fixed: {\n    system: number;              // System prompt, typically 500-1000\n    reserved: number;            // Response buffer, typically 2000-4000\n  };\n  \n  // Proportional allocations (% of remaining)\n  proportional: {\n    triage: number;              // Default: 0.30 (30%)\n    memory: number;              // Default: 0.20 (20%)\n    search: number;              // Default: 0.25 (25%)\n    history: number;             // Default: 0.25 (25%)\n  };\n  \n  // Minimum allocations (floor)\n  minimums: {\n    triage: number;              // At least 500 tokens\n    memory: number;              // At least 300 tokens\n    search: number;              // At least 500 tokens\n    history: number;             // At least 1000 tokens\n  };\n  \n  // Priority order for overflow redistribution\n  priority: ('triage' | 'memory' | 'search' | 'history')[];\n}\n\n// Default strategy\nconst defaultStrategy: BudgetStrategy = {\n  fixed: { system: 800, reserved: 3000 },\n  proportional: { triage: 0.30, memory: 0.20, search: 0.25, history: 0.25 },\n  minimums: { triage: 500, memory: 300, search: 500, history: 1000 },\n  priority: ['triage', 'history', 'search', 'memory']\n};\n\nfunction allocateBudget(\n  totalTokens: number,\n  strategy: BudgetStrategy\n): TokenBreakdown {\n  const available = totalTokens - strategy.fixed.system - strategy.fixed.reserved;\n  \n  // Initial proportional allocation\n  let allocation = {\n    system: strategy.fixed.system,\n    reserved: strategy.fixed.reserved,\n    triage: Math.floor(available * strategy.proportional.triage),\n    memory: Math.floor(available * strategy.proportional.memory),\n    search: Math.floor(available * strategy.proportional.search),\n    history: Math.floor(available * strategy.proportional.history)\n  };\n  \n  // Apply minimums\n  for (const key of ['triage', 'memory', 'search', 'history'] as const) {\n    allocation[key] = Math.max(allocation[key], strategy.minimums[key]);\n  }\n  \n  // Redistribute overflow by priority\n  let used = Object.values(allocation).reduce((a, b) =\u003e a + b, 0);\n  let overflow = used - totalTokens;\n  \n  if (overflow \u003e 0) {\n    // Take from lowest priority first\n    const reversePriority = [...strategy.priority].reverse();\n    for (const key of reversePriority) {\n      const reduction = Math.min(overflow, allocation[key] - strategy.minimums[key]);\n      allocation[key] -= reduction;\n      overflow -= reduction;\n      if (overflow \u003c= 0) break;\n    }\n  }\n  \n  return allocation;\n}\n```\n\n### Triage Section (Bead Valuation Integration)\n\n```typescript\ninterface TriageSection {\n  beads: TriagedBead[];\n  totalTokens: number;\n  truncated: boolean;\n  metadata: {\n    totalAvailable: number;      // Total ready beads in BV\n    included: number;            // Beads included in pack\n    topScore: number;            // Highest valuation score\n    avgScore: number;            // Average score of included\n  };\n}\n\ninterface TriagedBead {\n  id: string;\n  type: BeadType;\n  title: string;\n  content: string;               // May be summarized if large\n  score: number;                 // Valuation score\n  tokens: number;\n  reason: string;                // Why this bead is relevant\n}\n\nasync function buildTriageSection(\n  sessionId: string,\n  tokenBudget: number,\n  options: TriageOptions\n): Promise\u003cTriageSection\u003e {\n  // Query BV for top-scored ready beads\n  const beads = await beadValuation.getTopBeads({\n    sessionId,\n    status: 'ready',\n    limit: options.maxBeads || 20,\n    minScore: options.minScore || 0.5\n  });\n  \n  const section: TriageSection = {\n    beads: [],\n    totalTokens: 0,\n    truncated: false,\n    metadata: {\n      totalAvailable: beads.length,\n      included: 0,\n      topScore: beads[0]?.score || 0,\n      avgScore: 0\n    }\n  };\n  \n  // Pack beads within budget\n  for (const bead of beads) {\n    const beadTokens = await tokenizer.count(formatBead(bead));\n    \n    if (section.totalTokens + beadTokens \u003e tokenBudget) {\n      // Try summarization\n      const summarized = await summarizeBead(bead, tokenBudget - section.totalTokens);\n      if (summarized) {\n        section.beads.push(summarized);\n        section.totalTokens += summarized.tokens;\n        section.metadata.included++;\n      }\n      section.truncated = true;\n      break;\n    }\n    \n    section.beads.push({\n      id: bead.id,\n      type: bead.type,\n      title: bead.title,\n      content: bead.content,\n      score: bead.score,\n      tokens: beadTokens,\n      reason: bead.valuationReason\n    });\n    section.totalTokens += beadTokens;\n    section.metadata.included++;\n  }\n  \n  section.metadata.avgScore = section.beads.reduce((s, b) =\u003e s + b.score, 0) / section.beads.length;\n  return section;\n}\n```\n\n### Memory Section (Collective Memory Integration)\n\n```typescript\ninterface MemorySection {\n  rules: MemoryRule[];\n  totalTokens: number;\n  categories: string[];\n  metadata: {\n    totalRulesMatched: number;\n    rulesIncluded: number;\n    matchedCategories: string[];\n  };\n}\n\ninterface MemoryRule {\n  id: string;\n  category: string;\n  content: string;\n  priority: number;\n  tokens: number;\n  applicability: number;         // 0-1 relevance score\n}\n\nasync function buildMemorySection(\n  sessionId: string,\n  taskContext: string,\n  tokenBudget: number\n): Promise\u003cMemorySection\u003e {\n  // Query CM for relevant rules\n  const rules = await collectiveMemory.queryRules({\n    context: taskContext,\n    categories: ['coding', 'project', 'style', 'process'],\n    limit: 50\n  });\n  \n  // Score rules by applicability to current task\n  const scoredRules = await Promise.all(\n    rules.map(async (rule) =\u003e ({\n      ...rule,\n      applicability: await scoreApplicability(rule, taskContext)\n    }))\n  );\n  \n  // Sort by priority * applicability\n  scoredRules.sort((a, b) =\u003e \n    (b.priority * b.applicability) - (a.priority * a.applicability)\n  );\n  \n  const section: MemorySection = {\n    rules: [],\n    totalTokens: 0,\n    categories: [],\n    metadata: {\n      totalRulesMatched: scoredRules.length,\n      rulesIncluded: 0,\n      matchedCategories: []\n    }\n  };\n  \n  // Pack rules within budget\n  const seenCategories = new Set\u003cstring\u003e();\n  \n  for (const rule of scoredRules) {\n    const ruleTokens = await tokenizer.count(rule.content);\n    \n    if (section.totalTokens + ruleTokens \u003e tokenBudget) {\n      break;\n    }\n    \n    section.rules.push({\n      id: rule.id,\n      category: rule.category,\n      content: rule.content,\n      priority: rule.priority,\n      tokens: ruleTokens,\n      applicability: rule.applicability\n    });\n    section.totalTokens += ruleTokens;\n    section.metadata.rulesIncluded++;\n    seenCategories.add(rule.category);\n  }\n  \n  section.categories = Array.from(seenCategories);\n  section.metadata.matchedCategories = section.categories;\n  \n  return section;\n}\n```\n\n### Search Section (CASS Integration)\n\n```typescript\ninterface SearchSection {\n  results: SearchResult[];\n  totalTokens: number;\n  query: string;\n  metadata: {\n    totalMatches: number;\n    includedMatches: number;\n    searchTimeMs: number;\n  };\n}\n\ninterface SearchResult {\n  id: string;\n  source: string;                // File path or document ID\n  content: string;               // Relevant snippet\n  score: number;                 // Semantic similarity score\n  tokens: number;\n  context: string;               // Surrounding context\n}\n\nasync function buildSearchSection(\n  query: string,\n  tokenBudget: number,\n  options: SearchOptions\n): Promise\u003cSearchSection\u003e {\n  const startTime = Date.now();\n  \n  // Query CASS for semantically similar content\n  const results = await cass.search({\n    query,\n    limit: options.maxResults || 10,\n    threshold: options.minScore || 0.7,\n    sources: options.sources || ['codebase', 'docs', 'history']\n  });\n  \n  const section: SearchSection = {\n    results: [],\n    totalTokens: 0,\n    query,\n    metadata: {\n      totalMatches: results.length,\n      includedMatches: 0,\n      searchTimeMs: Date.now() - startTime\n    }\n  };\n  \n  // Pack results within budget\n  for (const result of results) {\n    const resultTokens = await tokenizer.count(formatSearchResult(result));\n    \n    if (section.totalTokens + resultTokens \u003e tokenBudget) {\n      // Try to include truncated snippet\n      const truncated = truncateResult(result, tokenBudget - section.totalTokens);\n      if (truncated) {\n        section.results.push(truncated);\n        section.totalTokens += truncated.tokens;\n        section.metadata.includedMatches++;\n      }\n      break;\n    }\n    \n    section.results.push({\n      id: result.id,\n      source: result.source,\n      content: result.content,\n      score: result.score,\n      tokens: resultTokens,\n      context: result.context\n    });\n    section.totalTokens += resultTokens;\n    section.metadata.includedMatches++;\n  }\n  \n  return section;\n}\n```\n\n### Context Pack Builder Service\n\n```typescript\nclass ContextPackBuilder {\n  constructor(\n    private beadValuation: BeadValuationService,\n    private collectiveMemory: CollectiveMemoryService,\n    private cass: CASSService,\n    private tokenizer: TokenizerService\n  ) {}\n  \n  async build(request: ContextPackRequest): Promise\u003cContextPack\u003e {\n    const startTime = Date.now();\n    \n    // Determine total budget\n    const totalBudget = request.maxTokens || this.getModelLimit(request.model);\n    \n    // Allocate budget\n    const breakdown = allocateBudget(totalBudget, request.strategy || defaultStrategy);\n    \n    // Build sections in parallel\n    const [triage, memory, search, history] = await Promise.all([\n      this.buildTriageSection(request.sessionId, breakdown.triage, request.triageOptions),\n      this.buildMemorySection(request.sessionId, request.taskContext, breakdown.memory),\n      this.buildSearchSection(request.searchQuery, breakdown.search, request.searchOptions),\n      this.buildHistorySection(request.sessionId, breakdown.history)\n    ]);\n    \n    // Assemble pack\n    const pack: ContextPack = {\n      id: ulid(),\n      sessionId: request.sessionId,\n      createdAt: new Date(),\n      budget: {\n        total: totalBudget,\n        used: breakdown.system + triage.totalTokens + memory.totalTokens + \n              search.totalTokens + history.totalTokens,\n        remaining: totalBudget - (breakdown.system + triage.totalTokens + \n                   memory.totalTokens + search.totalTokens + history.totalTokens),\n        breakdown\n      },\n      sections: {\n        triage,\n        memory,\n        search,\n        history,\n        system: await this.buildSystemSection(breakdown.system)\n      },\n      metadata: {\n        buildTimeMs: Date.now() - startTime,\n        sourcesQueried: ['bead-valuation', 'collective-memory', 'cass'],\n        truncations: this.collectTruncations(triage, memory, search, history)\n      }\n    };\n    \n    return pack;\n  }\n  \n  // Render pack to prompt format\n  render(pack: ContextPack): string {\n    return `\n${this.renderSystemSection(pack.sections.system)}\n\n## Relevant Context\n\n### Active Work Items (Triage)\n${this.renderTriageSection(pack.sections.triage)}\n\n### Project Guidelines (Memory)\n${this.renderMemorySection(pack.sections.memory)}\n\n### Related Information (Search)\n${this.renderSearchSection(pack.sections.search)}\n\n### Recent Conversation\n${this.renderHistorySection(pack.sections.history)}\n`.trim();\n  }\n}\n```\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Build context pack\nPOST /api/v1/sessions/:sessionId/context/build\nRequest: {\n  maxTokens?: number,\n  strategy?: BudgetStrategy,\n  taskContext?: string,\n  searchQuery?: string,\n  triageOptions?: TriageOptions,\n  searchOptions?: SearchOptions\n}\nResponse: ContextPack\n\n// Get current context pack\nGET /api/v1/sessions/:sessionId/context/current\nResponse: ContextPack\n\n// Preview context pack (dry run)\nPOST /api/v1/sessions/:sessionId/context/preview\nRequest: ContextPackRequest\nResponse: {\n  estimatedTokens: number,\n  breakdown: TokenBreakdown,\n  warnings: string[]\n}\n```\n\n### WebSocket Events\n\n```typescript\n// Context pack built\n{\n  event: 'context.built',\n  data: {\n    sessionId: string,\n    packId: string,\n    totalTokens: number,\n    buildTimeMs: number\n  }\n}\n\n// Budget warning\n{\n  event: 'context.budget_warning',\n  data: {\n    sessionId: string,\n    used: number,\n    total: number,\n    percentUsed: number,\n    truncatedSections: string[]\n  }\n}\n```\n\n## Configuration\n\n```typescript\ninterface ContextBuilderConfig {\n  // Default budget\n  defaultMaxTokens: number;        // Default: 100000\n  \n  // Model-specific limits\n  modelLimits: Record\u003cstring, number\u003e;\n  \n  // Default strategy\n  defaultStrategy: BudgetStrategy;\n  \n  // Caching\n  cacheTTLSeconds: number;         // Cache built packs, default: 60\n  \n  // Parallelism\n  maxConcurrentBuilds: number;     // Default: 10\n}\n```\n\n## File Locations\n\n- **Primary Service**: `apps/gateway/src/services/context.service.ts`\n- **Budget Calculator**: `apps/gateway/src/services/context-budget.service.ts`\n- **Section Builders**: `apps/gateway/src/services/context-sections/`\n  - `triage-section.builder.ts`\n  - `memory-section.builder.ts`\n  - `search-section.builder.ts`\n  - `history-section.builder.ts`\n- **Types**: `apps/gateway/src/types/context.types.ts`\n- **Controller**: `apps/gateway/src/controllers/context.controller.ts`\n- **Tests**: `apps/gateway/src/services/__tests__/context.service.test.ts`\n\n## Dependencies\n\n- Bead Valuation service (BV)\n- Collective Memory service (CM)\n- CASS semantic search service\n- Tokenizer service (tiktoken or similar)\n\n## Acceptance Criteria\n\n1. **Budget Allocation**\n   - [ ] Correctly allocates budget according to strategy\n   - [ ] Respects minimum allocations\n   - [ ] Redistributes overflow by priority\n   - [ ] Never exceeds total budget\n\n2. **Triage Integration**\n   - [ ] Queries BV for top-scored ready beads\n   - [ ] Includes beads in priority order\n   - [ ] Truncates/summarizes when over budget\n   - [ ] Includes bead metadata and reasoning\n\n3. **Memory Integration**\n   - [ ] Queries CM for relevant rules\n   - [ ] Scores applicability to current task\n   - [ ] Includes diverse categories\n   - [ ] Respects priority ordering\n\n4. **Search Integration**\n   - [ ] Queries CASS with provided query\n   - [ ] Includes results by relevance score\n   - [ ] Provides source and context\n   - [ ] Truncates large results\n\n5. **Performance**\n   - [ ] Builds context pack in \u003c500ms for typical session\n   - [ ] Parallel section building\n   - [ ] Caches results appropriately\n\n6. **Observability**\n   - [ ] Reports build time and token breakdown\n   - [ ] Emits WebSocket events\n   - [ ] Logs truncation decisions\n\n## Reference\n\n- PLAN.md Section 7.4 - Context Pack Structure\n- PLAN.md Section 7.5 - Token Budget Management\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Token budget allocation matches configured percentages and never exceeds total budget\n- [ ] Overflow truncation produces valid JSON/text and preserves required fields\n- [ ] Cache keying is stable (same inputs → same key) and invalidates on repoRev/inputs change\n- [ ] Rendering format switches correctly by agent type (XML vs Markdown)\n\n### Integration Tests\n- [ ] With adapters stubbed: triage/cm/cass/s2p components appear in correct order and within budget\n- [ ] Missing tools (bv/cm/cass/s2p not installed) degrade gracefully with explicit unavailable markers\n\n### Failure Mode Tests\n- [ ] Adapter timeouts or malformed outputs are captured as component errors without failing the whole build\n\n### Logging\n- [ ] Logs include correlationId + packId + component timings + token counts; content is truncated/redacted\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] TokenBudget: initializes with total limit\n- [ ] TokenBudget: allocates to categories\n- [ ] TokenBudget: tracks used tokens\n- [ ] TokenBudget: remaining calculation correct\n- [ ] SourcePriority: enum values ordered correctly\n- [ ] SourcePriority: higher priority \u003e lower priority\n- [ ] ContextSource: stores content and metadata\n- [ ] ContextSource: estimates tokens accurately (±5%)\n- [ ] ContextPack: adds sources in priority order\n- [ ] ContextPack: respects budget limit\n- [ ] ContextPack: includes required sources first\n- [ ] ContextPack: truncates overflow sources intelligently\n- [ ] ContextBuilder: gathers sources from all providers\n- [ ] ContextBuilder: deduplicates identical sources\n- [ ] ContextBuilder: applies relevance scoring\n- [ ] Relevance scoring: recent files score higher\n- [ ] Relevance scoring: mentioned files score higher\n- [ ] Relevance scoring: dependency files included\n\n### Integration Tests\n- [ ] Build context for agent with real files\n- [ ] Token budget respected in output\n- [ ] Priority sources always included\n- [ ] Large files truncated appropriately\n- [ ] Bead references included as context\n- [ ] CASS snippets included when relevant\n- [ ] CM rules included at top\n- [ ] Git diff included for dirty files\n\n### E2E Tests\n- [ ] Agent receives built context pack\n- [ ] Context pack improves agent performance (qualitative)\n- [ ] Rotation preserves relevant context\n\n### Performance Tests\n- [ ] Build context pack \u003c500ms for typical repo\n- [ ] Token counting \u003c10ms per file\n- [ ] Large repo (10k files) completes \u003c5s\n- [ ] Memory usage stays bounded\n\n### Failure Mode Tests\n- [ ] Missing file: skip with warning\n- [ ] Binary file: exclude with note\n- [ ] Token limit exceeded: truncation works\n- [ ] Empty sources: valid empty pack returned","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:43:01.907053609-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:04:37.169278931-05:00","dependencies":[{"issue_id":"flywheel_gateway-45c","depends_on_id":"flywheel_gateway-398","type":"blocks","created_at":"2026-01-08T14:01:50.966927902-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-46c","title":"FEAT: WebSocket Infrastructure with Durable Ring Buffers","description":"## Background\n\nReal-time communication is essential for the Flywheel Gateway. Clients need instant updates when:\n- Agent output streams in (stdout, stderr, tool results)\n- Agent state changes (ready, executing, terminated)\n- Conflicts arise requiring human resolution\n- Mail arrives from other agents\n- Reservations are acquired or released\n\nWebSocket connections are inherently unreliable - networks drop, clients reconnect. The ring buffer system ensures no messages are lost during brief disconnections by allowing cursor-based replay.\n\n## Technical Rationale\n\n### Why Ring Buffers?\n- **Bounded Memory**: Fixed-size buffers prevent memory exhaustion from slow consumers\n- **Fast Replay**: Clients reconnecting after brief disconnects get caught up instantly\n- **Cursor-Based**: Opaque cursors allow stateless servers (cursor encodes position)\n- **TTL Expiry**: Old messages automatically expire, keeping buffers fresh\n\n### Why Per-Channel Buffers?\n- **Isolation**: High-volume channels (output) don't starve low-volume ones (conflicts)\n- **Tuning**: Different channels can have different buffer sizes and TTLs\n- **Permissions**: Subscription authorization is per-channel\n\n### Hub Architecture\nThe WebSocket hub acts as a message broker:\n1. Publishers (drivers, API handlers) push messages to topics\n2. Hub fans out to all subscribed connections\n3. Each channel maintains its own ring buffer\n4. Connections track their cursor per channel\n\n## Scope \u0026 Requirements\n\n### WebSocket Hub\n\n```typescript\ninterface WebSocketHub {\n  // Connection management\n  addConnection(ws: WebSocket, auth: AuthContext): ConnectionHandle;\n  removeConnection(connectionId: string): void;\n  \n  // Subscriptions\n  subscribe(connectionId: string, channel: Channel, cursor?: string): void;\n  unsubscribe(connectionId: string, channel: Channel): void;\n  \n  // Publishing\n  publish(channel: Channel, message: HubMessage): void;\n  \n  // Replay\n  replay(channel: Channel, cursor: string, limit?: number): HubMessage[];\n  \n  // Monitoring\n  getStats(): HubStats;\n}\n\ninterface ConnectionHandle {\n  connectionId: string;\n  connectedAt: Date;\n  subscriptions: Set\u003cChannel\u003e;\n  lastHeartbeat: Date;\n  cursor: Map\u003cChannel, string\u003e;\n}\n\ninterface HubStats {\n  activeConnections: number;\n  subscriptionsByChannel: Map\u003cChannel, number\u003e;\n  messagesPerSecond: number;\n  bufferUtilization: Map\u003cChannel, number\u003e;\n}\n```\n\n### Channel Types\n\n```typescript\ntype Channel = \n  // Agent-scoped channels\n  | { type: 'agent:output'; agentId: string }\n  | { type: 'agent:state'; agentId: string }\n  | { type: 'agent:tools'; agentId: string }\n  \n  // Tenant-scoped channels\n  | { type: 'workspace:agents'; workspaceId: string }\n  | { type: 'workspace:reservations'; workspaceId: string }\n  | { type: 'workspace:conflicts'; workspaceId: string }\n  \n  // User-scoped channels\n  | { type: 'user:mail'; userId: string }\n  | { type: 'user:notifications'; userId: string }\n  \n  // System channels\n  | { type: 'system:health' }\n  | { type: 'system:metrics' };\n\n// Channel string format: \"type:id\" e.g., \"agent:output:agent-abc123\"\nfunction channelToString(channel: Channel): string;\nfunction parseChannel(str: string): Channel;\n```\n\n### Ring Buffer Implementation\n\n```typescript\ninterface RingBuffer\u003cT\u003e {\n  capacity: number;\n  ttlMs: number;\n  \n  push(item: T): string;              // Returns cursor\n  get(cursor: string): T | undefined;\n  slice(cursor: string, limit?: number): T[];\n  getLatestCursor(): string;\n  \n  // Maintenance\n  prune(): number;                    // Remove expired, return count\n  clear(): void;\n  \n  // Stats\n  size(): number;\n  oldestCursor(): string | undefined;\n}\n\n// Cursor format: base64(timestamp:sequence)\n// Allows cursor comparison without buffer access\ninterface CursorData {\n  timestamp: number;\n  sequence: number;\n}\n\nfunction encodeCursor(data: CursorData): string;\nfunction decodeCursor(cursor: string): CursorData;\nfunction compareCursors(a: string, b: string): -1 | 0 | 1;\n```\n\n### Buffer Configuration Per Channel Type\n\n```typescript\nconst BUFFER_CONFIG: Record\u003cstring, BufferConfig\u003e = {\n  'agent:output': {\n    capacity: 10000,    // High volume, many messages\n    ttlMs: 300000,      // 5 minutes - reconnect window\n  },\n  'agent:state': {\n    capacity: 100,      // Low volume\n    ttlMs: 3600000,     // 1 hour - state history\n  },\n  'workspace:conflicts': {\n    capacity: 500,\n    ttlMs: 1800000,     // 30 minutes\n  },\n  'user:mail': {\n    capacity: 1000,\n    ttlMs: 86400000,    // 24 hours - important messages\n  },\n  'system:health': {\n    capacity: 60,       // 1 per second\n    ttlMs: 60000,       // 1 minute\n  },\n};\n```\n\n### Message Format\n\n```typescript\ninterface HubMessage {\n  id: string;                    // UUID for deduplication\n  cursor: string;                // Ring buffer cursor\n  timestamp: Date;\n  channel: string;               // Serialized channel\n  \n  type: MessageType;\n  payload: unknown;              // Type-specific payload\n  \n  metadata?: {\n    correlationId?: string;\n    agentId?: string;\n    userId?: string;\n    workspaceId?: string;\n  };\n}\n\ntype MessageType =\n  | 'output.chunk'\n  | 'state.change'\n  | 'tool.start'\n  | 'tool.end'\n  | 'reservation.acquired'\n  | 'reservation.released'\n  | 'conflict.detected'\n  | 'conflict.resolved'\n  | 'mail.received'\n  | 'health.ping'\n  | 'error';\n```\n\n### Heartbeat Protocol\n\n```typescript\n// Client sends ping every 30 seconds\ninterface PingMessage {\n  type: 'ping';\n  timestamp: number;\n}\n\n// Server responds with pong + connection stats\ninterface PongMessage {\n  type: 'pong';\n  timestamp: number;\n  serverTime: number;\n  subscriptions: string[];\n  cursors: Record\u003cstring, string\u003e;\n}\n\n// Server sends heartbeat every 30 seconds to all connections\ninterface HeartbeatMessage {\n  type: 'heartbeat';\n  serverTime: number;\n}\n\n// Connection considered dead after 90 seconds without ping\nconst HEARTBEAT_INTERVAL = 30000;\nconst CONNECTION_TIMEOUT = 90000;\n```\n\n### Reconnection Flow\n\n```typescript\n// 1. Client connects with last known cursors\ninterface ReconnectRequest {\n  type: 'reconnect';\n  cursors: Record\u003cstring, string\u003e;  // channel -\u003e cursor\n}\n\n// 2. Server validates cursors, replays missed messages\ninterface ReconnectResponse {\n  type: 'reconnect_ack';\n  replayed: Record\u003cstring, number\u003e; // channel -\u003e message count\n  expired: string[];                // channels where cursor expired\n  newCursors: Record\u003cstring, string\u003e;\n}\n\n// 3. If cursor expired, client can either:\n//    a. Accept current cursor (lose messages)\n//    b. Re-fetch state via REST API\n```\n\n### Authorization\n\n```typescript\ninterface ChannelAuthorization {\n  canSubscribe(auth: AuthContext, channel: Channel): boolean;\n  canPublish(auth: AuthContext, channel: Channel): boolean;\n}\n\n// Example rules:\n// - agent:output:X requires read access to agent X\n// - workspace:conflicts:X requires workspace X membership\n// - user:mail:X requires being user X\n// - system:health requires authenticated connection\n```\n\n## File Structure\n\n```\napps/gateway/src/ws/\n├── index.ts                 # Public exports\n├── hub.ts                   # WebSocketHub implementation\n├── connection.ts            # Connection lifecycle management\n├── channels.ts              # Channel types and parsing\n├── ring-buffer.ts           # Generic ring buffer implementation\n├── cursor.ts                # Cursor encoding/decoding\n├── heartbeat.ts             # Heartbeat manager\n├── authorization.ts         # Channel access control\n├── messages.ts              # Message type definitions\n├── reconnect.ts             # Reconnection handling\n└── __tests__/\n    ├── hub.test.ts\n    ├── ring-buffer.test.ts\n    ├── cursor.test.ts\n    └── reconnect.test.ts\n```\n\n## References\n\n- PLAN.md §9 - WebSocket Architecture\n- PLAN.md §9.3 - Ring Buffer Specification\n- RFC 6455 - The WebSocket Protocol\n\n## Acceptance Criteria\n\n- [ ] WebSocketHub manages connections with add/remove/subscribe/unsubscribe\n- [ ] Ring buffer implements push, get, slice with cursor-based access\n- [ ] Cursor encoding/decoding is stable and comparable\n- [ ] Per-channel buffer configuration is tunable\n- [ ] Heartbeat protocol keeps connections alive\n- [ ] Dead connections are cleaned up after timeout\n- [ ] Reconnection replays missed messages within buffer window\n- [ ] Expired cursors are detected and reported\n- [ ] Channel authorization enforces access control\n- [ ] Message deduplication prevents double delivery\n- [ ] Hub stats expose connection and buffer metrics\n- [ ] Memory bounded by buffer capacity limits\n- [ ] Unit tests for ring buffer edge cases (wrap-around, TTL expiry)\n- [ ] Integration tests for reconnection scenarios\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] RingBuffer: push returns cursor\n- [ ] RingBuffer: get with valid cursor returns item\n- [ ] RingBuffer: get with invalid cursor returns undefined\n- [ ] RingBuffer: slice returns items from cursor\n- [ ] RingBuffer: prune removes expired items\n- [ ] RingBuffer: respects capacity limit\n- [ ] Cursor encoding: encodes timestamp and sequence\n- [ ] Cursor decoding: decodes valid cursor\n- [ ] Cursor comparison: compares cursors correctly\n- [ ] Channel parsing: parses agent:output:id format\n- [ ] Channel stringification: converts channel to string\n- [ ] Hub: addConnection assigns connectionId\n- [ ] Hub: removeConnection cleans up subscriptions\n- [ ] Hub: subscribe adds channel to connection\n- [ ] Hub: unsubscribe removes channel from connection\n- [ ] Hub: publish fans out to all subscribers\n- [ ] Hub: replay returns messages from cursor\n- [ ] Heartbeat: sends ping every interval\n- [ ] Heartbeat: detects dead connections after timeout\n- [ ] Authorization: canSubscribe checks agent access\n- [ ] Authorization: canPublish checks workspace membership\n\n### Integration Tests\n- [ ] WebSocket connection establishes with auth token\n- [ ] Subscribe to agent:output channel receives messages\n- [ ] Publish to channel fans out to all subscribers\n- [ ] Reconnect with cursor replays missed messages\n- [ ] Expired cursor returns reconnect_ack with expired list\n- [ ] Heartbeat ping/pong maintains connection\n- [ ] Connection timeout after missed heartbeats\n- [ ] Buffer configuration per channel type is respected\n\n### E2E Tests\n- [ ] Agent spawn triggers event on agents channel\n- [ ] Agent output streams to subscribed clients\n- [ ] Multiple clients receive same messages\n- [ ] Client disconnect and reconnect resumes from cursor\n- [ ] Browser closes and reopens: cursor-based resume works\n\n### Performance Tests\n- [ ] Hub handles 1000 concurrent connections\n- [ ] Message fanout to 100 subscribers \u003c10ms\n- [ ] Ring buffer push/get \u003c1ms\n- [ ] Cursor replay of 100 messages \u003c5ms\n\n### Failure Mode Tests\n- [ ] Invalid auth token rejects connection\n- [ ] Unauthorized channel subscription returns error\n- [ ] Buffer overflow: oldest messages evicted, cursor valid\n- [ ] Hub memory usage stays bounded under load\n\n### Logging\n- [ ] WS tests log: connectionId, channel, cursor (and correlationId when present)\n- [ ] Reconnect tests log: replay counts and expired cursors for diagnosis\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:32:58.400525873-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:32:31.008464027-05:00","labels":["foundation","phase-1","websocket"],"dependencies":[{"issue_id":"flywheel_gateway-46c","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T14:01:44.300350453-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-46c","depends_on_id":"flywheel_gateway-d18","type":"blocks","created_at":"2026-01-08T14:01:45.028521689-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-4ub","title":"CAAM auth UX follow-ups (device-code, import/upload guidance, BYOA onboarding copy)","description":"Add UX enhancements: device-code helper prompts, secure manual auth import flow copy, clearer BYOA onboarding guidance + warnings in UI/docs.\n\n\n## Acceptance Criteria\n\n- [ ] UX provides a guided device-code flow (clear steps, copy-to-clipboard, polling status, error recovery)\n- [ ] Manual import/upload guidance is explicit about what is stored, where it is stored, and how it is redacted in logs\n- [ ] Onboarding copy explains prerequisites and common failure modes (revoked tokens, expired device codes, insufficient scopes)\n- [ ] UI makes risky actions deliberate (confirmations, safe defaults, no accidental persistence)\n- [ ] Doc changes stay aligned with the implemented UI and do not reference any private business details\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] Copy helpers and form validation (required fields, scope warnings, expired code states)\n- [ ] State machine for device-code flow (idle → pending → authorized/failed)\n\n### E2E Tests\n- [ ] Happy path onboarding (mock provider): start device-code → confirm authorized → account becomes healthy\n- [ ] Failure modes: expired code, revoked token, missing scope → UI shows actionable recovery steps\n\n### Logging\n- [ ] Test logs include correlationId + anonymized accountId; secrets are never logged\n","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T10:49:20.040334292-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:58:49.146402518-05:00","dependencies":[{"issue_id":"flywheel_gateway-4ub","depends_on_id":"flywheel_gateway-6pm","type":"discovered-from","created_at":"2026-01-08T10:49:20.063417945-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-4ub","depends_on_id":"flywheel_gateway-41h","type":"blocks","created_at":"2026-01-08T18:34:37.111337615-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-59c","title":"Comprehensive Notification System","description":"## Background\n\nEffective observability requires proactive alerting when important events occur in the system. Users should not need to constantly monitor dashboards to stay informed about agent status changes, cost anomalies, conflict resolutions, or system issues. A comprehensive notification system bridges this gap by delivering relevant information through the user's preferred channels.\n\n## Problem Statement\n\nCurrently, users must manually check the platform to discover issues or important events. This leads to delayed responses to critical situations (agent failures, cost overruns, conflicts requiring approval) and reduces overall platform effectiveness. Different users have different notification preferences - some prefer email digests while others need real-time Slack alerts for urgent issues.\n\n## Technical Approach\n\n### Notification Event Types\n\n```typescript\n// apps/gateway/src/types/notification.types.ts\n\ntype NotificationCategory = \n  | 'agent'      // Agent lifecycle events\n  | 'conflict'   // Conflict detection and resolution\n  | 'bead'       // Bead status changes\n  | 'cost'       // Cost alerts and anomalies\n  | 'system'     // System health and maintenance\n  | 'security'   // Security-related events\n  | 'team';      // Team and collaboration events\n\ninterface NotificationEvent {\n  id: string;\n  category: NotificationCategory;\n  type: NotificationEventType;\n  severity: 'info' | 'warning' | 'error' | 'critical';\n  title: string;\n  message: string;\n  data: Record\u003cstring, any\u003e; // Event-specific payload\n  actorId?: string; // User/agent that triggered event\n  targetId?: string; // Affected entity ID\n  targetType?: string; // Entity type (agent, bead, etc.)\n  orgId: string;\n  timestamp: Date;\n}\n\n// Agent events\ntype AgentEventType = \n  | 'agent.created'\n  | 'agent.started'\n  | 'agent.stopped'\n  | 'agent.error'\n  | 'agent.recovered'\n  | 'agent.rate_limited'\n  | 'agent.quota_exceeded'\n  | 'agent.config_changed';\n\n// Conflict events\ntype ConflictEventType =\n  | 'conflict.detected'\n  | 'conflict.auto_resolved'\n  | 'conflict.needs_review'\n  | 'conflict.escalated'\n  | 'conflict.resolved'\n  | 'conflict.timeout';\n\n// Cost events\ntype CostEventType =\n  | 'cost.budget_warning'     // 80% threshold\n  | 'cost.budget_critical'    // 95% threshold\n  | 'cost.budget_exceeded'\n  | 'cost.anomaly_detected'\n  | 'cost.daily_summary'\n  | 'cost.weekly_report';\n\n// System events\ntype SystemEventType =\n  | 'system.maintenance_scheduled'\n  | 'system.maintenance_started'\n  | 'system.maintenance_completed'\n  | 'system.degraded_performance'\n  | 'system.incident_started'\n  | 'system.incident_resolved'\n  | 'system.update_available';\n```\n\n### Multi-Channel Delivery Architecture\n\n```typescript\n// apps/gateway/src/services/notification.service.ts\n\ninterface NotificationService {\n  // Core dispatch\n  dispatch(event: NotificationEvent): Promise\u003cvoid\u003e;\n  dispatchBatch(events: NotificationEvent[]): Promise\u003cvoid\u003e;\n  \n  // Channel-specific\n  sendInApp(userId: string, notification: Notification): Promise\u003cvoid\u003e;\n  sendEmail(userId: string, notification: Notification): Promise\u003cvoid\u003e;\n  sendSlack(channelConfig: SlackConfig, notification: Notification): Promise\u003cvoid\u003e;\n  sendWebhook(webhookConfig: WebhookConfig, notification: Notification): Promise\u003cvoid\u003e;\n  \n  // Digest management\n  queueForDigest(userId: string, notification: Notification): Promise\u003cvoid\u003e;\n  processDigests(frequency: 'daily' | 'weekly'): Promise\u003cvoid\u003e;\n}\n\n// Channel implementations\ninterface NotificationChannel {\n  type: 'in_app' | 'email' | 'slack' | 'webhook';\n  enabled: boolean;\n  config: ChannelConfig;\n  send(notification: FormattedNotification): Promise\u003cDeliveryResult\u003e;\n}\n\ninterface SlackChannelConfig {\n  webhookUrl: string;\n  channel?: string; // Override default channel\n  username?: string;\n  iconEmoji?: string;\n  mentionUsers?: string[]; // Slack user IDs for @mentions\n  threadTs?: string; // For threaded replies\n}\n\ninterface WebhookChannelConfig {\n  url: string;\n  method: 'POST' | 'PUT';\n  headers: Record\u003cstring, string\u003e;\n  authType?: 'none' | 'basic' | 'bearer' | 'hmac';\n  authConfig?: AuthConfig;\n  retryPolicy: RetryPolicy;\n  timeout: number;\n}\n\ninterface EmailChannelConfig {\n  provider: 'sendgrid' | 'ses' | 'smtp';\n  fromAddress: string;\n  replyTo?: string;\n  templates: Map\u003cNotificationEventType, string\u003e;\n}\n```\n\n### User Notification Preferences\n\n```typescript\n// apps/gateway/src/types/preferences.types.ts\n\ninterface NotificationPreferences {\n  userId: string;\n  orgId: string;\n  \n  // Global settings\n  globalEnabled: boolean;\n  \n  // Per-category channel preferences\n  categories: {\n    [K in NotificationCategory]: CategoryPreference;\n  };\n  \n  // Quiet hours\n  quietHours: {\n    enabled: boolean;\n    timezone: string;\n    schedule: WeeklySchedule;\n    allowUrgent: boolean; // Bypass for critical notifications\n  };\n  \n  // Digest preferences\n  digest: {\n    email: {\n      enabled: boolean;\n      frequency: 'daily' | 'weekly' | 'none';\n      dayOfWeek?: number; // For weekly: 0-6\n      timeOfDay: string; // HH:mm in user timezone\n      includeCategories: NotificationCategory[];\n    };\n  };\n  \n  // Channel-specific configs\n  channels: {\n    inApp: { enabled: boolean };\n    email: { \n      enabled: boolean;\n      address?: string; // Override default\n    };\n    slack: {\n      enabled: boolean;\n      configs: SlackChannelConfig[];\n    };\n    webhooks: {\n      enabled: boolean;\n      configs: WebhookConfig[];\n    };\n  };\n}\n\ninterface CategoryPreference {\n  enabled: boolean;\n  channels: ('in_app' | 'email' | 'slack' | 'webhook')[];\n  minSeverity: 'info' | 'warning' | 'error' | 'critical';\n  // Event-specific overrides\n  eventOverrides?: {\n    [eventType: string]: {\n      enabled?: boolean;\n      channels?: string[];\n      minSeverity?: string;\n    };\n  };\n}\n\ninterface WeeklySchedule {\n  // Each day: array of quiet periods\n  [day: number]: Array\u003c{ start: string; end: string }\u003e;\n  // Example: { 0: [{ start: '22:00', end: '08:00' }] } // Sunday 10pm-8am\n}\n```\n\n### Real-Time Notification Center\n\n```typescript\n// apps/web/src/components/notifications/NotificationCenter.tsx\n\ninterface NotificationCenterState {\n  notifications: Notification[];\n  unreadCount: number;\n  isOpen: boolean;\n  filter: NotificationFilter;\n  isLoading: boolean;\n}\n\ninterface NotificationFilter {\n  categories?: NotificationCategory[];\n  severities?: string[];\n  dateRange?: { start: Date; end: Date };\n  unreadOnly?: boolean;\n  searchQuery?: string;\n}\n\n// WebSocket events for real-time updates\ninterface NotificationWebSocketEvents {\n  'notification:new': (notification: Notification) =\u003e void;\n  'notification:read': (notificationId: string) =\u003e void;\n  'notification:batch_read': (notificationIds: string[]) =\u003e void;\n  'unread_count:update': (count: number) =\u003e void;\n}\n```\n\n### Database Schema\n\n```sql\n-- Notifications table\nCREATE TABLE notifications (\n  id UUID PRIMARY KEY,\n  org_id UUID NOT NULL REFERENCES organizations(id),\n  user_id UUID NOT NULL REFERENCES users(id),\n  category VARCHAR(50) NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  severity VARCHAR(20) NOT NULL,\n  title VARCHAR(255) NOT NULL,\n  message TEXT NOT NULL,\n  data JSONB,\n  actor_id UUID,\n  target_id UUID,\n  target_type VARCHAR(50),\n  read_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  expires_at TIMESTAMPTZ -- For auto-cleanup\n);\n\n-- Indexes for common queries\nCREATE INDEX idx_notifications_user_unread \n  ON notifications(user_id, created_at DESC) \n  WHERE read_at IS NULL;\nCREATE INDEX idx_notifications_user_category \n  ON notifications(user_id, category, created_at DESC);\nCREATE INDEX idx_notifications_org \n  ON notifications(org_id, created_at DESC);\n\n-- Notification preferences\nCREATE TABLE notification_preferences (\n  user_id UUID PRIMARY KEY REFERENCES users(id),\n  org_id UUID NOT NULL REFERENCES organizations(id),\n  preferences JSONB NOT NULL,\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Digest queue for batching\nCREATE TABLE notification_digest_queue (\n  id UUID PRIMARY KEY,\n  user_id UUID NOT NULL REFERENCES users(id),\n  notification_id UUID NOT NULL REFERENCES notifications(id),\n  frequency VARCHAR(20) NOT NULL, -- 'daily' or 'weekly'\n  scheduled_for TIMESTAMPTZ NOT NULL,\n  processed_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Delivery tracking\nCREATE TABLE notification_deliveries (\n  id UUID PRIMARY KEY,\n  notification_id UUID NOT NULL REFERENCES notifications(id),\n  channel VARCHAR(50) NOT NULL,\n  status VARCHAR(20) NOT NULL, -- 'pending', 'sent', 'failed', 'retrying'\n  attempts INTEGER DEFAULT 0,\n  last_attempt_at TIMESTAMPTZ,\n  error_message TEXT,\n  delivered_at TIMESTAMPTZ,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n```\n\n### Notification Templates\n\n```typescript\n// Email templates with Handlebars\ninterface EmailTemplates {\n  'agent.error': {\n    subject: '{{severity}}: Agent \"{{agentName}}\" encountered an error';\n    body: string; // HTML template\n  };\n  \n  'cost.budget_warning': {\n    subject: 'Budget Alert: {{percentage}}% of {{budgetName}} consumed';\n    body: string; // HTML template with table\n  };\n  \n  'digest.daily': {\n    subject: 'Daily Summary - {{date}}';\n    body: string; // HTML template with category sections\n  };\n}\n```\n\n### API Endpoints\n\n```typescript\n// Notification endpoints\nGET    /api/v1/notifications                      // List notifications\nGET    /api/v1/notifications/unread-count         // Get unread count\nPOST   /api/v1/notifications/:id/read             // Mark as read\nPOST   /api/v1/notifications/mark-all-read        // Mark all as read\nDELETE /api/v1/notifications/:id                  // Delete notification\n\n// Preferences\nGET    /api/v1/notifications/preferences          // Get preferences\nPUT    /api/v1/notifications/preferences          // Update preferences\nPOST   /api/v1/notifications/test                 // Send test notification\n\n// Webhooks management\nGET    /api/v1/notifications/webhooks             // List webhooks\nPOST   /api/v1/notifications/webhooks             // Create webhook\nPUT    /api/v1/notifications/webhooks/:id         // Update webhook\nDELETE /api/v1/notifications/webhooks/:id         // Delete webhook\nPOST   /api/v1/notifications/webhooks/:id/test    // Test webhook\n\n// Slack integration\nGET    /api/v1/integrations/slack/channels        // List Slack channels\nPOST   /api/v1/integrations/slack/connect         // OAuth flow\nDELETE /api/v1/integrations/slack/disconnect      // Remove integration\n```\n\n## File Locations\n\n- apps/gateway/src/services/notification.service.ts - Core notification service\n- apps/gateway/src/services/notification-dispatcher.ts - Channel routing logic\n- apps/gateway/src/services/channels/ - Channel implementations\n  - email.channel.ts\n  - slack.channel.ts\n  - webhook.channel.ts\n  - inapp.channel.ts\n- apps/gateway/src/services/digest.service.ts - Digest processing\n- apps/gateway/src/controllers/notification.controller.ts - API controller\n- apps/gateway/src/templates/notifications/ - Email/Slack templates\n- apps/web/src/components/notifications/NotificationCenter.tsx - Main component\n- apps/web/src/components/notifications/NotificationList.tsx - List view\n- apps/web/src/components/notifications/NotificationItem.tsx - Individual item\n- apps/web/src/components/notifications/NotificationPreferences.tsx - Settings\n- apps/web/src/components/notifications/NotificationBadge.tsx - Unread badge\n- apps/web/src/hooks/useNotifications.ts - Notification state hook\n- packages/shared/src/types/notification.ts - Shared types\n\n## Dependencies\n\n- @sendgrid/mail or @aws-sdk/client-ses: Email delivery\n- @slack/web-api: Slack integration\n- handlebars: Template rendering\n- cron: Digest scheduling\n- socket.io: Real-time updates\n\n## Acceptance Criteria\n\n1. All notification event types trigger appropriate notifications\n2. In-app notifications appear in real-time via WebSocket\n3. Email notifications are delivered within 30 seconds (non-digest)\n4. Slack integration works with workspace OAuth flow\n5. Webhook delivery includes retry logic (3 attempts with exponential backoff)\n6. User preferences are respected for all notification routing\n7. Quiet hours prevent non-urgent notifications during specified times\n8. Daily/weekly digests are delivered at user-configured times\n9. Notification center shows unread badge with accurate count\n10. Mark as read/unread works individually and in bulk\n11. Notification search and filtering works across all fields\n12. Test notification feature works for all channels\n13. Performance: Dispatch 1000 notifications/second without blocking\n\n## Testing Strategy\n\n- Unit tests for notification service and each channel\n- Integration tests for end-to-end delivery\n- Mock external services (SendGrid, Slack) in tests\n- Load testing for high-volume scenarios\n- E2E tests for notification preferences UI\n\n## Reference\n\nPLAN.md section 21.9 - Comprehensive Notification System\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Notification routing respects per-category preferences and quiet hours\n- [ ] Deduping and digest logic prevents notification storms\n- [ ] Retry/backoff policy for delivery channels behaves deterministically\n\n### Integration Tests\n- [ ] Trigger a representative event → notification is created, stored, and emitted via WebSocket\n- [ ] Preference updates take effect immediately for subsequent notifications\n\n### E2E Tests (UI)\n- [ ] User can configure preferences and verify a test notification appears\n\n### Logging\n- [ ] Logs include correlationId + notificationId + category + channel + deliveryStatus\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Notification: creates with required fields\n- [ ] Notification: serializes correctly\n- [ ] Channel: email formatter works\n- [ ] Channel: Slack formatter works\n- [ ] Channel: webhook formatter works\n- [ ] Preferences: parses user settings\n- [ ] Preferences: applies to notification\n- [ ] Digest: batches notifications\n- [ ] Digest: formats summary\n- [ ] DoNotDisturb: checks schedule\n- [ ] DoNotDisturb: defers notification\n- [ ] Priority: routes urgent immediately\n\n### Integration Tests\n- [ ] POST /notifications creates notification\n- [ ] Email delivery works\n- [ ] Slack delivery works\n- [ ] Webhook delivery works\n- [ ] Preferences applied to routing\n- [ ] Digest sent at scheduled time\n- [ ] DND respects schedule\n\n### E2E Tests\n- [ ] User receives email notification\n- [ ] User receives Slack notification\n- [ ] Preferences UI saves correctly\n- [ ] Digest contains batched items\n\n### Performance Tests\n- [ ] Notification send \u003c100ms\n- [ ] Batch 1000 notifications \u003c5s\n- [ ] Digest generation \u003c1s\n- [ ] Preference lookup \u003c10ms\n\n### Failure Mode Tests\n- [ ] Email service down: retry queue\n- [ ] Slack service down: fallback channel\n- [ ] Invalid preferences: default used\n- [ ] Rate limit: backoff applied","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:59:33.393366195-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:04:55.587994469-05:00","dependencies":[{"issue_id":"flywheel_gateway-59c","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T14:01:51.693786475-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-5nm","title":"File Reservation System","description":"## Background\n\nThe File Reservation System prevents file conflicts when multiple agents work in the same codebase. Without coordination, agents might simultaneously modify the same file, leading to merge conflicts, lost work, or inconsistent state.\n\nThis system provides glob-based file reservations with two modes:\n- **Exclusive**: Only the reservation holder can modify matching files\n- **Shared**: Multiple agents can read, one can write with coordination\n\nReservations are TTL-based to prevent deadlocks from crashed or stuck agents.\n\n## Technical Architecture\n\n### Reservation Model\n```typescript\ninterface FileReservation {\n  id: string;                    // UUID\n  projectId: string;             // Project scope\n  agentId: string;               // Reserving agent\n  patterns: string[];            // Glob patterns\n  mode: 'exclusive' | 'shared';  // Reservation type\n  ttl: number;                   // Time-to-live in seconds\n  createdAt: Date;\n  expiresAt: Date;\n  renewCount: number;            // Number of renewals\n  metadata: {\n    reason?: string;             // Why reserved\n    taskId?: string;             // Associated task\n  };\n}\n```\n\n### Glob Pattern Matching\nUses `micromatch` for fast, accurate glob matching:\n```typescript\n// Example patterns\n'src/**/*.ts'           // All TypeScript in src\n'!src/**/*.test.ts'     // Exclude tests\n'packages/core/src/*'   // Direct children only\n'**/{package,tsconfig}.json'  // Specific files anywhere\n```\n\n### Core Operations\n\n#### 1. Create Reservation\n```typescript\nasync createReservation(params: {\n  projectId: string;\n  agentId: string;\n  patterns: string[];\n  mode: 'exclusive' | 'shared';\n  ttl?: number;          // Default: 300 (5 minutes)\n  reason?: string;\n}): Promise\u003c{\n  reservation: FileReservation;\n  conflicts: ConflictInfo[];  // Empty if granted\n  granted: boolean;\n}\u003e\n```\n\n#### 2. Check Reservation\n```typescript\nasync checkReservation(params: {\n  projectId: string;\n  agentId: string;\n  filePath: string;\n}): Promise\u003c{\n  allowed: boolean;\n  heldBy?: string;        // Agent holding reservation\n  expiresAt?: Date;\n  mode?: 'exclusive' | 'shared';\n}\u003e\n```\n\n#### 3. Release Reservation\n```typescript\nasync releaseReservation(params: {\n  reservationId: string;\n  agentId: string;        // Must match holder\n}): Promise\u003c{ released: boolean }\u003e\n```\n\n#### 4. Renew Reservation\n```typescript\nasync renewReservation(params: {\n  reservationId: string;\n  agentId: string;\n  additionalTtl?: number; // Default: original TTL\n}): Promise\u003c{\n  renewed: boolean;\n  newExpiresAt: Date;\n}\u003e\n```\n\n#### 5. List Reservations\n```typescript\nasync listReservations(params: {\n  projectId: string;\n  agentId?: string;       // Filter by agent\n  filePath?: string;      // Filter by affected file\n}): Promise\u003cFileReservation[]\u003e\n```\n\n### Conflict Detection Algorithm\n\nWhen a new reservation is requested:\n1. Expand all patterns to a set of potential file paths\n2. For each existing reservation in the project:\n   a. Expand its patterns\n   b. Compute intersection with new patterns\n   c. If intersection non-empty AND modes conflict, record conflict\n3. Return conflicts or grant reservation\n\n```typescript\nfunction detectConflicts(\n  newPatterns: string[],\n  newMode: ReservationMode,\n  existingReservations: FileReservation[]\n): ConflictInfo[] {\n  const conflicts: ConflictInfo[] = [];\n  \n  for (const existing of existingReservations) {\n    const overlap = computePatternOverlap(newPatterns, existing.patterns);\n    \n    if (overlap.length \u003e 0) {\n      // Exclusive conflicts with everything\n      // Shared only conflicts with exclusive\n      if (existing.mode === 'exclusive' || newMode === 'exclusive') {\n        conflicts.push({\n          reservationId: existing.id,\n          agentId: existing.agentId,\n          overlappingPatterns: overlap,\n          expiresAt: existing.expiresAt\n        });\n      }\n    }\n  }\n  \n  return conflicts;\n}\n```\n\n### TTL Management\n\n- Background job runs every 10 seconds\n- Expired reservations are marked and cleaned\n- Agents can subscribe to expiration warnings (30s before)\n- Maximum TTL: 1 hour (configurable)\n- Maximum renewals: 10 (prevents indefinite locks)\n\n## UI Components\n\n### Reservation Map View\nVisual representation of current reservations:\n```\nProject: flywheel-gateway\n==========================\n\n[Agent: architect-001] (exclusive, expires in 4:32)\n  - src/services/**/*.ts\n  - src/models/**/*.ts\n\n[Agent: coder-002] (shared, expires in 2:15)\n  - src/utils/*.ts\n  - src/helpers/*.ts\n\n[Agent: tester-003] (exclusive, expires in 8:45)\n  - **/*.test.ts\n  - **/*.spec.ts\n\nConflicts: None\n```\n\n### Real-time Updates\n- WebSocket subscription for reservation changes\n- Live conflict notifications\n- Expiration countdown timers\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `apps/gateway/src/services/reservation.service.ts` | Core reservation logic |\n| `apps/gateway/src/services/reservation.types.ts` | TypeScript interfaces |\n| `apps/gateway/src/services/reservation.store.ts` | Storage abstraction |\n| `apps/gateway/src/services/pattern-matcher.ts` | Glob pattern utilities |\n| `apps/gateway/src/controllers/reservation.controller.ts` | REST API endpoints |\n| `apps/gateway/src/websocket/reservation.gateway.ts` | WebSocket handlers |\n| `apps/gateway/src/jobs/reservation-cleanup.job.ts` | TTL enforcement |\n| `apps/web/src/components/ReservationMap.tsx` | UI component |\n| `apps/gateway/src/__tests__/reservation.service.test.ts` | Unit tests |\n\n## Acceptance Criteria\n\n- [ ] Create, check, release, renew, list operations\n- [ ] Glob pattern matching with negation support\n- [ ] Exclusive vs shared mode semantics\n- [ ] Conflict detection for overlapping patterns\n- [ ] TTL-based automatic expiration\n- [ ] Maximum renewal limit enforcement\n- [ ] REST API endpoints for all operations\n- [ ] WebSocket events for real-time updates\n- [ ] Reservation map UI component\n- [ ] Background cleanup job for expired reservations\n- [ ] \u003e95% test coverage for conflict detection\n- [ ] Performance: \u003c50ms for conflict check with 100 active reservations\n- [ ] Documentation with usage examples\n\n## References\n\n- PLAN.md Section 11: File Coordination\n- PLAN.md Section 12: Conflict Prevention\n\n## Dependencies\n\n- `micromatch` - Glob pattern matching\n- `ioredis` - Redis for distributed state\n- `cron` - Background job scheduling\n- Socket.io for WebSocket support\n\n## Edge Cases to Handle\n\n1. Agent requests pattern that is subset of own existing reservation\n2. Agent crashes without releasing reservation\n3. Two agents request overlapping patterns simultaneously\n4. Pattern expansion exceeds memory limits (cap at 10,000 files)\n5. Reservation renewal race conditions\n6. Project deletion with active reservations\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Reservation conflict detection matches symmetric glob semantics\n- [ ] TTL expiry and renew semantics behave correctly (extend from max(now, expires))\n- [ ] Exclusive vs shared reservation rules are enforced deterministically\n\n### Integration Tests\n- [ ] Create/renew/release reservations against Agent Mail (mock or local) and verify server state\n- [ ] Concurrent reservation attempts for overlapping patterns resolve correctly (one conflict, one granted)\n\n### Failure Mode Tests\n- [ ] Agent Mail unavailable → graceful degradation with actionable error + no local corruption\n\n### Logging\n- [ ] Logs include correlationId + reservationId + pathPattern + exclusive + expiresTs\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Reservation.create: generates unique ID\n- [ ] Reservation.create: parses glob patterns\n- [ ] Reservation.create: sets TTL correctly\n- [ ] Reservation.isExpired: returns true after TTL\n- [ ] Reservation.matches: glob matching works\n- [ ] Reservation.conflicts: exclusive vs shared logic\n- [ ] ReservationManager.acquire: stores reservation\n- [ ] ReservationManager.release: removes reservation\n- [ ] ReservationManager.renew: extends TTL\n- [ ] ReservationManager.check: finds conflicts\n- [ ] Glob patterns: ** matches directories\n- [ ] Glob patterns: * matches files\n- [ ] Glob patterns: negation patterns work\n- [ ] Exclusive mode: blocks overlapping exclusive\n- [ ] Exclusive mode: blocks overlapping shared\n- [ ] Shared mode: allows overlapping shared\n- [ ] Shared mode: blocked by exclusive\n\n### Integration Tests\n- [ ] POST /reservations creates reservation\n- [ ] GET /reservations lists agent's reservations\n- [ ] DELETE /reservations releases reservation\n- [ ] GET /reservations/conflicts shows conflicts\n- [ ] WebSocket reservation event fires on create\n- [ ] WebSocket release event fires on delete\n- [ ] WebSocket conflict event fires on conflict\n- [ ] TTL expiration triggers release event\n- [ ] Renewal extends TTL successfully\n\n### E2E Tests\n- [ ] Agent reserves files before editing\n- [ ] Conflict detected when overlapping\n- [ ] Conflict cleared when reservation released\n- [ ] Reservation map UI shows current state\n\n### Performance Tests\n- [ ] Reserve 1000 patterns \u003c100ms\n- [ ] Conflict check \u003c10ms for 100 reservations\n- [ ] TTL expiration processed within 1 second\n- [ ] Memory bounded with many reservations\n\n### Failure Mode Tests\n- [ ] Reserve without registration: error\n- [ ] Invalid glob pattern: validation error\n- [ ] Reserve expired agent: error\n- [ ] Concurrent reserve race: handled correctly","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:38:37.14682048-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:05:10.295947298-05:00","dependencies":[{"issue_id":"flywheel_gateway-5nm","depends_on_id":"flywheel_gateway-61i","type":"blocks","created_at":"2026-01-08T14:01:46.297929756-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-5nm","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:47.21369042-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-5nq","title":"FEAT: DCG Integration (Destructive Command Guard)","description":"## Background\n\nDestructive Command Guard (DCG) is a critical safety layer that intercepts and analyzes bash commands before execution. It prevents accidental data loss, security breaches, and infrastructure damage by identifying potentially dangerous operations and requiring explicit user confirmation.\n\n### Why DCG?\n\nModern development workflows involve numerous CLI operations that can have irreversible consequences:\n- Recursive forced deletion commands targeting root or important directories\n- Force push operations overwriting remote git history\n- DROP DATABASE or truncation commands\n- Cloud CLI commands that delete resources\n- Package publish commands that cannot be unpublished\n\nDCG provides a safety net without impeding developer productivity for safe operations.\n\n## Technical Architecture\n\n### Pre-Execution Hook System\n\nThe hook intercepts commands at the shell level before execution:\n\n```typescript\n// apps/gateway/src/dcg/hooks/pre-execution.hook.ts\ninterface PreExecutionHook {\n  intercept(command: string, context: ExecutionContext): Promise\u003cInterceptResult\u003e;\n  analyze(command: string): Promise\u003cThreatAssessment\u003e;\n  shouldBlock(assessment: ThreatAssessment): boolean;\n}\n\ninterface ExecutionContext {\n  workingDirectory: string;\n  user: string;\n  environment: Record\u003cstring, string\u003e;\n  previousCommands: string[];\n  sessionId: string;\n}\n\ninterface InterceptResult {\n  allowed: boolean;\n  reason?: string;\n  severity?: SeverityTier;\n  matchedPatterns?: Pattern[];\n  suggestedAlternative?: string;\n}\n```\n\n### Block Event Storage\n\nAll blocked commands are captured for audit and learning:\n\n```typescript\n// apps/gateway/src/dcg/storage/block-events.repository.ts\ninterface BlockEvent {\n  id: string;\n  timestamp: Date;\n  command: string;\n  severity: SeverityTier;\n  matchedPatterns: string[];\n  context: ExecutionContext;\n  userAction: 'blocked' | 'overridden' | 'cancelled';\n  overrideReason?: string;\n}\n\n// Storage in SQLite for local dev, PostgreSQL for production\n// Retention: 90 days default, configurable\n```\n\n### Severity Tier System\n\nFour-tier classification system:\n\n| Tier | Color | Behavior | Examples |\n|------|-------|----------|----------|\n| **Critical** | Red | Hard block, requires manager override | recursive delete on root, DROP DATABASE production |\n| **High** | Orange | Block with confirmation + reason required | git force push, kubectl delete namespace |\n| **Medium** | Yellow | Warning with single confirmation | npm publish, docker system prune |\n| **Low** | Blue | Informational notice, no block | git reset hard, recursive delete on node_modules |\n\n```typescript\n// apps/gateway/src/dcg/types/severity.ts\nenum SeverityTier {\n  CRITICAL = 'critical',\n  HIGH = 'high', \n  MEDIUM = 'medium',\n  LOW = 'low'\n}\n\ninterface SeverityConfig {\n  tier: SeverityTier;\n  requiresConfirmation: boolean;\n  requiresReason: boolean;\n  requiresManagerOverride: boolean;\n  cooldownSeconds: number;\n}\n```\n\n### Pack System for Modular Patterns\n\nPatterns are organized into installable packs:\n\n```typescript\n// apps/gateway/src/dcg/packs/pack.interface.ts\ninterface DCGPack {\n  id: string;\n  name: string;\n  version: string;\n  description: string;\n  author: string;\n  patterns: Pattern[];\n  enabled: boolean;\n}\n\ninterface Pattern {\n  id: string;\n  regex: RegExp;\n  severity: SeverityTier;\n  description: string;\n  category: string;\n  suggestedAlternative?: string;\n  falsePositiveHints?: string[];\n}\n\n// Built-in packs:\n// - core-destructive: rm, del, format commands\n// - git-safety: force push, hard reset, history rewrite\n// - cloud-aws: EC2 terminate, S3 bucket delete, IAM changes\n// - cloud-gcp: Compute delete, GCS bucket operations\n// - database: DROP, TRUNCATE, DELETE without WHERE\n// - kubernetes: namespace delete, node drain, secret exposure\n// - npm-publish: publish, deprecate, unpublish\n```\n\n### Dashboard Components\n\n```typescript\n// apps/web/src/components/safety/DCGDashboard.tsx\n// Main dashboard showing:\n// - Recent blocks (last 24h, 7d, 30d)\n// - Block frequency chart\n// - Top blocked patterns\n// - User override history\n// - Pack management\n\n// apps/web/src/components/safety/BlockEventList.tsx\n// Paginated list of block events with:\n// - Command preview (sanitized)\n// - Severity badge\n// - Timestamp\n// - User action taken\n// - Expand for full context\n\n// apps/web/src/components/safety/PackManager.tsx\n// Enable/disable packs\n// View pack patterns\n// Custom pattern creation\n// Import/export pack configurations\n```\n\n## File Structure\n\n```\napps/gateway/src/dcg/\n├── index.ts                    # Module exports\n├── dcg.module.ts              # NestJS module definition\n├── dcg.service.ts             # Main DCG service\n├── hooks/\n│   ├── pre-execution.hook.ts  # Command interception\n│   └── post-execution.hook.ts # Audit logging\n├── analyzers/\n│   ├── pattern.analyzer.ts    # Regex pattern matching\n│   ├── context.analyzer.ts    # Context-aware analysis\n│   └── ml.analyzer.ts         # Future: ML-based detection\n├── storage/\n│   ├── block-events.repository.ts\n│   └── block-events.entity.ts\n├── packs/\n│   ├── pack.interface.ts\n│   ├── pack.loader.ts\n│   ├── built-in/\n│   │   ├── core-destructive.pack.ts\n│   │   ├── git-safety.pack.ts\n│   │   ├── cloud-aws.pack.ts\n│   │   ├── database.pack.ts\n│   │   └── kubernetes.pack.ts\n│   └── custom/\n│       └── .gitkeep\n├── types/\n│   ├── severity.ts\n│   ├── block-event.ts\n│   └── execution-context.ts\n└── __tests__/\n    ├── dcg.service.spec.ts\n    ├── pattern.analyzer.spec.ts\n    └── packs.spec.ts\n\napps/web/src/components/safety/\n├── DCGDashboard.tsx\n├── BlockEventList.tsx\n├── BlockEventDetail.tsx\n├── PackManager.tsx\n├── PatternEditor.tsx\n├── SeverityBadge.tsx\n└── __tests__/\n    └── DCGDashboard.test.tsx\n```\n\n## Implementation Phases\n\n### Phase 1: Core Infrastructure\n1. Define all TypeScript interfaces\n2. Implement pattern analyzer with regex matching\n3. Create block event entity and repository\n4. Build pre-execution hook skeleton\n\n### Phase 2: Built-in Packs\n1. Create core-destructive pack\n2. Create git-safety pack\n3. Create database pack\n4. Pack loader and registry\n\n### Phase 3: Dashboard\n1. Block event list component\n2. Dashboard with statistics\n3. Pack manager UI\n4. Real-time updates via WebSocket\n\n### Phase 4: Advanced Features\n1. Context-aware analysis\n2. User-specific overrides\n3. Team policies\n4. Export/import configurations\n\n## Acceptance Criteria\n\n- [ ] Pre-execution hook intercepts all bash commands via gateway\n- [ ] Pattern matching correctly identifies destructive commands\n- [ ] Severity tiers are enforced (critical blocks, high warns, etc.)\n- [ ] Block events are persisted to database\n- [ ] At least 5 built-in packs with 50+ patterns total\n- [ ] Dashboard displays block history with filtering\n- [ ] Pack manager allows enable/disable of packs\n- [ ] Custom patterns can be added via UI\n- [ ] WebSocket pushes real-time block notifications\n- [ ] 90%+ test coverage on analyzers\n- [ ] Performance: less than 10ms added latency per command check\n- [ ] Documentation for creating custom packs\n\n## Dependencies\n\n- Command Registry (for hook integration)\n- WebSocket infrastructure (for real-time updates)\n- Database schema (block_events table)\n\n## References\n\n- PLAN.md Section 17.6: DCG Integration\n- RFC-003: Safety Layer Architecture\n- Existing DCG repository: github.com/anthropics/dcg\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Block event parsing validates schema and applies redaction/sanitization rules\n- [ ] Severity classification and pack matching are deterministic for the same command/context\n- [ ] Storage layer persists events with correct indexes and retention behavior\n\n### Integration Tests\n- [ ] Ingest endpoint accepts a representative block event and emits WebSocket event + history entry\n- [ ] Dashboard query endpoints return correct pagination and filtering (by severity, time range)\n\n### E2E Tests (UI)\n- [ ] Block event appears in dashboard with sanitized command preview and correct severity badge\n\n### Logging\n- [ ] Logs include correlationId + dcgEventId + severity + matchedPatternIds; secrets are never logged\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:32:38.611877216-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:28:35.885628403-05:00","dependencies":[{"issue_id":"flywheel_gateway-5nq","depends_on_id":"flywheel_gateway-w55","type":"blocks","created_at":"2026-01-08T14:01:55.818443693-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-5nq","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:58.006237178-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-5nq","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T17:51:59.889823015-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-5nq","depends_on_id":"flywheel_gateway-46c","type":"blocks","created_at":"2026-01-08T17:52:04.923256682-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-5nq","depends_on_id":"flywheel_gateway-r3p","type":"blocks","created_at":"2026-01-08T17:52:09.978965354-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-61i","title":"Agent Mail Integration (MCP Client)","description":"## Background\n\nAgent Mail provides MCP-based (Model Context Protocol) inter-agent communication within the Flywheel ecosystem. This enables agents to collaborate, delegate tasks, share context, and coordinate their activities without requiring direct connections.\n\nThe mail system uses a message queue architecture where agents send messages to named mailboxes. This decouples senders from receivers and enables asynchronous communication patterns essential for multi-agent orchestration.\n\n## Technical Architecture\n\n### MCP Integration\nAgent Mail is exposed as an MCP server that agents connect to as clients. This leverages the standard MCP tool-calling mechanism for all mail operations:\n\n```typescript\n// MCP Tools exposed by Agent Mail\ntools: [\n  'agentmail_ensure_project',    // Create/verify project exists\n  'agentmail_register_agent',    // Register agent in project\n  'agentmail_send_message',      // Send message to agent\n  'agentmail_reply',             // Reply to received message\n  'agentmail_fetch_inbox',       // Get pending messages\n  'agentmail_request_file_reservation'  // Request file lock\n]\n```\n\n### Message Structure\n```typescript\ninterface AgentMailMessage {\n  id: string;                    // UUID\n  projectId: string;             // Project context\n  from: AgentIdentity;           // Sender agent\n  to: AgentIdentity;             // Recipient agent\n  subject: string;               // Message subject\n  body: any;                     // Structured content (JSON)\n  replyTo?: string;              // Parent message ID for threads\n  priority: 'low' | 'normal' | 'high' | 'urgent';\n  ttl: number;                   // Time-to-live in seconds\n  metadata: Record\u003cstring, any\u003e; // Extension point\n  createdAt: Date;\n  expiresAt: Date;\n}\n```\n\n### Core Operations\n\n#### 1. Ensure Project\nIdempotently creates a project context for agent communication:\n```typescript\nagentmail_ensure_project({\n  projectId: string,\n  name: string,\n  metadata?: Record\u003cstring, any\u003e\n}): { projectId: string, created: boolean }\n```\n\n#### 2. Register Agent\nRegisters an agent to receive messages in a project:\n```typescript\nagentmail_register_agent({\n  projectId: string,\n  agentId: string,\n  capabilities: string[],\n  metadata?: Record\u003cstring, any\u003e\n}): { registered: boolean, mailboxId: string }\n```\n\n#### 3. Send Message\nSends a message to another agent's mailbox:\n```typescript\nagentmail_send_message({\n  projectId: string,\n  to: string,           // Agent ID\n  subject: string,\n  body: any,\n  priority?: Priority,\n  ttl?: number          // Default: 3600 (1 hour)\n}): { messageId: string, delivered: boolean }\n```\n\n#### 4. Reply\nReplies to a received message, maintaining thread context:\n```typescript\nagentmail_reply({\n  messageId: string,    // Original message to reply to\n  body: any,\n  priority?: Priority\n}): { replyId: string, delivered: boolean }\n```\n\n#### 5. Fetch Inbox\nRetrieves pending messages for an agent:\n```typescript\nagentmail_fetch_inbox({\n  projectId: string,\n  agentId: string,\n  limit?: number,       // Default: 50\n  since?: Date,\n  priority?: Priority   // Filter by priority\n}): { messages: AgentMailMessage[], hasMore: boolean }\n```\n\n#### 6. Request File Reservation\nRequests a file reservation through the mail system:\n```typescript\nagentmail_request_file_reservation({\n  projectId: string,\n  requesterId: string,\n  patterns: string[],   // Glob patterns\n  exclusive: boolean,\n  duration: number      // Seconds\n}): { reservationId: string, granted: boolean, conflicts?: string[] }\n```\n\n## Implementation Details\n\n### MCP Server Configuration\n```typescript\nconst mcpServer = new MCPServer({\n  name: 'flywheel-agentmail',\n  version: '1.0.0',\n  capabilities: {\n    tools: true,\n    resources: false,\n    prompts: false\n  }\n});\n```\n\n### Message Queue Backend\n- In-memory queue for development\n- Redis-backed queue for production\n- PostgreSQL for message persistence and history\n- Configurable retention policies\n\n### Delivery Guarantees\n- At-least-once delivery with idempotency keys\n- Dead letter queue for undeliverable messages\n- Retry with exponential backoff (max 3 attempts)\n- Delivery confirmation via acknowledgment\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `packages/flywheel-clients/src/agentmail/index.ts` | Public exports |\n| `packages/flywheel-clients/src/agentmail/mcp-server.ts` | MCP server implementation |\n| `packages/flywheel-clients/src/agentmail/tools/` | Individual MCP tool handlers |\n| `packages/flywheel-clients/src/agentmail/queue.ts` | Message queue abstraction |\n| `packages/flywheel-clients/src/agentmail/types.ts` | TypeScript interfaces |\n| `packages/flywheel-clients/src/agentmail/storage/` | Storage adapters (memory, Redis, Postgres) |\n| `packages/flywheel-clients/src/agentmail/__tests__/` | Test suites |\n\n## Acceptance Criteria\n\n- [ ] MCP server with all 6 tools implemented\n- [ ] Tool input/output schema validation\n- [ ] Message persistence across restarts\n- [ ] Thread support via replyTo chains\n- [ ] Priority queue ordering (urgent \u003e high \u003e normal \u003e low)\n- [ ] TTL enforcement with automatic expiration\n- [ ] Dead letter queue for failed deliveries\n- [ ] At-least-once delivery guarantee\n- [ ] Redis adapter for production\n- [ ] PostgreSQL adapter for persistence\n- [ ] \u003e90% test coverage\n- [ ] Integration tests with mock agents\n- [ ] Performance: handle 1000 msgs/sec\n\n## References\n\n- PLAN.md Section 10: Inter-Agent Communication\n- PLAN.md Section 11: Agent Mail Protocol\n- MCP Specification: https://modelcontextprotocol.io/\n\n## Dependencies\n\n- `@modelcontextprotocol/sdk` - MCP SDK\n- `ioredis` - Redis client\n- `pg` - PostgreSQL client\n- Shared types from `@flywheel/types`\n\n## Security Considerations\n\n- Validate agent identity before message access\n- Enforce project-level isolation\n- Rate limit message sending (default: 100/min/agent)\n- Sanitize message body content\n- Encrypt sensitive message content at rest\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Client request/response schemas validate and map errors into shared taxonomy\n- [ ] Availability/health caching behaves as intended (TTL, invalidate)\n- [ ] Macro helpers (start session, reservations cycle) compose correctly\n\n### Integration Tests\n- [ ] Against a local/mock Agent Mail server: ensure_project/register_agent/send_message/fetch_inbox work end-to-end\n- [ ] File reservation conflict scenarios are handled and surfaced to callers with clear details\n\n### Failure Mode Tests\n- [ ] Server unreachable/timeouts → graceful degradation and actionable error hints\n\n### Logging\n- [ ] Logs include correlationId + agentmail_method + request_id + latencyMs; message bodies are not logged by default\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] MCP server: initializes with correct capabilities\n- [ ] ensure_project: creates project idempotently\n- [ ] ensure_project: returns projectId and created flag\n- [ ] register_agent: registers agent with capabilities\n- [ ] register_agent: returns mailboxId\n- [ ] send_message: creates message with correct structure\n- [ ] send_message: respects priority ordering\n- [ ] send_message: sets TTL and expiration\n- [ ] reply: links to parent message\n- [ ] reply: inherits thread context\n- [ ] fetch_inbox: returns messages in priority order\n- [ ] fetch_inbox: respects limit parameter\n- [ ] fetch_inbox: filters by since timestamp\n- [ ] request_file_reservation: validates patterns\n- [ ] request_file_reservation: checks for conflicts\n- [ ] Message queue: push adds to queue\n- [ ] Message queue: pop returns highest priority\n- [ ] Message queue: expired messages removed\n- [ ] Dead letter queue: captures undeliverable\n\n### Integration Tests\n- [ ] MCP tool calls work end-to-end\n- [ ] Agent registers and receives mailbox\n- [ ] Send message delivers to recipient inbox\n- [ ] Reply creates threaded conversation\n- [ ] File reservation grants when no conflicts\n- [ ] File reservation conflicts when exclusive overlap\n- [ ] Message TTL expiration works\n- [ ] Redis backend persists across restart\n- [ ] PostgreSQL backend handles concurrent access\n\n### E2E Tests\n- [ ] Two agents exchange messages\n- [ ] Agent reserves files and releases\n- [ ] Thread conversation with multiple replies\n- [ ] Cross-project contact handshake\n\n### Performance Tests\n- [ ] Handle 1000 msgs/sec send rate\n- [ ] Inbox fetch \u003c50ms for 100 messages\n- [ ] Message delivery latency \u003c100ms\n- [ ] Connection pool handles 100 concurrent agents\n\n### Failure Mode Tests\n- [ ] Unregistered agent send: clear error\n- [ ] Invalid projectId: appropriate error\n- [ ] Queue full: backpressure applied\n- [ ] Redis disconnect: graceful reconnect\n- [ ] Message validation failure: rejected with reason","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:38:36.977252736-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:05:38.740268084-05:00","dependencies":[{"issue_id":"flywheel_gateway-61i","depends_on_id":"flywheel_gateway-46c","type":"blocks","created_at":"2026-01-08T14:01:44.501230175-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-66n","title":"FEAT: Flywheel Velocity Dashboard","description":"## Background\n\nThe Flywheel methodology is built on the premise of continuous improvement - each cycle through Plan, Coordinate, Execute, Scan, and Remember should be faster and more effective than the last. The Velocity Dashboard provides a quantitative measure of this improvement, enabling operators to understand how well their Flywheel ecosystem is accelerating and where friction exists.\n\n## Reasoning\n\nVelocity measurement is crucial because:\n- **Validates the Flywheel Concept**: Proves that the system is actually improving over time\n- **Identifies Bottlenecks**: Highlights which stages are slowing down the cycle\n- **Guides Investment**: Shows where improvements will have the most impact\n- **Motivates Teams**: Visible progress encourages continued adoption\n\nThe velocity score provides a single, intuitive metric (0-100) that captures overall ecosystem health, while detailed stage metrics enable diagnosis and optimization.\n\n## Technical Considerations\n\n### Velocity Score Calculation\n\n**Composite Score (0-100):**\n```typescript\ninterface VelocityScore {\n  overall_score: number; // 0-100\n  timestamp: Date;\n  period: '24h' | '7d' | '30d';\n  \n  components: {\n    throughput_score: number;      // Weight: 25%\n    cycle_time_score: number;      // Weight: 25%\n    success_rate_score: number;    // Weight: 20%\n    learning_rate_score: number;   // Weight: 20%\n    collaboration_score: number;   // Weight: 10%\n  };\n  \n  trend: 'accelerating' | 'stable' | 'decelerating';\n  trend_magnitude: number; // percentage change\n}\n```\n\n**Component Calculations:**\n\n1. **Throughput Score (25%):**\n   - Tasks completed per hour normalized against capacity\n   - Baseline: First 30 days of operation\n   - Score: (current_throughput / baseline_throughput) * 50, capped at 100\n\n2. **Cycle Time Score (25%):**\n   - Average time from task creation to completion\n   - Compared against historical best and baseline\n   - Score: (baseline_time / current_time) * 50, capped at 100\n\n3. **Success Rate Score (20%):**\n   - Percentage of tasks completing successfully\n   - Score: success_rate directly (90% = 90 score)\n\n4. **Learning Rate Score (20%):**\n   - Improvement in efficiency over time\n   - Measures knowledge reuse and error reduction\n   - Calculated from derivative of efficiency metrics\n\n5. **Collaboration Score (10%):**\n   - Efficiency of multi-agent coordination\n   - Handoff success rate and latency\n   - Cross-agent knowledge sharing\n\n### Per-Stage Metrics\n\n**Plan Stage:**\n```typescript\ninterface PlanStageMetrics {\n  avg_planning_duration_seconds: number;\n  plan_quality_score: number; // based on execution success\n  plan_revision_rate: number; // replanning frequency\n  estimation_accuracy: number; // predicted vs actual duration\n  complexity_assessment_accuracy: number;\n}\n```\n\n**Coordinate Stage:**\n```typescript\ninterface CoordinateStageMetrics {\n  avg_coordination_duration_seconds: number;\n  agent_assignment_efficiency: number;\n  resource_contention_rate: number;\n  parallel_execution_ratio: number;\n  coordination_overhead_percent: number;\n}\n```\n\n**Execute Stage:**\n```typescript\ninterface ExecuteStageMetrics {\n  avg_execution_duration_seconds: number;\n  tool_call_success_rate: number;\n  retry_rate: number;\n  context_switch_frequency: number;\n  execution_efficiency: number; // useful work / total time\n}\n```\n\n**Scan Stage:**\n```typescript\ninterface ScanStageMetrics {\n  avg_scan_duration_seconds: number;\n  files_scanned_per_second: number;\n  issue_detection_rate: number;\n  false_positive_rate: number;\n  scan_coverage_percent: number;\n}\n```\n\n**Remember Stage:**\n```typescript\ninterface RememberStageMetrics {\n  avg_remember_duration_seconds: number;\n  knowledge_entries_created: number;\n  knowledge_retrieval_hit_rate: number;\n  knowledge_freshness_score: number;\n  cross_agent_sharing_rate: number;\n}\n```\n\n### Learning Rate Tracking\n\n**Learning Metrics:**\n```typescript\ninterface LearningMetrics {\n  period: DateRange;\n  \n  improvement_rate: {\n    overall: number; // percentage improvement per week\n    by_task_type: Map\u003cstring, number\u003e;\n    by_agent: Map\u003cstring, number\u003e;\n  };\n  \n  knowledge_reuse: {\n    cache_hit_rate: number;\n    similar_task_acceleration: number;\n    pattern_recognition_improvement: number;\n  };\n  \n  error_reduction: {\n    overall_error_rate_trend: number; // negative = improvement\n    recurring_error_elimination: number;\n    novel_error_rate: number;\n  };\n}\n```\n\n**Learning Indicators:**\n- **Positive Learning**: Decreasing error rates, increasing throughput\n- **Knowledge Accumulation**: Growing knowledge base, higher reuse\n- **Pattern Recognition**: Faster handling of similar tasks\n- **Error Prevention**: Fewer repeated mistakes\n\n### Trend Indicators\n\n**Trend Detection:**\n```typescript\ninterface TrendAnalysis {\n  velocity_trend: 'accelerating' | 'stable' | 'decelerating';\n  confidence: number;\n  \n  acceleration_factors: string[]; // What's helping\n  deceleration_factors: string[]; // What's hurting\n  \n  forecast_7d: {\n    expected_velocity: number;\n    confidence_interval: [number, number];\n  };\n  \n  recommendations: TrendRecommendation[];\n}\n```\n\n**Trend Thresholds:**\n- **Accelerating**: \u003e 5% improvement week-over-week\n- **Stable**: -2% to +5% change\n- **Decelerating**: \u003c -2% decline\n\n**Trend Visualization:**\n- Velocity sparkline with trend line\n- Color-coded trend indicator (green/yellow/red)\n- Comparison to historical periods\n- Anomaly highlighting\n\n### Dashboard Layout\n\n**Main Dashboard Sections:**\n\n1. **Hero Velocity Gauge:**\n   - Large circular gauge (0-100)\n   - Current score prominently displayed\n   - Trend arrow with percentage change\n   - Comparison to 30-day average\n\n2. **Stage Performance Strip:**\n   - Five horizontal bars for each stage\n   - Color-coded performance (vs baseline)\n   - Click to drill into stage details\n   - Mini sparklines for trends\n\n3. **Learning Rate Panel:**\n   - Improvement rate over time chart\n   - Knowledge reuse metrics\n   - Error reduction trend\n   - Key learning milestones\n\n4. **Trend Analysis Section:**\n   - Trend status with explanation\n   - Acceleration/deceleration factors\n   - Actionable recommendations\n   - Forecast visualization\n\n5. **Historical Comparison:**\n   - Velocity over time (30/60/90 days)\n   - Week-over-week comparisons\n   - Best/worst day analysis\n   - Milestone markers\n\n## Acceptance Criteria\n\n1. **Velocity Score**\n   - [ ] Composite score calculated from 5 components\n   - [ ] Score updates in real-time (\u003c 1 minute lag)\n   - [ ] Historical scores stored for trending\n   - [ ] Score explanation available on hover\n\n2. **Stage Metrics**\n   - [ ] All 5 stages measured independently\n   - [ ] Duration, quality, and efficiency per stage\n   - [ ] Stage bottleneck identification\n   - [ ] Stage-specific recommendations\n\n3. **Learning Rate**\n   - [ ] Improvement rate calculated weekly\n   - [ ] Knowledge reuse metrics tracked\n   - [ ] Error reduction trends visible\n   - [ ] Learning milestones highlighted\n\n4. **Trend Analysis**\n   - [ ] Trend detected with confidence score\n   - [ ] Factors explained in plain language\n   - [ ] 7-day forecast with confidence interval\n   - [ ] Recommendations for improvement\n\n5. **Dashboard UI**\n   - [ ] Velocity gauge as focal point\n   - [ ] Stage breakdown with drill-down\n   - [ ] Learning metrics visualization\n   - [ ] Trend indicators with explanations\n   - [ ] Responsive design for all screen sizes\n\n## File Locations\n\n### Backend Services\n- `apps/gateway/src/services/velocity.service.ts` - Core velocity calculation\n- `apps/gateway/src/services/stage-metrics.service.ts` - Per-stage metrics\n- `apps/gateway/src/services/learning-rate.service.ts` - Learning tracking\n- `apps/gateway/src/services/trend-analysis.service.ts` - Trend detection\n- `apps/gateway/src/controllers/velocity.controller.ts` - Velocity API\n\n### Database\n- `packages/database/prisma/migrations/xxx_add_velocity_tracking.sql` - Schema\n- Tables: `velocity_scores`, `stage_metrics`, `learning_metrics`, `trend_analysis`\n\n### Frontend Components\n- `apps/web/src/components/analytics/FlywheelVelocityDashboard.tsx` - Main dashboard\n- `apps/web/src/components/analytics/VelocityGauge.tsx` - Hero gauge component\n- `apps/web/src/components/analytics/StagePerformanceStrip.tsx` - Stage breakdown\n- `apps/web/src/components/analytics/LearningRatePanel.tsx` - Learning metrics\n- `apps/web/src/components/analytics/TrendIndicator.tsx` - Trend visualization\n- `apps/web/src/components/analytics/VelocityHistoryChart.tsx` - Historical chart\n\n### Algorithms\n- `apps/gateway/src/algorithms/velocity-score.ts` - Score calculation\n- `apps/gateway/src/algorithms/trend-detection.ts` - CUSUM/EWMA trend detection\n- `apps/gateway/src/algorithms/learning-rate.ts` - Learning curve fitting\n\n## References\n\n- PLAN.md §21.7 - Flywheel Velocity Dashboard\n- Flywheel Methodology: Plan -\u003e Coordinate -\u003e Execute -\u003e Scan -\u003e Remember\n- Statistical Methods: Exponentially Weighted Moving Average, Change Point Detection\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Velocity metrics aggregation is deterministic (same inputs → same output)\n- [ ] Scoring/weighting logic handles missing subsystems (partial availability) without NaNs\n- [ ] Time-window computations (7d/30d) are correct and timezone-safe\n\n### Integration Tests\n- [ ] With stubbed integrations (BV/CASS/Scanner/Metrics): dashboard endpoint returns a complete, validated response\n\n### E2E Tests (UI)\n- [ ] Dashboard renders velocity overview and updates when new events arrive\n\n### Logging\n- [ ] Logs include correlationId + window + component availability flags + computation latency\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] HealthScore: calculates from metrics\n- [ ] HealthScore: weights components\n- [ ] LearningRate: tracks improvement\n- [ ] LearningRate: detects plateaus\n- [ ] CrossRepoActivity: aggregates across repos\n- [ ] CrossRepoActivity: identifies hotspots\n- [ ] Bottleneck: detects from BV data\n- [ ] Bottleneck: ranks by impact\n- [ ] Velocity: calculates from completions\n- [ ] Velocity: compares to baseline\n- [ ] Trend: weekly/monthly comparison\n- [ ] Trend: anomaly detection\n\n### Integration Tests\n- [ ] GET /analytics/velocity returns data\n- [ ] Multi-repo aggregation works\n- [ ] BV bottleneck data integrated\n- [ ] CM learning rate included\n- [ ] Real-time health score updates\n- [ ] Historical velocity queryable\n\n### E2E Tests\n- [ ] Dashboard shows ecosystem health\n- [ ] Bottleneck list clickable\n- [ ] Learning rate trend visible\n- [ ] Drill down by repo\n\n### Performance Tests\n- [ ] Health score calculation \u003c200ms\n- [ ] Multi-repo aggregation \u003c1s\n- [ ] Dashboard load \u003c2s\n- [ ] Real-time updates smooth\n\n### Failure Mode Tests\n- [ ] BV unavailable: partial data\n- [ ] No recent data: shows stale indicator\n- [ ] Single repo error: others still shown\n- [ ] Anomaly detected: alert shown","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:56:40.765949828-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:05:55.479467076-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-66n","depends_on_id":"flywheel_gateway-p8j","type":"blocks","created_at":"2026-01-08T14:01:48.50100809-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-66n","depends_on_id":"flywheel_gateway-c4z","type":"blocks","created_at":"2026-01-08T14:01:49.541080448-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-66n","depends_on_id":"flywheel_gateway-bpg","type":"blocks","created_at":"2026-01-08T14:01:50.318407891-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-66n","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T17:22:55.306317838-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-6ix","title":"FEAT: Output Streaming System","description":"## Background\n\nAI coding agents produce substantial output during execution - code analysis, file operations, command results, and thinking processes. Users need to see this output in real-time for interactive workflows, while also being able to retrieve historical output for review and debugging.\n\n## Reasoning\n\n### Why Real-time Streaming?\n- **User Experience**: Watching output appear live is essential for interactive agent use\n- **Progress Visibility**: Long-running operations show incremental progress\n- **Early Termination**: Users can stop agents early if output shows wrong direction\n- **Debugging**: See exactly what the agent is doing as it works\n\n### Why Output Buffering?\n- **Reconnection Support**: Users can disconnect and reconnect without losing output\n- **Historical Review**: Examine what an agent did after the fact\n- **Sharing**: Share output logs with teammates for collaboration\n- **Compliance**: Some use cases require output retention for audit\n\n### Why Separate REST + WebSocket?\n- **WebSocket for Live**: Low-latency push of new output chunks\n- **REST for History**: Simple retrieval of past output with pagination\n- **Flexibility**: Clients choose their consumption pattern\n- **Graceful Degradation**: REST works even if WebSocket fails\n\n## Technical Considerations\n\n### PTY Output Handling\n```typescript\ninterface OutputChunk {\n  id: string;              // UUID v7 for ordering\n  agentId: string;\n  sessionId: string;\n  timestamp: string;       // ISO 8601\n  streamType: 'stdout' | 'stderr' | 'system';\n  content: string;         // Raw output content\n  encoding: 'utf-8' | 'base64'; // Base64 for binary\n  sequence: number;        // Monotonic sequence number\n}\n```\n\n### Buffering Strategy\n- **Ring Buffer**: Keep last N chunks in memory (configurable, default 1000)\n- **Persistence**: Write to database for long-term storage\n- **Compression**: Compress older chunks to save space\n- **TTL**: Auto-delete output older than retention period\n\n### Streaming Implementation\n1. PTY data event fires\n2. Parse into output chunks\n3. Assign sequence number and timestamp\n4. Emit to WebSocket subscribers\n5. Push to ring buffer\n6. Async persist to database\n\n### WebSocket Protocol\n```typescript\n// Client subscribes to agent output\n{ type: 'subscribe', agentId: 'uuid' }\n\n// Server pushes output chunks\n{ \n  type: 'output.chunk', \n  agentId: 'uuid',\n  chunk: OutputChunk \n}\n\n// Client can request backfill\n{ type: 'output.backfill', agentId: 'uuid', fromSequence: 42 }\n```\n\n### REST Endpoint Design\n```\nGET /api/v1/agents/:agentId/output\nQuery params:\n  - limit: number (default 100, max 1000)\n  - cursor: string (for pagination)\n  - since: ISO timestamp (filter by time)\n  - streamType: stdout | stderr | system (filter by type)\n\nResponse:\n{\n  \"chunks\": [...],\n  \"cursor\": \"next-page-token\",\n  \"hasMore\": true\n}\n```\n\n### Performance Considerations\n- **Batching**: Group rapid output into larger chunks (every 50ms)\n- **Backpressure**: Handle slow consumers without blocking PTY\n- **Memory Limits**: Cap total buffer size per agent\n- **Connection Limits**: Max WebSocket connections per agent\n\n### Output Processing\n- **ANSI Parsing**: Optionally strip or preserve ANSI codes\n- **Line Detection**: Identify complete lines for structured display\n- **Content Detection**: Flag potential secrets in output\n- **Size Limits**: Truncate extremely large output chunks\n\n## Acceptance Criteria\n\n- [ ] PTY stdout/stderr is captured as output chunks\n- [ ] WebSocket endpoint accepts output subscriptions\n- [ ] Subscribed clients receive output chunks in real-time (\u003c100ms latency)\n- [ ] Ring buffer retains configurable number of recent chunks\n- [ ] REST endpoint returns paginated output history\n- [ ] Cursor-based pagination works correctly\n- [ ] Output chunks include sequence numbers for ordering\n- [ ] Clients can request backfill from specific sequence\n- [ ] Large output is batched to reduce message frequency\n- [ ] ANSI codes are preserved in raw output\n- [ ] Memory usage stays bounded under high output load\n- [ ] Unit tests for ring buffer operations\n- [ ] Integration test for subscribe -\u003e receive flow\n\n## File Locations\n\n### Core Service\n- `apps/gateway/src/services/output.service.ts` - Output capture and distribution\n\n### Buffering\n- `apps/gateway/src/services/output-buffer.ts` - Ring buffer implementation\n- `apps/gateway/src/services/output-persistence.ts` - Database persistence\n\n### WebSocket\n- `apps/gateway/src/websocket/output-streaming.ts` - WebSocket handlers\n- `apps/gateway/src/websocket/subscriptions.ts` - Subscription management\n\n### REST\n- `apps/gateway/src/routes/output.routes.ts` - Output endpoint registration\n- `apps/gateway/src/controllers/output.controller.ts` - Output retrieval handler\n\n### Types\n- `packages/shared-types/src/output.types.ts` - Output chunk interfaces\n\n### Utilities\n- `apps/gateway/src/utils/ansi-parser.ts` - ANSI code handling\n\n## Reference\n\n- PLAN.md §19: Output Management\n- xterm.js integration patterns\n- WebSocket streaming best practices\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Ring buffer append/trim logic preserves ordering and enforces size limits\n- [ ] Cursor semantics: resume from cursor returns exactly-once stream slice\n- [ ] Backpressure strategy (drop/slow/queue) behaves deterministically under load\n\n### Integration Tests\n- [ ] Stream output over WebSocket; disconnect/reconnect with cursor → no gaps, no duplicates\n- [ ] Output polling endpoint returns consistent results with the streaming buffer\n\n### Failure Mode Tests\n- [ ] Cursor expired → correct error code + hint; client can recover by full reload\n\n### Logging\n- [ ] Logs include correlationId + agentId + cursor + buffer sizes; output content is not logged\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:31:58.527296664-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:29:08.780790322-05:00","dependencies":[{"issue_id":"flywheel_gateway-6ix","depends_on_id":"flywheel_gateway-398","type":"blocks","created_at":"2026-01-08T14:01:54.215278628-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6ix","depends_on_id":"flywheel_gateway-46c","type":"blocks","created_at":"2026-01-08T14:01:55.217456532-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-6ld","title":"Pipeline Engine","description":"## Background\n\nComplex AI workflows often require orchestrating multiple agents in sequence or parallel, with conditional logic, approval gates, and variable passing between steps. A pipeline engine provides a declarative way to define these multi-step workflows, enabling sophisticated automation without custom code while maintaining visibility into execution state.\n\n## Problem Statement\n\nCurrently, orchestrating multi-agent workflows requires custom application code, making it difficult to:\n- Define reusable workflow templates\n- Track execution progress across multiple steps\n- Handle failures with proper retry and fallback logic\n- Implement human-in-the-loop approval gates\n- Manage variable context between steps\n- Visualize and debug complex workflows\n\n## Technical Approach\n\n### Pipeline Definition Schema\n\n```typescript\n// apps/gateway/src/types/pipeline.types.ts\n\ninterface Pipeline {\n  id: string;\n  orgId: string;\n  name: string;\n  description?: string;\n  version: number;\n  status: 'draft' | 'published' | 'deprecated';\n  \n  // Pipeline structure\n  trigger: PipelineTrigger;\n  inputs: PipelineInput[];\n  steps: PipelineStep[];\n  outputs: PipelineOutput[];\n  \n  // Configuration\n  config: PipelineConfig;\n  \n  // Metadata\n  createdAt: Date;\n  updatedAt: Date;\n  createdBy: string;\n  publishedAt?: Date;\n}\n\ninterface PipelineTrigger {\n  type: 'manual' | 'schedule' | 'webhook' | 'event';\n  config: TriggerConfig;\n}\n\ninterface ScheduleTrigger {\n  type: 'schedule';\n  config: {\n    cron: string;  // Cron expression\n    timezone: string;\n    enabled: boolean;\n  };\n}\n\ninterface WebhookTrigger {\n  type: 'webhook';\n  config: {\n    path: string;  // Unique webhook path\n    secret?: string;\n    allowedIPs?: string[];\n    validatePayload?: boolean;\n  };\n}\n\ninterface EventTrigger {\n  type: 'event';\n  config: {\n    eventTypes: string[];  // e.g., ['bead.created', 'agent.completed']\n    filters?: Record\u003cstring, any\u003e;\n  };\n}\n\ninterface PipelineInput {\n  name: string;\n  type: 'string' | 'number' | 'boolean' | 'object' | 'array';\n  required: boolean;\n  default?: any;\n  description?: string;\n  validation?: ValidationRule[];\n}\n\ninterface PipelineConfig {\n  timeout: number;  // Overall pipeline timeout (ms)\n  retryPolicy: RetryPolicy;\n  errorHandling: 'fail_fast' | 'continue' | 'custom';\n  concurrencyLimit?: number;  // Max parallel executions\n  variables: Record\u003cstring, any\u003e;  // Global variables\n}\n```\n\n### Step Types\n\n```typescript\n// Step type definitions\n\ntype PipelineStep = \n  | AgentStep\n  | ParallelStep\n  | ConditionalStep\n  | LoopStep\n  | WaitStep\n  | ApprovalStep\n  | TransformStep\n  | WebhookStep\n  | SubPipelineStep;\n\ninterface BaseStep {\n  id: string;\n  name: string;\n  description?: string;\n  dependsOn?: string[];  // Step IDs this step depends on\n  condition?: StepCondition;  // Skip condition\n  timeout?: number;\n  retryPolicy?: RetryPolicy;\n  onError?: ErrorHandler;\n}\n\n// Agent step - invoke an AI agent\ninterface AgentStep extends BaseStep {\n  type: 'agent';\n  config: {\n    agentId: string;\n    prompt: string;  // Supports variable substitution\n    systemPrompt?: string;\n    model?: string;  // Override agent default\n    temperature?: number;\n    maxTokens?: number;\n    tools?: string[];\n    outputVariable: string;  // Store result in this variable\n  };\n}\n\n// Parallel step - execute multiple branches simultaneously\ninterface ParallelStep extends BaseStep {\n  type: 'parallel';\n  config: {\n    branches: PipelineStep[][];  // Array of step sequences\n    joinMode: 'all' | 'any' | 'n_of_m';  // How to wait\n    nRequired?: number;  // For 'n_of_m' mode\n    failFast: boolean;  // Cancel other branches on failure\n    outputVariable: string;  // Array of branch results\n  };\n}\n\n// Conditional step - if/else branching\ninterface ConditionalStep extends BaseStep {\n  type: 'conditional';\n  config: {\n    condition: StepCondition;\n    ifTrue: PipelineStep[];\n    ifFalse?: PipelineStep[];\n    outputVariable?: string;\n  };\n}\n\n// Loop step - iterate over collection or until condition\ninterface LoopStep extends BaseStep {\n  type: 'loop';\n  config: {\n    mode: 'for_each' | 'while' | 'until' | 'times';\n    collection?: string;  // Variable reference for for_each\n    condition?: StepCondition;  // For while/until\n    maxIterations: number;  // Safety limit\n    parallel?: boolean;  // Execute iterations in parallel\n    parallelLimit?: number;\n    itemVariable: string;  // Current item variable name\n    indexVariable: string;  // Current index variable name\n    steps: PipelineStep[];\n    outputVariable: string;  // Array of iteration results\n  };\n}\n\n// Wait step - pause execution\ninterface WaitStep extends BaseStep {\n  type: 'wait';\n  config: {\n    mode: 'duration' | 'until' | 'webhook';\n    duration?: number;  // Milliseconds\n    until?: Date | string;  // ISO date or variable\n    webhookToken?: string;  // Resume via webhook\n    timeout: number;\n  };\n}\n\n// Approval step - human in the loop\ninterface ApprovalStep extends BaseStep {\n  type: 'approval';\n  config: {\n    approvers: ApproverConfig;\n    message: string;  // Supports variable substitution\n    timeout: number;  // Auto-reject after timeout\n    timeoutAction: 'reject' | 'approve' | 'escalate';\n    escalateTo?: string[];  // User IDs for escalation\n    requireComment: boolean;\n    data?: Record\u003cstring, any\u003e;  // Data to show approvers\n    outputVariable: string;  // Approval result\n  };\n}\n\ninterface ApproverConfig {\n  type: 'user' | 'role' | 'team' | 'any';\n  ids?: string[];  // User/role/team IDs\n  minApprovals?: number;  // For multiple approvers\n}\n\n// Transform step - data manipulation\ninterface TransformStep extends BaseStep {\n  type: 'transform';\n  config: {\n    operations: TransformOperation[];\n    outputVariable: string;\n  };\n}\n\ntype TransformOperation = \n  | { op: 'set'; path: string; value: any }\n  | { op: 'delete'; path: string }\n  | { op: 'merge'; source: string; target: string }\n  | { op: 'map'; source: string; expression: string; target: string }\n  | { op: 'filter'; source: string; condition: string; target: string }\n  | { op: 'reduce'; source: string; expression: string; initial: any; target: string }\n  | { op: 'jmespath'; source: string; query: string; target: string };\n\n// Webhook step - call external service\ninterface WebhookStep extends BaseStep {\n  type: 'webhook';\n  config: {\n    url: string;\n    method: 'GET' | 'POST' | 'PUT' | 'PATCH' | 'DELETE';\n    headers?: Record\u003cstring, string\u003e;\n    body?: any;  // Supports variable substitution\n    auth?: WebhookAuth;\n    validateStatus?: number[];\n    outputVariable: string;\n    extractFields?: Record\u003cstring, string\u003e;  // JMESPath extractions\n  };\n}\n\n// Sub-pipeline step - invoke another pipeline\ninterface SubPipelineStep extends BaseStep {\n  type: 'sub_pipeline';\n  config: {\n    pipelineId: string;\n    version?: number;  // Specific version or latest\n    inputs: Record\u003cstring, any\u003e;  // Variable mapping\n    outputVariable: string;\n  };\n}\n```\n\n### Condition Expressions\n\n```typescript\n// Condition evaluation for branching and skipping\n\ninterface StepCondition {\n  type: 'expression' | 'comparison' | 'all' | 'any' | 'not';\n  \n  // For expression type - JavaScript-like expression\n  expression?: string;  // e.g., \"steps.classify.output.category === 'urgent'\"\n  \n  // For comparison type\n  left?: string | number | boolean;\n  operator?: '==' | '!=' | '\u003e' | '\u003c' | '\u003e=' | '\u003c=' | 'contains' | 'matches';\n  right?: string | number | boolean;\n  \n  // For logical operators\n  conditions?: StepCondition[];\n}\n\n// Variable substitution syntax\n// \\${variable.path} - direct substitution\n// \\${variable.path | filter} - with filter (e.g., uppercase, json, default:value)\n// {{#if condition}}...{{/if}} - conditional blocks in prompts\n\nclass ConditionEvaluator {\n  evaluate(condition: StepCondition, context: ExecutionContext): boolean {\n    switch (condition.type) {\n      case 'expression':\n        return this.evaluateExpression(condition.expression!, context);\n      case 'comparison':\n        return this.evaluateComparison(condition, context);\n      case 'all':\n        return condition.conditions!.every(c =\u003e this.evaluate(c, context));\n      case 'any':\n        return condition.conditions!.some(c =\u003e this.evaluate(c, context));\n      case 'not':\n        return !this.evaluate(condition.conditions![0], context);\n    }\n  }\n}\n```\n\n### Pipeline Execution Engine\n\n```typescript\n// apps/gateway/src/services/pipeline.service.ts\n\ninterface PipelineRun {\n  id: string;\n  pipelineId: string;\n  pipelineVersion: number;\n  status: PipelineRunStatus;\n  \n  // Execution state\n  inputs: Record\u003cstring, any\u003e;\n  variables: Record\u003cstring, any\u003e;  // Runtime variables\n  stepResults: Map\u003cstring, StepResult\u003e;\n  outputs?: Record\u003cstring, any\u003e;\n  \n  // Timing\n  startedAt: Date;\n  completedAt?: Date;\n  \n  // Current state\n  currentSteps: string[];  // Currently executing step IDs\n  completedSteps: string[];\n  pendingSteps: string[];\n  \n  // Error tracking\n  errors: PipelineError[];\n  \n  // Metadata\n  triggeredBy: string;\n  triggerType: string;\n}\n\ntype PipelineRunStatus = \n  | 'pending'\n  | 'running'\n  | 'paused'      // Waiting for approval or webhook\n  | 'completed'\n  | 'failed'\n  | 'cancelled'\n  | 'timeout';\n\ninterface StepResult {\n  stepId: string;\n  status: 'pending' | 'running' | 'completed' | 'failed' | 'skipped';\n  startedAt?: Date;\n  completedAt?: Date;\n  duration?: number;\n  output?: any;\n  error?: {\n    code: string;\n    message: string;\n    details?: any;\n  };\n  retryCount: number;\n}\n\nclass PipelineExecutionService {\n  async startRun(pipelineId: string, inputs: Record\u003cstring, any\u003e): Promise\u003cPipelineRun\u003e {\n    const pipeline = await this.getPipeline(pipelineId);\n    \n    // Validate inputs\n    this.validateInputs(pipeline.inputs, inputs);\n    \n    // Create run record\n    const run = await this.createRun(pipeline, inputs);\n    \n    // Start execution\n    this.executeAsync(run.id);\n    \n    return run;\n  }\n  \n  private async executeStep(run: PipelineRun, step: PipelineStep): Promise\u003cStepResult\u003e {\n    // Check condition\n    if (step.condition \u0026\u0026 !this.evaluateCondition(step.condition, run)) {\n      return { stepId: step.id, status: 'skipped', retryCount: 0 };\n    }\n    \n    const executor = this.getStepExecutor(step.type);\n    \n    try {\n      const result = await executor.execute(step, run);\n      \n      // Store output variable\n      if (step.config.outputVariable) {\n        run.variables[step.config.outputVariable] = result.output;\n      }\n      \n      return result;\n    } catch (error) {\n      if (this.shouldRetry(step, error)) {\n        return this.retryStep(run, step);\n      }\n      throw error;\n    }\n  }\n  \n  private async executeParallel(run: PipelineRun, step: ParallelStep): Promise\u003cStepResult\u003e {\n    const branchPromises = step.config.branches.map(async (branch, index) =\u003e {\n      const results: StepResult[] = [];\n      for (const branchStep of branch) {\n        results.push(await this.executeStep(run, branchStep));\n      }\n      return results;\n    });\n    \n    let results: StepResult[][];\n    \n    switch (step.config.joinMode) {\n      case 'all':\n        results = await Promise.all(branchPromises);\n        break;\n      case 'any':\n        results = [await Promise.race(branchPromises.map(p =\u003e p.then(r =\u003e [r])))];\n        break;\n      case 'n_of_m':\n        results = await this.waitForN(branchPromises, step.config.nRequired!);\n        break;\n    }\n    \n    return {\n      stepId: step.id,\n      status: 'completed',\n      output: results,\n      retryCount: 0,\n    };\n  }\n  \n  async resumeFromApproval(runId: string, approvalResult: ApprovalResult): Promise\u003cvoid\u003e {\n    const run = await this.getRun(runId);\n    const pendingApproval = this.findPendingApprovalStep(run);\n    \n    // Update step result\n    run.stepResults.set(pendingApproval.id, {\n      stepId: pendingApproval.id,\n      status: 'completed',\n      output: approvalResult,\n      retryCount: 0,\n    });\n    \n    // Continue execution\n    await this.continueExecution(run);\n  }\n}\n```\n\n### Variable Substitution\n\n```typescript\n// apps/gateway/src/services/variable-substitution.service.ts\n\nclass VariableSubstitutionService {\n  // Substitute variables in string values\n  substitute(template: string, context: ExecutionContext): string {\n    // Handle \\${variable.path} syntax\n    let result = template.replace(/\\$\\{([^}]+)\\}/g, (match, path) =\u003e {\n      const [varPath, ...filters] = path.split('|').map((s: string) =\u003e s.trim());\n      let value = this.resolvePath(varPath, context);\n      \n      for (const filter of filters) {\n        value = this.applyFilter(value, filter);\n      }\n      \n      return String(value);\n    });\n    \n    // Handle {{#if condition}}...{{/if}} blocks\n    result = this.processConditionalBlocks(result, context);\n    \n    return result;\n  }\n  \n  private resolvePath(path: string, context: ExecutionContext): any {\n    const parts = path.split('.');\n    let current: any = context;\n    \n    for (const part of parts) {\n      if (current === undefined || current === null) return undefined;\n      \n      // Handle special prefixes\n      if (part === 'inputs') current = context.inputs;\n      else if (part === 'steps') current = context.stepResults;\n      else if (part === 'vars') current = context.variables;\n      else if (part === 'env') current = context.environment;\n      else current = current[part];\n    }\n    \n    return current;\n  }\n  \n  private applyFilter(value: any, filter: string): any {\n    const [filterName, ...args] = filter.split(':');\n    \n    switch (filterName) {\n      case 'uppercase':\n        return String(value).toUpperCase();\n      case 'lowercase':\n        return String(value).toLowerCase();\n      case 'json':\n        return JSON.stringify(value);\n      case 'default':\n        return value ?? args.join(':');\n      case 'truncate':\n        return String(value).slice(0, parseInt(args[0]));\n      case 'first':\n        return Array.isArray(value) ? value[0] : value;\n      case 'last':\n        return Array.isArray(value) ? value[value.length - 1] : value;\n      case 'length':\n        return Array.isArray(value) ? value.length : String(value).length;\n      default:\n        return value;\n    }\n  }\n}\n```\n\n### Pipeline Run History\n\n```typescript\n// Database schema for pipeline runs\n\ninterface PipelineRunRepository {\n  // Create and update\n  create(run: PipelineRun): Promise\u003cPipelineRun\u003e;\n  update(runId: string, updates: Partial\u003cPipelineRun\u003e): Promise\u003cPipelineRun\u003e;\n  updateStepResult(runId: string, stepId: string, result: StepResult): Promise\u003cvoid\u003e;\n  \n  // Query\n  findById(runId: string): Promise\u003cPipelineRun | null\u003e;\n  findByPipeline(pipelineId: string, options: QueryOptions): Promise\u003cPaginatedResult\u003cPipelineRun\u003e\u003e;\n  findByStatus(status: PipelineRunStatus, options: QueryOptions): Promise\u003cPaginatedResult\u003cPipelineRun\u003e\u003e;\n  \n  // Analytics\n  getRunStats(pipelineId: string, dateRange: DateRange): Promise\u003cPipelineStats\u003e;\n  getStepPerformance(pipelineId: string): Promise\u003cStepPerformanceStats[]\u003e;\n}\n```\n\n### Visual Pipeline Designer\n\n```typescript\n// apps/web/src/components/pipelines/PipelineDesigner.tsx\n\ninterface PipelineDesignerState {\n  pipeline: Pipeline;\n  selectedStep: string | null;\n  isDragging: boolean;\n  zoom: number;\n  pan: { x: number; y: number };\n}\n\n// React Flow based visual editor\ninterface PipelineNode {\n  id: string;\n  type: 'agent' | 'parallel' | 'conditional' | 'loop' | 'wait' | 'approval' | 'transform' | 'webhook';\n  position: { x: number; y: number };\n  data: PipelineStep;\n}\n\ninterface PipelineEdge {\n  id: string;\n  source: string;\n  target: string;\n  type: 'default' | 'conditional' | 'loop_back';\n  label?: string;\n  animated?: boolean;\n}\n\n// Component structure\n// PipelineDesigner/\n//   Canvas.tsx           - React Flow canvas\n//   Toolbar.tsx          - Add step, zoom controls\n//   StepPalette.tsx      - Draggable step types\n//   StepNode.tsx         - Rendered step in canvas\n//   StepConfigPanel.tsx  - Step configuration sidebar\n//   VariablePanel.tsx    - Input/output variable management\n//   RunPanel.tsx         - Test run interface\n//   nodes/\n//     AgentNode.tsx\n//     ParallelNode.tsx\n//     ConditionalNode.tsx\n//     LoopNode.tsx\n//     WaitNode.tsx\n//     ApprovalNode.tsx\n//     WebhookNode.tsx\n//   utils/\n//     layoutEngine.ts  - Dagre auto-layout\n//     validation.ts    - Pipeline validation\n//     serialization.ts - Convert to/from JSON\n```\n\n### API Endpoints\n\n```typescript\n// Pipeline CRUD\nGET    /api/v1/pipelines                      // List pipelines\nPOST   /api/v1/pipelines                      // Create pipeline\nGET    /api/v1/pipelines/:id                  // Get pipeline\nPUT    /api/v1/pipelines/:id                  // Update pipeline\nDELETE /api/v1/pipelines/:id                  // Delete pipeline\nPOST   /api/v1/pipelines/:id/publish          // Publish pipeline\nPOST   /api/v1/pipelines/:id/duplicate        // Clone pipeline\n\n// Pipeline versions\nGET    /api/v1/pipelines/:id/versions         // List versions\nGET    /api/v1/pipelines/:id/versions/:ver    // Get specific version\n\n// Pipeline runs\nPOST   /api/v1/pipelines/:id/runs             // Start run\nGET    /api/v1/pipelines/:id/runs             // List runs\nGET    /api/v1/pipelines/:id/runs/:runId      // Get run details\nPOST   /api/v1/pipelines/:id/runs/:runId/cancel  // Cancel run\nPOST   /api/v1/pipelines/:id/runs/:runId/retry   // Retry failed run\n\n// Approval handling\nPOST   /api/v1/pipeline-approvals/:approvalId/approve\nPOST   /api/v1/pipeline-approvals/:approvalId/reject\nGET    /api/v1/pipeline-approvals/pending     // List pending approvals\n\n// Webhooks for triggers and resume\nPOST   /api/v1/pipelines/webhook/:path        // Webhook trigger\nPOST   /api/v1/pipelines/resume/:token        // Resume from wait\n\n// Analytics\nGET    /api/v1/pipelines/:id/stats            // Pipeline statistics\nGET    /api/v1/pipelines/:id/step-performance // Step performance metrics\n```\n\n## File Locations\n\n- apps/gateway/src/services/pipeline.service.ts - Core pipeline service\n- apps/gateway/src/services/pipeline-execution.service.ts - Execution engine\n- apps/gateway/src/services/pipeline-scheduler.service.ts - Scheduled triggers\n- apps/gateway/src/services/variable-substitution.service.ts - Variable handling\n- apps/gateway/src/services/step-executors/ - Step type executors\n  - agent.executor.ts\n  - parallel.executor.ts\n  - conditional.executor.ts\n  - loop.executor.ts\n  - wait.executor.ts\n  - approval.executor.ts\n  - transform.executor.ts\n  - webhook.executor.ts\n- apps/gateway/src/controllers/pipeline.controller.ts - API controller\n- apps/gateway/src/types/pipeline.types.ts - Type definitions\n- apps/web/src/components/pipelines/PipelineDesigner.tsx - Visual designer\n- apps/web/src/components/pipelines/PipelineList.tsx - Pipeline listing\n- apps/web/src/components/pipelines/PipelineRunViewer.tsx - Run details\n- apps/web/src/components/pipelines/ApprovalQueue.tsx - Pending approvals\n- packages/shared/src/types/pipeline.ts - Shared types\n\n## Dependencies\n\n- reactflow: Visual pipeline designer\n- dagre: Graph layout algorithm\n- cron-parser: Schedule expression parsing\n- safe-eval: Sandboxed expression evaluation\n- handlebars: Template processing\n- ajv: JSON schema validation for inputs\n\n## Acceptance Criteria\n\n1. Pipelines can be created via API and visual designer\n2. All step types execute correctly (agent, parallel, conditional, loop, wait, approval, transform, webhook)\n3. Variable substitution works in prompts and configurations\n4. Parallel execution respects join modes (all, any, n_of_m)\n5. Approval steps pause execution and notify approvers\n6. Pipeline runs can be cancelled mid-execution\n7. Failed steps retry according to retry policy\n8. Pipeline run history is queryable and searchable\n9. Visual designer supports drag-and-drop step placement\n10. Step connections are validated (no cycles except loops)\n11. Scheduled pipelines trigger on configured cron expressions\n12. Webhook triggers work with optional payload validation\n13. Performance: Pipeline with 50 steps starts within 1 second\n14. Sub-pipeline invocation works with variable passing\n\n## Testing Strategy\n\n- Unit tests for each step executor\n- Integration tests for complete pipeline execution\n- E2E tests for visual designer\n- Load tests for concurrent pipeline runs\n- Timeout and cancellation tests\n- Error handling and retry tests\n\n## Reference\n\nPLAN.md section 20 - Pipeline Engine\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Pipeline schema validation rejects invalid graphs and produces actionable diagnostics\n- [ ] Dependency resolution executes steps in correct order and supports parallel branches\n- [ ] Retry/backoff policies and fail-fast/continue modes behave deterministically\n- [ ] Resume logic restores state correctly and never replays completed side effects\n\n### Integration Tests\n- [ ] Execute a multi-step workflow end-to-end (including at least one parallel branch and one approval gate)\n- [ ] WebSocket progress events can be replayed/resumed via cursor\n\n### Failure Mode Tests\n- [ ] Step timeout/cancellation propagates correctly and leaves workflow in a consistent terminal state\n\n### Logging\n- [ ] Logs include correlationId + pipelineId + runId + stepId + timings; prompts are redacted by default\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Pipeline: creates from definition\n- [ ] Pipeline: validates step order\n- [ ] Step: executes action\n- [ ] Step: passes output to next\n- [ ] Condition: evaluates expression\n- [ ] Condition: branches correctly\n- [ ] Retry: attempts on failure\n- [ ] Retry: applies backoff\n- [ ] Retry: respects max attempts\n- [ ] Variable: substitutes in steps\n- [ ] Template: loads from library\n- [ ] Progress: calculates percentage\n\n### Integration Tests\n- [ ] POST /pipelines creates pipeline\n- [ ] POST /pipelines/:id/run starts execution\n- [ ] GET /pipelines/:id/runs/:runId status\n- [ ] Steps execute in sequence\n- [ ] Condition branches work\n- [ ] Retry recovers from failure\n- [ ] WebSocket progress events\n\n### E2E Tests\n- [ ] Create pipeline in UI\n- [ ] Run pipeline and watch progress\n- [ ] Pipeline handles step failure\n- [ ] View run history\n\n### Performance Tests\n- [ ] Step handoff \u003c100ms\n- [ ] Progress updates real-time\n- [ ] Large pipeline (50 steps) works\n- [ ] Concurrent pipelines scale\n\n### Failure Mode Tests\n- [ ] Step timeout: marked failed\n- [ ] All retries exhausted: pipeline fails\n- [ ] Invalid step config: validation error\n- [ ] Pipeline cancel: cleanup runs","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:59:40.018139985-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:06:30.604763606-05:00","dependencies":[{"issue_id":"flywheel_gateway-6ld","depends_on_id":"flywheel_gateway-6wp","type":"blocks","created_at":"2026-01-08T14:01:53.416988863-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6ld","depends_on_id":"flywheel_gateway-89x","type":"blocks","created_at":"2026-01-08T14:01:54.12838387-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6ld","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T17:51:29.753037175-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6ld","depends_on_id":"flywheel_gateway-7n4","type":"blocks","created_at":"2026-01-08T17:51:34.788544135-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-6mn","title":"FEAT: Database Schema and Drizzle Setup","description":"## Overview\n\nflywheel_gateway uses **SQLite with Drizzle ORM** for persistent storage. This combination provides type-safe database access, automatic migration management, and excellent performance for the gateway's workload characteristics. WAL (Write-Ahead Logging) mode enables concurrent read/write access without blocking.\n\n## Background \u0026 Reasoning\n\n### Why SQLite?\n\n1. **Simplicity**: Single-file database with no external dependencies\n2. **Bun-Native**: First-class SQLite support in Bun runtime via `bun:sqlite`\n3. **Performance**: Sub-millisecond queries for typical workloads\n4. **WAL Mode**: Concurrent readers don't block writers (and vice versa)\n5. **Portability**: Easy backup, replication, and disaster recovery\n6. **Proven Scale**: SQLite handles millions of rows with proper indexing\n\n### Why Drizzle ORM?\n\n1. **Type Safety**: Full TypeScript inference from schema to queries\n2. **SQL-Like API**: Familiar syntax, no magic strings\n3. **Migrations**: Drizzle-kit generates and applies migrations\n4. **Performance**: Minimal overhead compared to raw SQL\n5. **Bun Support**: Native integration with Bun's SQLite driver\n\n## Technical Architecture\n\n### Database Tables\n\nAll tables from PLAN.md §29.1:\n\n#### Core Tables\n\n| Table | Purpose | Key Columns |\n|-------|---------|-------------|\n| `agents` | Active and historical agent records | id, repoUrl, task, status, model, createdAt |\n| `checkpoints` | Agent state snapshots for resume | id, agentId, state, createdAt |\n| `accounts` | User accounts and API keys | id, email, apiKeyHash, role, createdAt |\n| `history` | Command execution history | id, agentId, command, input, output, durationMs |\n\n#### Monitoring \u0026 Audit Tables\n\n| Table | Purpose | Key Columns |\n|-------|---------|-------------|\n| `alerts` | System alerts and notifications | id, severity, message, acknowledged, createdAt |\n| `auditLogs` | Security and compliance audit trail | id, accountId, action, resource, metadata, createdAt |\n\n#### DCG (Derived Code Governance) Tables\n\n| Table | Purpose | Key Columns |\n|-------|---------|-------------|\n| `dcgBlocks` | Blocked operations and reasons | id, pattern, reason, createdBy, createdAt |\n| `dcgAllowlist` | Explicitly allowed operations | id, pattern, approvedBy, expiresAt |\n\n#### Fleet Management Tables\n\n| Table | Purpose | Key Columns |\n|-------|---------|-------------|\n| `fleetRepos` | Repositories in the managed fleet | id, url, branch, lastSyncAt, status |\n| `agentSweeps` | Bulk agent operations | id, query, action, status, affectedCount |\n\n### Schema Definition\n\n```typescript\n// apps/gateway/src/db/schema.ts\nimport { sqliteTable, text, integer, blob } from 'drizzle-orm/sqlite-core';\n\nexport const agents = sqliteTable('agents', {\n  id: text('id').primaryKey(),\n  repoUrl: text('repo_url').notNull(),\n  task: text('task').notNull(),\n  status: text('status').notNull().default('idle'),\n  model: text('model').notNull().default('sonnet-4'),\n  accountId: text('account_id').references(() =\u003e accounts.id),\n  createdAt: integer('created_at', { mode: 'timestamp' }).notNull(),\n  updatedAt: integer('updated_at', { mode: 'timestamp' }).notNull(),\n});\n\nexport const checkpoints = sqliteTable('checkpoints', {\n  id: text('id').primaryKey(),\n  agentId: text('agent_id').references(() =\u003e agents.id).notNull(),\n  state: blob('state', { mode: 'json' }).notNull(),\n  createdAt: integer('created_at', { mode: 'timestamp' }).notNull(),\n});\n\n// ... additional tables\n```\n\n### Index Strategy\n\nIndexes are created for frequently queried columns:\n\n```typescript\n// apps/gateway/src/db/schema.ts\nimport { index } from 'drizzle-orm/sqlite-core';\n\nexport const agentsIndexes = {\n  statusIdx: index('agents_status_idx').on(agents.status),\n  accountIdx: index('agents_account_idx').on(agents.accountId),\n  createdAtIdx: index('agents_created_at_idx').on(agents.createdAt),\n};\n\nexport const historyIndexes = {\n  agentIdx: index('history_agent_idx').on(history.agentId),\n  commandIdx: index('history_command_idx').on(history.command),\n  createdAtIdx: index('history_created_at_idx').on(history.createdAt),\n};\n\nexport const auditLogsIndexes = {\n  accountIdx: index('audit_logs_account_idx').on(auditLogs.accountId),\n  actionIdx: index('audit_logs_action_idx').on(auditLogs.action),\n  createdAtIdx: index('audit_logs_created_at_idx').on(auditLogs.createdAt),\n};\n```\n\n### Drizzle-kit for Migrations\n\n```typescript\n// drizzle.config.ts\nimport type { Config } from 'drizzle-kit';\n\nexport default {\n  schema: './apps/gateway/src/db/schema.ts',\n  out: './apps/gateway/src/db/migrations',\n  driver: 'bun-sqlite',\n  dbCredentials: {\n    url: './data/gateway.db',\n  },\n} satisfies Config;\n```\n\nMigration commands:\n- `bun drizzle-kit generate` - Generate migration from schema changes\n- `bun drizzle-kit migrate` - Apply pending migrations\n- `bun drizzle-kit push` - Push schema directly (dev only)\n\n### WAL Mode Configuration\n\n```typescript\n// apps/gateway/src/db/connection.ts\nimport { Database } from 'bun:sqlite';\nimport { drizzle } from 'drizzle-orm/bun-sqlite';\n\nconst sqlite = new Database('./data/gateway.db');\nsqlite.exec('PRAGMA journal_mode = WAL');\nsqlite.exec('PRAGMA synchronous = NORMAL');\nsqlite.exec('PRAGMA foreign_keys = ON');\n\nexport const db = drizzle(sqlite);\n```\n\n## File Locations\n\n```\napps/gateway/src/db/\n├── schema.ts            # Table definitions\n├── indexes.ts           # Index definitions\n├── connection.ts        # Database connection setup\n├── migrations/          # Generated migrations\n│   ├── 0000_initial.sql\n│   ├── 0001_add_dcg_tables.sql\n│   └── meta/\n└── queries/\n    ├── agents.ts        # Agent-related queries\n    ├── checkpoints.ts   # Checkpoint queries\n    ├── accounts.ts      # Account queries\n    └── audit.ts         # Audit log queries\n```\n\n## Testing Requirements\n\n### Unit Tests\n\n- [ ] Schema validation tests\n  - All required columns are defined\n  - Foreign key relationships are correct\n  - Default values work as expected\n- [ ] Type inference tests\n  - Insert types match schema\n  - Select types match schema\n  - Nullable columns are properly typed\n\n### Migration Tests\n\n- [ ] Up migrations apply cleanly to empty database\n- [ ] Down migrations revert changes correctly\n- [ ] Migrations are idempotent (can be re-run safely)\n- [ ] Data is preserved through migration cycles\n\n### Integration Tests\n\n- [ ] CRUD operations for each table\n  - Create: Insert records with all field combinations\n  - Read: Query by primary key and indexed columns\n  - Update: Modify records and verify changes\n  - Delete: Remove records and verify cascade behavior\n- [ ] Transaction tests\n  - Commits persist data\n  - Rollbacks revert changes\n  - Concurrent transactions don't corrupt data\n\n### Performance Tests\n\n- [ ] Index usage verification via EXPLAIN QUERY PLAN\n- [ ] Query performance benchmarks for typical workloads\n- [ ] Bulk insert performance (1000+ records)\n- [ ] Concurrent read/write performance under WAL mode\n\n## Logging Requirements\n\n### Query Logging (Development Mode)\n\n```typescript\n// Enabled when NODE_ENV=development\nlogger.debug('db:query', {\n  sql: 'SELECT * FROM agents WHERE status = ?',\n  params: ['running'],\n  durationMs: 0.42,\n});\n```\n\n### Slow Query Logging\n\n```typescript\n// Queries exceeding threshold (default: 100ms)\nlogger.warn('db:slow-query', {\n  sql: 'SELECT * FROM history WHERE agent_id = ?',\n  params: ['agent-123'],\n  durationMs: 156,\n  threshold: 100,\n});\n```\n\n### Migration Logging\n\n```typescript\nlogger.info('db:migration:start', {\n  migration: '0001_add_dcg_tables',\n  direction: 'up',\n});\n\nlogger.info('db:migration:complete', {\n  migration: '0001_add_dcg_tables',\n  direction: 'up',\n  durationMs: 23,\n});\n```\n\n## Acceptance Criteria\n\n- [ ] All tables from PLAN.md §29.1 are defined in schema\n- [ ] Drizzle schema compiles without errors\n- [ ] Initial migration creates all tables\n- [ ] WAL mode is enabled and working\n- [ ] Foreign key constraints are enforced\n- [ ] Indexes exist for frequently queried columns\n- [ ] CRUD operations work for all tables\n- [ ] Query logging works in development mode\n- [ ] Slow query logging triggers above threshold\n- [ ] Migration up/down cycle preserves data integrity\n- [ ] Concurrent read/write operations don't block\n- [ ] Database file is created in correct location\n\n## References\n\n- PLAN.md §29.1 - Database Schema Specification\n- Drizzle ORM Documentation: https://orm.drizzle.team/\n- SQLite WAL Mode: https://www.sqlite.org/wal.html\n\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Schema: agents table has all required columns\n- [ ] Schema: checkpoints table foreign key to agents\n- [ ] Schema: accounts table has encrypted API key column\n- [ ] Schema: history table references agents correctly\n- [ ] Schema: alerts table has all severity levels\n- [ ] Schema: auditLogs table captures all required fields\n- [ ] Schema: dcgBlocks table links to agents\n- [ ] Schema: dcgAllowlist table has unique constraint on ruleId\n- [ ] Schema: fleetRepos table has unique constraint on path\n- [ ] Schema: agentSweeps table foreign keys valid\n- [ ] Migrations: up migration creates tables\n- [ ] Migrations: down migration drops tables cleanly\n- [ ] Drizzle queries: insert returns created record\n- [ ] Drizzle queries: select with filters works\n- [ ] Drizzle queries: update returns modified record\n- [ ] Drizzle queries: delete removes record\n\n### Integration Tests\n- [ ] Database file created on first run\n- [ ] Schema migrations run in order\n- [ ] Foreign key constraints enforced\n- [ ] Unique constraints prevent duplicates\n- [ ] Timestamp columns auto-populate\n- [ ] JSON columns store and retrieve objects\n- [ ] Blob columns store binary data\n- [ ] Connection pool handles concurrent queries\n- [ ] Transaction rollback on error\n- [ ] WAL mode enabled for SQLite\n\n### Performance Tests\n- [ ] Insert 1000 agents in \u003c1s\n- [ ] Query agents with filters \u003c10ms\n- [ ] Join checkpoints to agents \u003c20ms\n- [ ] Audit log insert doesn't block main operations\n- [ ] Database file size stays reasonable\n\n### Failure Mode Tests\n- [ ] Corrupted database: graceful error message\n- [ ] Disk full: appropriate error handling\n- [ ] Migration failure: rollback to previous state\n- [ ] Schema mismatch: clear error about version","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:29:45.643214551-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:59:59.580491474-05:00","dependencies":[{"issue_id":"flywheel_gateway-6mn","depends_on_id":"flywheel_gateway-2kf","type":"blocks","created_at":"2026-01-08T14:01:41.784913966-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6mn","depends_on_id":"flywheel_gateway-hnv","type":"blocks","created_at":"2026-01-08T18:04:09.021332265-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-6pm","title":"Improve CAAM auth management to align with BYOA/BYOK plan","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-07T23:46:20.778720353-05:00","created_by":"ubuntu","updated_at":"2026-01-08T10:49:50.513289968-05:00","closed_at":"2026-01-08T10:49:50.513289968-05:00","close_reason":"Implemented CAAM auth management updates and synced docs"}
{"id":"flywheel_gateway-6wp","title":"FEAT: Agent Performance Analytics","description":"## Background\n\nUnderstanding individual agent performance is critical for optimizing the Flywheel ecosystem. Organizations need visibility into which agents are most productive, which models perform best for specific task types, and where bottlenecks exist. This bead implements comprehensive agent performance analytics with AI-powered recommendations to help operators continuously improve their agent fleet.\n\n## Reasoning\n\nAgent performance analytics serves multiple stakeholders:\n- **Operators**: Identify underperforming agents, optimize configurations\n- **Efficiency**: Understand usage drivers and optimize model selection\n- **Engineering**: Debug issues, improve agent prompts and tooling\n- **Management**: Track ROI, make informed scaling decisions\n\nThe analytics must go beyond simple metrics to provide actionable insights. This means:\n- Aggregating raw events into meaningful KPIs\n- Comparing performance across dimensions (model, task type, time)\n- Detecting anomalies and trends automatically\n- Generating human-readable recommendations\n\n## Technical Considerations\n\n### Productivity Metrics\n\n**Tasks Completed:**\n- Count of tasks reaching terminal state (completed, failed, cancelled)\n- Breakdown by outcome: success vs failure vs timeout\n- Rolling averages: hourly, daily, weekly\n- Comparison to fleet average and historical self\n\n**Success Rate:**\n```typescript\ninterface SuccessRateMetric {\n  agent_id: string;\n  period: '1h' | '24h' | '7d' | '30d';\n  total_tasks: number;\n  successful_tasks: number;\n  success_rate: number; // 0-100\n  trend: 'improving' | 'stable' | 'declining';\n  percentile_rank: number; // vs other agents\n}\n```\n\n**Task Duration:**\n- Median, p95, p99 task completion times\n- Breakdown by task complexity tier\n- Time-in-state analysis (planning, executing, blocked)\n- Comparison to estimated duration from planning phase\n\n### Quality Metrics\n\n**Error Rate:**\n- Errors per 100 tasks\n- Error categorization: tool failure, model error, timeout, user cancel\n- Error clustering to identify systemic issues\n- Mean time between errors (MTBE)\n\n**Rollback Rate:**\n- Percentage of tasks requiring rollback\n- Partial vs full rollback breakdown\n- Rollback trigger analysis (user request, error, conflict)\n- Recovery success rate after rollback\n\n**Conflict Rate:**\n- Git merge conflicts encountered\n- Resource contention events\n- Conflict resolution success rate\n- Time spent resolving conflicts\n\n### Efficiency Metrics\n\n**Tokens Per Task:**\n```typescript\ninterface TokenEfficiencyMetric {\n  agent_id: string;\n  model: string;\n  avg_tokens_per_task: number;\n  avg_prompt_tokens: number;\n  avg_completion_tokens: number;\n  efficiency_score: number; // normalized 0-100\n  vs_fleet_average: number; // percentage difference\n}\n```\n\n**Usage Per Task:**\n- Total usage units across all model calls\n- Breakdown by model tier (fast vs capable)\n- Usage trend over time\n- Usage per successful task (excludes failures)\n\n**Context Utilization:**\n- Average context window usage percentage\n- Context overflow events\n- Summarization trigger frequency\n- Effective context (relevant tokens / total tokens)\n\n### Collaboration Metrics\n\n**Messages Exchanged:**\n- Inter-agent message count\n- Message types: coordination, handoff, query, response\n- Response latency between agents\n- Message success rate\n\n**Handoff Metrics:**\n- Handoff count per task\n- Handoff success rate\n- Average handoff latency\n- Handoff chain depth\n\n### Model Comparison Reports\n\n**Report Structure:**\n```typescript\ninterface ModelComparisonReport {\n  period: DateRange;\n  models: ModelPerformance[];\n  task_type_breakdown: TaskTypeComparison[];\n  cost_efficiency_matrix: CostEfficiencyData;\n  recommendations: ModelRecommendation[];\n}\n\ninterface ModelPerformance {\n  model: string;\n  tasks_completed: number;\n  success_rate: number;\n  avg_duration_seconds: number;\n  avg_tokens_used: number;\n  avg_cost_units: number;\n  quality_score: number; // composite metric\n}\n```\n\n**Comparison Dimensions:**\n- Success rate by task complexity\n- Speed vs quality tradeoff analysis\n- Cost efficiency by task type\n- Error pattern differences\n\n### AI-Generated Recommendations\n\n**Recommendation Engine:**\n```typescript\ninterface PerformanceRecommendation {\n  id: string;\n  agent_id: string;\n  category: 'configuration' | 'model_selection' | 'workload' | 'prompt';\n  priority: 'high' | 'medium' | 'low';\n  title: string;\n  description: string;\n  expected_improvement: string;\n  evidence: MetricEvidence[];\n  actions: RecommendedAction[];\n}\n```\n\n**Recommendation Categories:**\n1. **Model Selection**: \"Consider switching to claude-3-5-sonnet for code review tasks - 23% faster with same quality\"\n2. **Configuration**: \"Increase context limit to 100k - agent hitting context overflow on 15% of tasks\"\n3. **Workload**: \"Agent overloaded - reassign complex tasks to reduce queue depth\"\n4. **Prompt Optimization**: \"High retry rate on tool calls - consider adding examples to system prompt\"\n\n**Evidence Collection:**\n- Statistical significance testing\n- Confidence intervals on recommendations\n- A/B test support for validating changes\n- Before/after comparison tracking\n\n## Acceptance Criteria\n\n1. **Productivity Metrics**\n   - [ ] Real-time task completion tracking\n   - [ ] Success rate calculated with configurable windows\n   - [ ] Duration percentiles computed accurately\n   - [ ] Trend detection with statistical significance\n\n2. **Quality Metrics**\n   - [ ] Error categorization and clustering\n   - [ ] Rollback tracking with trigger analysis\n   - [ ] Conflict metrics with resolution tracking\n   - [ ] Quality score composite calculation\n\n3. **Efficiency Metrics**\n   - [ ] Token tracking per model call\n   - [ ] Cost/usage unit calculation uses configurable weighting (no embedded rate tables)\n   - [ ] Context utilization measurement\n   - [ ] Efficiency scoring and ranking\n\n4. **Collaboration Metrics**\n   - [ ] Message tracking between agents\n   - [ ] Handoff success measurement\n   - [ ] Latency tracking for coordination\n   - [ ] Collaboration graph visualization\n\n5. **Model Comparison**\n   - [ ] Side-by-side model performance\n   - [ ] Task-type specific analysis\n   - [ ] Statistical significance indicators\n   - [ ] Exportable comparison reports\n\n6. **AI Recommendations**\n   - [ ] Automated recommendation generation\n   - [ ] Evidence-based suggestions\n   - [ ] Priority ranking of recommendations\n   - [ ] Tracking of recommendation outcomes\n\n7. **Dashboard UI**\n   - [ ] Agent selector with search/filter\n   - [ ] Metric cards with sparklines\n   - [ ] Detailed drill-down views\n   - [ ] Recommendation panel with actions\n\n## File Locations\n\n### Backend Services\n- `apps/gateway/src/services/agent-analytics.service.ts` - Core analytics computation\n- `apps/gateway/src/services/agent-metrics-collector.service.ts` - Event aggregation\n- `apps/gateway/src/services/model-comparison.service.ts` - Model analysis\n- `apps/gateway/src/services/recommendation-engine.service.ts` - AI recommendations\n- `apps/gateway/src/controllers/agent-analytics.controller.ts` - Analytics API\n\n### Database\n- `packages/database/prisma/migrations/xxx_add_agent_analytics.sql` - Schema\n- Tables: `agent_metrics_hourly`, `agent_metrics_daily`, `model_comparisons`, `recommendations`\n\n### Frontend Components\n- `apps/web/src/components/analytics/AgentPerformanceDashboard.tsx` - Main dashboard\n- `apps/web/src/components/analytics/AgentMetricCard.tsx` - Individual metric display\n- `apps/web/src/components/analytics/ProductivityChart.tsx` - Productivity trends\n- `apps/web/src/components/analytics/QualityMetrics.tsx` - Quality breakdown\n- `apps/web/src/components/analytics/EfficiencyPanel.tsx` - Efficiency analysis\n- `apps/web/src/components/analytics/ModelComparisonTable.tsx` - Model comparison\n- `apps/web/src/components/analytics/RecommendationList.tsx` - AI suggestions\n\n### Types\n- `packages/types/src/analytics/agent-performance.ts` - Metric type definitions\n- `packages/types/src/analytics/recommendations.ts` - Recommendation types\n\n## References\n\n- PLAN.md §21.5 - Agent Performance Analytics\n- Statistical Methods: Welch's t-test for comparison, CUSUM for trend detection\n\n\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Aggregations (throughput, success rate, latency, usage units) compute correctly from raw events\n- [ ] Breakdown dimensions (task type, complexity tier, model tier) are stable and well-defined\n- [ ] Recommendation generation is deterministic for the same historical dataset\n\n### Integration Tests\n- [ ] Dashboard endpoints return validated responses and handle empty datasets gracefully\n\n### Failure Mode Tests\n- [ ] Missing/malformed historical records do not crash analytics; errors are surfaced with partial results where safe\n\n### Logging\n- [ ] Logs include correlationId + analyticsWindow + queryLatencyMs; no raw secrets in stored analytics\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] MetricsCollector: aggregates by model\n- [ ] MetricsCollector: aggregates by time period\n- [ ] ModelComparison: calculates success rate\n- [ ] ModelComparison: calculates avg tokens\n- [ ] ModelComparison: calculates avg duration\n- [ ] ProductivityTrend: daily/weekly/monthly\n- [ ] ProductivityTrend: rolling average\n- [ ] TokenPattern: usage by category\n- [ ] TokenPattern: peak hours detection\n- [ ] Recommendation: generates from patterns\n- [ ] Recommendation: prioritizes by impact\n- [ ] Chart data: formats for visualization\n\n### Integration Tests\n- [ ] GET /analytics/performance returns data\n- [ ] Model filter applied correctly\n- [ ] Time range filter works\n- [ ] Aggregate by project works\n- [ ] Historical data queryable\n- [ ] Real-time updates via WebSocket\n\n### E2E Tests\n- [ ] Dashboard shows model comparison\n- [ ] Trend chart updates over time\n- [ ] Drill down into specific model\n- [ ] Export data to CSV\n\n### Performance Tests\n- [ ] Analytics query \u003c500ms\n- [ ] Large dataset aggregation \u003c2s\n- [ ] Chart render smooth\n- [ ] Concurrent analytics requests\n\n### Failure Mode Tests\n- [ ] No data: shows empty state\n- [ ] Partial data: graceful handling\n- [ ] Invalid time range: validation\n- [ ] Service unavailable: cached data","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:56:40.390492006-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:06:51.275499907-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-6wp","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T14:01:45.343539662-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-6wp","depends_on_id":"flywheel_gateway-89x","type":"blocks","created_at":"2026-01-08T14:01:46.093376746-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-71w","title":"feat","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:46:50.273859739-05:00","created_by":"ubuntu","updated_at":"2026-01-08T14:00:25.453019613-05:00","closed_at":"2026-01-08T14:00:25.453019613-05:00","close_reason":"Empty placeholder beads created in error"}
{"id":"flywheel_gateway-7ek","title":"Audit Trail Hardening","description":"## Background\n\nEnterprise customers require comprehensive audit logging for compliance (SOC 2, HIPAA, GDPR), security forensics, and operational troubleshooting. A robust audit trail provides an immutable record of all significant actions within the system, enabling organizations to answer \"who did what, when, and why\" for any point in time.\n\n## Problem Statement\n\nCurrent logging is inconsistent across services, lacks correlation IDs for request tracing, may inadvertently log sensitive data, and has no standardized export or retention policies. This creates compliance gaps and makes incident investigation difficult. Organizations cannot demonstrate to auditors that they have complete visibility into system access and changes.\n\n## Technical Approach\n\n### Audit Event Structure\n\n```typescript\n// apps/gateway/src/types/audit.types.ts\n\ninterface AuditEvent {\n  // Identification\n  id: string; // UUID\n  correlationId: string; // Request correlation ID\n  parentEventId?: string; // For nested operations\n  \n  // Timing\n  timestamp: Date;\n  duration?: number; // Operation duration in ms\n  \n  // Actor information\n  actor: {\n    type: 'user' | 'agent' | 'system' | 'api_key';\n    id: string;\n    name?: string;\n    email?: string;\n    ip?: string;\n    userAgent?: string;\n    sessionId?: string;\n  };\n  \n  // Organization context\n  org: {\n    id: string;\n    name?: string;\n  };\n  \n  // Action details\n  action: AuditAction;\n  resource: {\n    type: ResourceType;\n    id: string;\n    name?: string;\n    parentId?: string;\n    parentType?: string;\n  };\n  \n  // Operation details\n  operation: {\n    type: 'create' | 'read' | 'update' | 'delete' | 'execute' | 'login' | 'logout';\n    status: 'success' | 'failure' | 'partial';\n    errorCode?: string;\n    errorMessage?: string;\n  };\n  \n  // Change tracking\n  changes?: {\n    before?: Record\u003cstring, any\u003e; // Redacted\n    after?: Record\u003cstring, any\u003e; // Redacted\n    diff?: Array\u003c{ field: string; old: any; new: any }\u003e;\n  };\n  \n  // Additional context\n  metadata: {\n    requestId: string;\n    endpoint?: string;\n    method?: string;\n    sourceService?: string;\n    tags?: string[];\n    [key: string]: any;\n  };\n}\n\ntype AuditAction = \n  // Authentication\n  | 'auth.login'\n  | 'auth.logout'\n  | 'auth.login_failed'\n  | 'auth.password_changed'\n  | 'auth.mfa_enabled'\n  | 'auth.mfa_disabled'\n  | 'auth.api_key_created'\n  | 'auth.api_key_revoked'\n  \n  // User management\n  | 'user.created'\n  | 'user.updated'\n  | 'user.deleted'\n  | 'user.role_changed'\n  | 'user.invited'\n  \n  // Agent operations\n  | 'agent.created'\n  | 'agent.updated'\n  | 'agent.deleted'\n  | 'agent.started'\n  | 'agent.stopped'\n  | 'agent.config_changed'\n  | 'agent.execution'\n  \n  // Bead operations\n  | 'bead.created'\n  | 'bead.updated'\n  | 'bead.deleted'\n  | 'bead.status_changed'\n  | 'bead.assigned'\n  \n  // Conflict operations\n  | 'conflict.detected'\n  | 'conflict.resolved'\n  | 'conflict.escalated'\n  \n  // Settings changes\n  | 'settings.updated'\n  | 'integration.connected'\n  | 'integration.disconnected'\n  \n  // Data access\n  | 'data.exported'\n  | 'data.accessed'\n  | 'report.generated';\n\ntype ResourceType = \n  | 'user' | 'team' | 'organization'\n  | 'agent' | 'bead' | 'conflict'\n  | 'dashboard' | 'pipeline'\n  | 'api_key' | 'integration'\n  | 'settings' | 'export';\n```\n\n### Correlation ID Propagation\n\n```typescript\n// apps/gateway/src/middleware/correlation.middleware.ts\n\nimport { v4 as uuidv4 } from 'uuid';\nimport { AsyncLocalStorage } from 'async_hooks';\n\n// AsyncLocalStorage for request-scoped correlation\nconst correlationStorage = new AsyncLocalStorage\u003cCorrelationContext\u003e();\n\ninterface CorrelationContext {\n  correlationId: string;\n  parentSpanId?: string;\n  traceId?: string;\n  requestId: string;\n}\n\nexport function correlationMiddleware(req: Request, res: Response, next: NextFunction) {\n  // Extract or generate correlation ID\n  const correlationId = \n    req.headers['x-correlation-id'] as string ||\n    req.headers['x-request-id'] as string ||\n    uuidv4();\n  \n  const context: CorrelationContext = {\n    correlationId,\n    traceId: req.headers['x-trace-id'] as string,\n    parentSpanId: req.headers['x-parent-span-id'] as string,\n    requestId: uuidv4(),\n  };\n  \n  // Set response header for client correlation\n  res.setHeader('x-correlation-id', correlationId);\n  res.setHeader('x-request-id', context.requestId);\n  \n  // Run request in correlation context\n  correlationStorage.run(context, () =\u003e next());\n}\n\nexport function getCorrelationContext(): CorrelationContext | undefined {\n  return correlationStorage.getStore();\n}\n\n// Propagate to external service calls\nexport function getCorrelationHeaders(): Record\u003cstring, string\u003e {\n  const context = getCorrelationContext();\n  if (!context) return {};\n  \n  return {\n    'x-correlation-id': context.correlationId,\n    'x-request-id': context.requestId,\n    'x-trace-id': context.traceId || context.correlationId,\n  };\n}\n```\n\n### Sensitive Data Redaction\n\n```typescript\n// apps/gateway/src/services/audit-redaction.service.ts\n\ninterface RedactionConfig {\n  // Fields to completely remove\n  removeFields: string[];\n  \n  // Fields to mask (show partial)\n  maskFields: {\n    field: string;\n    pattern: 'email' | 'phone' | 'card' | 'ssn' | 'api_key' | 'custom';\n    customMask?: (value: string) =\u003e string;\n  }[];\n  \n  // Fields to hash (for later matching without exposing)\n  hashFields: string[];\n  \n  // Regex patterns to redact in any string field\n  redactPatterns: RegExp[];\n}\n\nconst defaultRedactionConfig: RedactionConfig = {\n  removeFields: [\n    'password',\n    'passwordHash',\n    'secret',\n    'privateKey',\n    'accessToken',\n    'refreshToken',\n    'sessionToken',\n    'creditCard',\n    'cvv',\n    'ssn',\n  ],\n  \n  maskFields: [\n    { field: 'email', pattern: 'email' },  // j***@example.com\n    { field: 'phone', pattern: 'phone' },  // ***-***-1234\n    { field: 'apiKey', pattern: 'api_key' }, // sk_...***xyz\n  ],\n  \n  hashFields: [\n    'userId', // Can verify matches without exposing\n  ],\n  \n  redactPatterns: [\n    /Bearer\\s+[A-Za-z0-9\\-._~+\\/]+=*/g,  // JWT tokens\n    /sk_[a-zA-Z0-9]{32,}/g,              // API keys\n  ],\n};\n\nclass AuditRedactionService {\n  redact(data: any, config = defaultRedactionConfig): any {\n    if (!data) return data;\n    if (typeof data === 'string') return this.redactString(data, config);\n    if (Array.isArray(data)) return data.map(item =\u003e this.redact(item, config));\n    if (typeof data === 'object') return this.redactObject(data, config);\n    return data;\n  }\n  \n  private applyMask(value: string, pattern: string): string {\n    switch (pattern) {\n      case 'email':\n        const [local, domain] = value.split('@');\n        return local[0] + '***@' + domain;\n      case 'phone':\n        return value.replace(/\\d(?=\\d{4})/g, '*');\n      case 'api_key':\n        return value.slice(0, 5) + '***' + value.slice(-3);\n      default:\n        return '***';\n    }\n  }\n}\n```\n\n### Export Functionality\n\n```typescript\n// apps/gateway/src/services/audit-export.service.ts\n\ninterface ExportOptions {\n  format: 'csv' | 'json' | 'json_lines';\n  dateRange: { start: Date; end: Date };\n  filters?: AuditFilter;\n  includeFields?: string[];\n  excludeFields?: string[];\n  compression?: 'none' | 'gzip' | 'zip';\n}\n\ninterface AuditFilter {\n  actions?: AuditAction[];\n  actors?: string[];\n  resources?: { type: ResourceType; id?: string }[];\n  status?: ('success' | 'failure')[];\n  searchQuery?: string;\n}\n\nclass AuditExportService {\n  async exportToFile(options: ExportOptions): Promise\u003cExportResult\u003e {\n    // Stream-based export for large datasets\n    const stream = this.createExportStream(options);\n    const filename = this.generateFilename(options);\n    \n    // Write to temporary file\n    const tempPath = await this.writeStreamToFile(stream, filename, options.compression);\n    \n    // Generate signed download URL\n    const downloadUrl = await this.uploadToStorage(tempPath);\n    \n    // Audit the export itself\n    await this.auditService.log({\n      action: 'data.exported',\n      resource: { type: 'export', id: filename },\n      metadata: {\n        format: options.format,\n        dateRange: options.dateRange,\n        recordCount: stream.recordCount,\n      },\n    });\n    \n    return {\n      filename,\n      downloadUrl,\n      expiresAt: new Date(Date.now() + 24 * 60 * 60 * 1000), // 24 hours\n      recordCount: stream.recordCount,\n      fileSize: stream.byteCount,\n    };\n  }\n}\n```\n\n### Retention Policies\n\n```typescript\n// apps/gateway/src/services/audit-retention.service.ts\n\ninterface RetentionPolicy {\n  id: string;\n  name: string;\n  description?: string;\n  \n  // What to retain\n  filter: {\n    actions?: AuditAction[];\n    severities?: string[];\n    resourceTypes?: ResourceType[];\n  };\n  \n  // How long to retain\n  retention: {\n    duration: number; // Days\n    archiveFirst: boolean; // Archive to cold storage before delete\n    archiveLocation?: string; // S3 bucket/path\n  };\n  \n  // When created/modified\n  createdAt: Date;\n  updatedAt: Date;\n  createdBy: string;\n}\n\nconst defaultPolicies: RetentionPolicy[] = [\n  {\n    id: 'auth-events',\n    name: 'Authentication Events',\n    filter: { actions: ['auth.login', 'auth.logout', 'auth.login_failed'] },\n    retention: { duration: 365, archiveFirst: true },\n  },\n  {\n    id: 'data-access',\n    name: 'Data Access Events',\n    filter: { actions: ['data.accessed', 'data.exported'] },\n    retention: { duration: 730, archiveFirst: true }, // 2 years\n  },\n  {\n    id: 'config-changes',\n    name: 'Configuration Changes',\n    filter: { actions: ['settings.updated', 'agent.config_changed'] },\n    retention: { duration: 365, archiveFirst: true },\n  },\n  {\n    id: 'default',\n    name: 'Default Policy',\n    filter: {}, // Catch-all\n    retention: { duration: 90, archiveFirst: false },\n  },\n];\n```\n\n### Search and Filter Capabilities\n\n```typescript\n// apps/gateway/src/services/audit-search.service.ts\n\ninterface AuditSearchQuery {\n  // Full-text search\n  query?: string;\n  \n  // Time range (required for performance)\n  timeRange: {\n    start: Date;\n    end: Date;\n  };\n  \n  // Filters\n  filters: {\n    correlationId?: string;\n    actorTypes?: string[];\n    actorIds?: string[];\n    actions?: AuditAction[];\n    resourceTypes?: ResourceType[];\n    resourceIds?: string[];\n    statuses?: string[];\n    hasErrors?: boolean;\n  };\n  \n  // Pagination\n  pagination: {\n    limit: number;\n    offset?: number;\n    cursor?: string; // For keyset pagination\n  };\n  \n  // Sorting\n  sort: {\n    field: 'timestamp' | 'action' | 'actor';\n    direction: 'asc' | 'desc';\n  };\n}\n\ninterface AuditSearchResult {\n  events: AuditEvent[];\n  total: number;\n  hasMore: boolean;\n  nextCursor?: string;\n  aggregations?: {\n    byAction: Record\u003cstring, number\u003e;\n    byActor: Record\u003cstring, number\u003e;\n    byResource: Record\u003cstring, number\u003e;\n    byStatus: Record\u003cstring, number\u003e;\n    timeline: Array\u003c{ bucket: string; count: number }\u003e;\n  };\n}\n```\n\n### ClickHouse Integration for Analytics\n\n```typescript\n// apps/gateway/src/services/audit-clickhouse.service.ts\n\ninterface ClickHouseConfig {\n  host: string;\n  port: number;\n  database: string;\n  username: string;\n  password: string;\n  cluster?: string;\n}\n\nclass AuditClickHouseService {\n  async forwardEvent(event: AuditEvent): Promise\u003cvoid\u003e {\n    // Buffer events for batch insert\n    this.buffer.push(this.transformForClickHouse(event));\n    \n    if (this.buffer.length \u003e= this.batchSize || this.shouldFlush()) {\n      await this.flushBuffer();\n    }\n  }\n  \n  private transformForClickHouse(event: AuditEvent): ClickHouseRow {\n    return {\n      event_id: event.id,\n      correlation_id: event.correlationId,\n      timestamp: event.timestamp,\n      org_id: event.org.id,\n      actor_type: event.actor.type,\n      actor_id: event.actor.id,\n      action: event.action,\n      resource_type: event.resource.type,\n      resource_id: event.resource.id,\n      status: event.operation.status,\n      duration_ms: event.duration || 0,\n      metadata: JSON.stringify(event.metadata),\n      // Materialized columns for common queries\n      date: event.timestamp.toISOString().split('T')[0],\n      hour: event.timestamp.getUTCHours(),\n    };\n  }\n}\n```\n\n### API Endpoints\n\n```typescript\n// Audit log endpoints\nGET    /api/v1/audit                          // Search audit events\nGET    /api/v1/audit/:id                      // Get specific event\nGET    /api/v1/audit/correlation/:correlationId  // Get correlated events\n\n// Export\nPOST   /api/v1/audit/export                   // Create export job\nGET    /api/v1/audit/export/:jobId            // Get export status\nGET    /api/v1/audit/export/:jobId/download   // Download export\n\n// Retention policies\nGET    /api/v1/audit/retention-policies       // List policies\nPOST   /api/v1/audit/retention-policies       // Create policy\nPUT    /api/v1/audit/retention-policies/:id   // Update policy\nDELETE /api/v1/audit/retention-policies/:id   // Delete policy\n\n// Analytics (from ClickHouse)\nGET    /api/v1/audit/analytics/summary        // Summary statistics\nGET    /api/v1/audit/analytics/trends         // Time-series trends\nGET    /api/v1/audit/analytics/top-actors     // Most active actors\nGET    /api/v1/audit/analytics/top-actions    // Most common actions\n```\n\n## File Locations\n\n- apps/gateway/src/services/audit.service.ts - Core audit service\n- apps/gateway/src/services/audit-redaction.service.ts - Data redaction\n- apps/gateway/src/services/audit-export.service.ts - Export functionality\n- apps/gateway/src/services/audit-retention.service.ts - Retention policies\n- apps/gateway/src/services/audit-search.service.ts - Search capabilities\n- apps/gateway/src/services/audit-clickhouse.service.ts - ClickHouse integration\n- apps/gateway/src/middleware/correlation.middleware.ts - Correlation ID propagation\n- apps/gateway/src/middleware/audit.middleware.ts - Request audit logging\n- apps/gateway/src/controllers/audit.controller.ts - API controller\n- apps/gateway/src/types/audit.types.ts - Type definitions\n- packages/shared/src/types/audit.ts - Shared audit types\n- apps/web/src/components/audit/AuditLogViewer.tsx - UI component\n- apps/web/src/components/audit/AuditSearch.tsx - Search interface\n- apps/web/src/components/audit/AuditExport.tsx - Export dialog\n\n## Database Schema\n\n```sql\n-- Primary audit log table\nCREATE TABLE audit_events (\n  id UUID PRIMARY KEY,\n  correlation_id UUID NOT NULL,\n  parent_event_id UUID REFERENCES audit_events(id),\n  timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n  duration_ms INTEGER,\n  \n  -- Actor\n  actor_type VARCHAR(50) NOT NULL,\n  actor_id VARCHAR(255) NOT NULL,\n  actor_ip INET,\n  actor_user_agent TEXT,\n  \n  -- Organization\n  org_id UUID NOT NULL REFERENCES organizations(id),\n  \n  -- Action\n  action VARCHAR(100) NOT NULL,\n  resource_type VARCHAR(50) NOT NULL,\n  resource_id VARCHAR(255),\n  \n  -- Operation\n  operation_type VARCHAR(20) NOT NULL,\n  operation_status VARCHAR(20) NOT NULL,\n  error_code VARCHAR(50),\n  error_message TEXT,\n  \n  -- Changes (JSONB for flexibility)\n  changes JSONB,\n  \n  -- Metadata\n  metadata JSONB NOT NULL DEFAULT '{}'\n);\n\n-- Indexes for common query patterns\nCREATE INDEX idx_audit_correlation ON audit_events(correlation_id);\nCREATE INDEX idx_audit_org_time ON audit_events(org_id, timestamp DESC);\nCREATE INDEX idx_audit_actor ON audit_events(actor_id, timestamp DESC);\nCREATE INDEX idx_audit_action ON audit_events(action, timestamp DESC);\nCREATE INDEX idx_audit_resource ON audit_events(resource_type, resource_id, timestamp DESC);\n```\n\n## Dependencies\n\n- @clickhouse/client: ClickHouse integration\n- async_hooks: For correlation context\n- csv-stringify: CSV export\n- archiver: ZIP compression\n- winston: Structured logging\n\n## Acceptance Criteria\n\n1. All API operations generate audit events automatically\n2. Correlation IDs propagate across all service calls\n3. Sensitive data is redacted according to configuration\n4. Export supports CSV and JSON formats with compression\n5. Retention policies can be configured per-category\n6. Search returns results within 2 seconds for 30-day queries\n7. ClickHouse receives audit events within 5 seconds\n8. Audit events are tamper-evident (cannot be modified after creation)\n9. Export jobs handle datasets up to 1M records\n10. UI provides intuitive search and filter interface\n11. Compliance report generation for SOC 2 audits\n12. Performance: \u003c 5ms overhead per request for audit logging\n\n## Testing Strategy\n\n- Unit tests for redaction service\n- Integration tests for correlation propagation\n- Load tests for high-volume audit logging\n- E2E tests for export functionality\n- Compliance tests for required audit fields\n\n## Reference\n\nPLAN.md section 24 - Audit Trail Hardening\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Redaction rules remove secrets deterministically and preserve non-sensitive context\n- [ ] Export formats (JSON/NDJSON) are schema-valid and stable across versions\n- [ ] Retention policies apply correctly without deleting required audit records\n\n### Integration Tests\n- [ ] Mutating operations create audit events with correlation IDs and can be queried via REST\n\n### Failure Mode Tests\n- [ ] Export under load does not block core operations; partial failures return resumable job state\n\n### Logging\n- [ ] Logs include correlationId + auditEventId + actor + entity; exported content is not logged\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] AuditEvent: creates with all fields\n- [ ] AuditEvent: generates correlation ID\n- [ ] AuditEvent: serializes for storage\n- [ ] TamperDetection: computes hash chain\n- [ ] TamperDetection: verifies integrity\n- [ ] Export: formats as CSV\n- [ ] Export: formats as JSON\n- [ ] Retention: applies policy rules\n- [ ] Retention: archives old events\n- [ ] Search: full-text indexing\n- [ ] Search: filter by actor/resource\n- [ ] Redaction: sanitizes sensitive data\n\n### Integration Tests\n- [ ] Events persisted on API calls\n- [ ] Correlation ID flows through stack\n- [ ] Export generates valid file\n- [ ] Retention deletes expired events\n- [ ] Search returns matching events\n- [ ] Hash chain valid across events\n- [ ] Large export handled streaming\n\n### E2E Tests\n- [ ] User action appears in audit log\n- [ ] Export downloaded in UI\n- [ ] Search finds historical event\n- [ ] Tamper detection alerts on mismatch\n\n### Performance Tests\n- [ ] Event logging \u003c5ms overhead\n- [ ] Search \u003c500ms for 1M events\n- [ ] Export 10k events \u003c10s\n- [ ] Retention cleanup efficient\n\n### Failure Mode Tests\n- [ ] Storage full: graceful handling\n- [ ] Corrupt event: isolated and flagged\n- [ ] Export timeout: partial file\n- [ ] Hash mismatch: alert and quarantine","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:59:36.299921252-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:07:10.046393575-05:00","dependencies":[{"issue_id":"flywheel_gateway-7ek","depends_on_id":"flywheel_gateway-d18","type":"blocks","created_at":"2026-01-08T14:01:52.556581277-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-7n4","title":"Job Orchestration for Long-Running Operations","description":"## Background\n\nThe Job Orchestration system provides infrastructure for managing long-running operations that cannot complete within typical HTTP request timeouts. This includes context builds, codebase scans, exports, and other operations that may take seconds to minutes.\n\n### Why This Matters\n\n1. **User Experience**: Long-running operations need progress feedback. Users should see what is happening, not a spinning cursor.\n\n2. **Reliability**: Operations that span minutes need checkpointing and resume capability. Network blips should not require restart.\n\n3. **Resource Management**: Concurrent long operations need throttling. Unbounded parallelism leads to resource exhaustion.\n\n4. **Cancellation**: Users must be able to cancel operations. Runaway jobs waste resources and block progress.\n\n## Technical Design\n\n### Job Types\n\n```typescript\nenum JobType {\n  // Context operations\n  CONTEXT_BUILD = 'context_build',\n  CONTEXT_COMPACT = 'context_compact',\n  \n  // Scan operations\n  CODEBASE_SCAN = 'codebase_scan',\n  DEPENDENCY_SCAN = 'dependency_scan',\n  \n  // Export operations\n  SESSION_EXPORT = 'session_export',\n  BEAD_EXPORT = 'bead_export',\n  \n  // Import operations\n  CODEBASE_IMPORT = 'codebase_import',\n  MEMORY_IMPORT = 'memory_import',\n  \n  // Analysis operations\n  SEMANTIC_INDEX = 'semantic_index',\n  EMBEDDING_GENERATE = 'embedding_generate',\n  \n  // Maintenance operations\n  CHECKPOINT_COMPACT = 'checkpoint_compact',\n  CACHE_WARM = 'cache_warm'\n}\n\nenum JobStatus {\n  PENDING = 'pending',           // Queued, waiting to start\n  RUNNING = 'running',           // Currently executing\n  PAUSED = 'paused',             // Temporarily paused\n  COMPLETED = 'completed',       // Successfully finished\n  FAILED = 'failed',             // Failed with error\n  CANCELLED = 'cancelled',       // User-cancelled\n  TIMEOUT = 'timeout'            // Exceeded time limit\n}\n\nenum JobPriority {\n  LOW = 0,\n  NORMAL = 1,\n  HIGH = 2,\n  CRITICAL = 3\n}\n```\n\n### Job Model\n\n```typescript\ninterface Job {\n  id: string;                    // ULID\n  type: JobType;\n  status: JobStatus;\n  priority: JobPriority;\n  \n  // Ownership\n  sessionId?: string;\n  userId?: string;\n  \n  // Input/Output\n  input: Record\u003cstring, any\u003e;\n  output?: Record\u003cstring, any\u003e;\n  \n  // Progress tracking\n  progress: {\n    current: number;\n    total: number;\n    percentage: number;\n    message: string;\n    stage?: string;\n  };\n  \n  // Timing\n  createdAt: Date;\n  startedAt?: Date;\n  completedAt?: Date;\n  estimatedDuration?: number;    // milliseconds\n  \n  // Error handling\n  error?: {\n    code: string;\n    message: string;\n    stack?: string;\n    retryable: boolean;\n  };\n  \n  // Retry configuration\n  retry: {\n    attempts: number;\n    maxAttempts: number;\n    backoffMs: number;\n    nextRetryAt?: Date;\n  };\n  \n  // Cancellation\n  cancellation?: {\n    requestedAt: Date;\n    requestedBy: string;\n    reason?: string;\n  };\n  \n  // Metadata\n  metadata: Record\u003cstring, any\u003e;\n}\n```\n\n### Job Queue\n\n```typescript\ninterface JobQueueConfig {\n  // Concurrency limits\n  concurrency: {\n    global: number;              // Max concurrent jobs overall\n    perType: Record\u003cJobType, number\u003e;  // Max per job type\n    perSession: number;          // Max per session\n  };\n  \n  // Timeouts\n  timeouts: {\n    default: number;             // Default timeout (5 minutes)\n    perType: Record\u003cJobType, number\u003e;  // Per-type overrides\n  };\n  \n  // Retry\n  retry: {\n    maxAttempts: number;         // Default: 3\n    backoffMultiplier: number;   // Default: 2\n    initialBackoffMs: number;    // Default: 1000\n    maxBackoffMs: number;        // Default: 60000\n  };\n  \n  // Cleanup\n  cleanup: {\n    completedRetentionHours: number;  // Keep completed jobs for N hours\n    failedRetentionHours: number;     // Keep failed jobs for N hours\n  };\n}\n\nclass JobQueue {\n  private queue: PriorityQueue\u003cJob\u003e;\n  private running = new Map\u003cstring, JobExecution\u003e();\n  private handlers = new Map\u003cJobType, JobHandler\u003e();\n  \n  constructor(\n    private config: JobQueueConfig,\n    private storage: JobStorage,\n    private events: EventEmitter\n  ) {}\n  \n  async enqueue(job: Omit\u003cJob, 'id' | 'status' | 'createdAt'\u003e): Promise\u003cJob\u003e {\n    const newJob: Job = {\n      ...job,\n      id: ulid(),\n      status: JobStatus.PENDING,\n      createdAt: new Date(),\n      progress: {\n        current: 0,\n        total: 100,\n        percentage: 0,\n        message: 'Queued'\n      },\n      retry: {\n        attempts: 0,\n        maxAttempts: this.config.retry.maxAttempts,\n        backoffMs: this.config.retry.initialBackoffMs\n      }\n    };\n    \n    await this.storage.save(newJob);\n    this.queue.enqueue(newJob, newJob.priority);\n    \n    this.events.emit('job.created', { jobId: newJob.id, type: newJob.type });\n    this.processQueue();\n    \n    return newJob;\n  }\n  \n  private async processQueue(): Promise\u003cvoid\u003e {\n    while (this.canStartJob() \u0026\u0026 !this.queue.isEmpty()) {\n      const job = this.queue.dequeue();\n      if (job \u0026\u0026 this.canRunJob(job)) {\n        this.startJob(job);\n      }\n    }\n  }\n  \n  private canStartJob(): boolean {\n    return this.running.size \u003c this.config.concurrency.global;\n  }\n  \n  private canRunJob(job: Job): boolean {\n    // Check per-type limit\n    const typeCount = Array.from(this.running.values())\n      .filter(e =\u003e e.job.type === job.type).length;\n    const typeLimit = this.config.concurrency.perType[job.type] || \n                      this.config.concurrency.global;\n    if (typeCount \u003e= typeLimit) return false;\n    \n    // Check per-session limit\n    if (job.sessionId) {\n      const sessionCount = Array.from(this.running.values())\n        .filter(e =\u003e e.job.sessionId === job.sessionId).length;\n      if (sessionCount \u003e= this.config.concurrency.perSession) return false;\n    }\n    \n    return true;\n  }\n  \n  private async startJob(job: Job): Promise\u003cvoid\u003e {\n    const handler = this.handlers.get(job.type);\n    if (!handler) {\n      await this.failJob(job, {\n        code: 'NO_HANDLER',\n        message: `No handler registered for job type: ${job.type}`,\n        retryable: false\n      });\n      return;\n    }\n    \n    job.status = JobStatus.RUNNING;\n    job.startedAt = new Date();\n    await this.storage.save(job);\n    \n    this.events.emit('job.started', { jobId: job.id, type: job.type });\n    \n    const execution = new JobExecution(job, handler, this);\n    this.running.set(job.id, execution);\n    \n    execution.run()\n      .then(() =\u003e this.completeJob(job))\n      .catch(error =\u003e this.handleJobError(job, error))\n      .finally(() =\u003e {\n        this.running.delete(job.id);\n        this.processQueue();\n      });\n  }\n}\n```\n\n### Job Handler Interface\n\n```typescript\ninterface JobHandler\u003cTInput = any, TOutput = any\u003e {\n  // Validate input before execution\n  validate(input: TInput): Promise\u003cValidationResult\u003e;\n  \n  // Execute the job\n  execute(context: JobContext\u003cTInput\u003e): Promise\u003cTOutput\u003e;\n  \n  // Optional: Handle cancellation cleanup\n  onCancel?(context: JobContext\u003cTInput\u003e): Promise\u003cvoid\u003e;\n  \n  // Optional: Handle pause\n  onPause?(context: JobContext\u003cTInput\u003e): Promise\u003cvoid\u003e;\n  \n  // Optional: Handle resume\n  onResume?(context: JobContext\u003cTInput\u003e): Promise\u003cvoid\u003e;\n}\n\ninterface JobContext\u003cTInput\u003e {\n  job: Job;\n  input: TInput;\n  \n  // Progress reporting\n  updateProgress(current: number, total: number, message?: string): Promise\u003cvoid\u003e;\n  setStage(stage: string): Promise\u003cvoid\u003e;\n  \n  // Checkpointing for resume\n  checkpoint(state: any): Promise\u003cvoid\u003e;\n  getCheckpoint(): Promise\u003cany | null\u003e;\n  \n  // Cancellation checking\n  isCancelled(): boolean;\n  throwIfCancelled(): void;\n  \n  // Logging\n  log(level: 'debug' | 'info' | 'warn' | 'error', message: string): void;\n}\n\n// Example handler implementation\nclass CodebaseScanHandler implements JobHandler\u003cScanInput, ScanOutput\u003e {\n  async validate(input: ScanInput): Promise\u003cValidationResult\u003e {\n    if (!input.path) {\n      return { valid: false, errors: ['path is required'] };\n    }\n    return { valid: true, errors: [] };\n  }\n  \n  async execute(context: JobContext\u003cScanInput\u003e): Promise\u003cScanOutput\u003e {\n    const { input } = context;\n    \n    // Get files to scan\n    const files = await this.getFiles(input.path, input.patterns);\n    \n    context.setStage('scanning');\n    const results: ScanResult[] = [];\n    \n    for (let i = 0; i \u003c files.length; i++) {\n      // Check for cancellation\n      context.throwIfCancelled();\n      \n      // Update progress\n      await context.updateProgress(i, files.length, `Scanning ${files[i]}`);\n      \n      // Scan file\n      const result = await this.scanFile(files[i]);\n      results.push(result);\n      \n      // Checkpoint every 100 files\n      if (i % 100 === 0) {\n        await context.checkpoint({ lastIndex: i, results });\n      }\n    }\n    \n    return { results, totalFiles: files.length };\n  }\n  \n  async onCancel(context: JobContext\u003cScanInput\u003e): Promise\u003cvoid\u003e {\n    // Cleanup partial results\n    context.log('info', 'Scan cancelled, cleaning up');\n  }\n}\n```\n\n### Job Execution\n\n```typescript\nclass JobExecution {\n  private cancelled = false;\n  private timeout: NodeJS.Timeout | null = null;\n  \n  constructor(\n    readonly job: Job,\n    private handler: JobHandler,\n    private queue: JobQueue\n  ) {}\n  \n  async run(): Promise\u003cvoid\u003e {\n    const timeoutMs = this.queue.getTimeout(this.job.type);\n    \n    // Set timeout\n    this.timeout = setTimeout(() =\u003e {\n      this.handleTimeout();\n    }, timeoutMs);\n    \n    try {\n      const context = this.createContext();\n      const output = await this.handler.execute(context);\n      \n      this.job.output = output;\n      this.job.status = JobStatus.COMPLETED;\n      this.job.completedAt = new Date();\n      \n    } finally {\n      if (this.timeout) {\n        clearTimeout(this.timeout);\n      }\n    }\n  }\n  \n  cancel(reason?: string): void {\n    this.cancelled = true;\n    this.job.cancellation = {\n      requestedAt: new Date(),\n      requestedBy: 'user',\n      reason\n    };\n    \n    if (this.handler.onCancel) {\n      this.handler.onCancel(this.createContext());\n    }\n  }\n  \n  private createContext(): JobContext\u003cany\u003e {\n    return {\n      job: this.job,\n      input: this.job.input,\n      \n      updateProgress: async (current, total, message) =\u003e {\n        this.job.progress = {\n          current,\n          total,\n          percentage: Math.round((current / total) * 100),\n          message: message || this.job.progress.message,\n          stage: this.job.progress.stage\n        };\n        await this.queue.storage.save(this.job);\n        this.queue.events.emit('job.progress', {\n          jobId: this.job.id,\n          progress: this.job.progress\n        });\n      },\n      \n      setStage: async (stage) =\u003e {\n        this.job.progress.stage = stage;\n        await this.queue.storage.save(this.job);\n      },\n      \n      checkpoint: async (state) =\u003e {\n        this.job.metadata.checkpoint = state;\n        await this.queue.storage.save(this.job);\n      },\n      \n      getCheckpoint: async () =\u003e {\n        return this.job.metadata.checkpoint || null;\n      },\n      \n      isCancelled: () =\u003e this.cancelled,\n      \n      throwIfCancelled: () =\u003e {\n        if (this.cancelled) {\n          throw new JobCancelledException(this.job.id);\n        }\n      },\n      \n      log: (level, message) =\u003e {\n        this.queue.logger[level](`[Job ${this.job.id}] ${message}`);\n      }\n    };\n  }\n}\n```\n\n### WebSocket Events\n\n```typescript\n// Job created\n{\n  event: 'job.created',\n  data: {\n    jobId: string,\n    type: JobType,\n    sessionId?: string,\n    priority: JobPriority\n  }\n}\n\n// Job started\n{\n  event: 'job.started',\n  data: {\n    jobId: string,\n    type: JobType,\n    estimatedDuration?: number\n  }\n}\n\n// Job progress\n{\n  event: 'job.progress',\n  data: {\n    jobId: string,\n    progress: {\n      current: number,\n      total: number,\n      percentage: number,\n      message: string,\n      stage?: string\n    }\n  }\n}\n\n// Job completed\n{\n  event: 'job.completed',\n  data: {\n    jobId: string,\n    type: JobType,\n    duration: number,\n    output?: Record\u003cstring, any\u003e\n  }\n}\n\n// Job failed\n{\n  event: 'job.failed',\n  data: {\n    jobId: string,\n    type: JobType,\n    error: {\n      code: string,\n      message: string,\n      retryable: boolean\n    },\n    willRetry: boolean,\n    nextRetryAt?: Date\n  }\n}\n\n// Job cancelled\n{\n  event: 'job.cancelled',\n  data: {\n    jobId: string,\n    type: JobType,\n    reason?: string\n  }\n}\n```\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Create job\nPOST /api/v1/jobs\nRequest: {\n  type: JobType,\n  input: Record\u003cstring, any\u003e,\n  priority?: JobPriority,\n  sessionId?: string\n}\nResponse: Job\n\n// Get job status\nGET /api/v1/jobs/:jobId\nResponse: Job\n\n// List jobs\nGET /api/v1/jobs\nQuery: {\n  type?: JobType,\n  status?: JobStatus,\n  sessionId?: string,\n  limit?: number,\n  offset?: number\n}\nResponse: { jobs: Job[], total: number }\n\n// Cancel job\nPOST /api/v1/jobs/:jobId/cancel\nRequest: { reason?: string }\nResponse: Job\n\n// Retry failed job\nPOST /api/v1/jobs/:jobId/retry\nResponse: Job\n\n// Get job output\nGET /api/v1/jobs/:jobId/output\nResponse: Record\u003cstring, any\u003e\n\n// Pause job (if supported)\nPOST /api/v1/jobs/:jobId/pause\nResponse: Job\n\n// Resume job\nPOST /api/v1/jobs/:jobId/resume\nResponse: Job\n```\n\n## Configuration\n\n```typescript\ninterface JobServiceConfig {\n  // Queue configuration\n  queue: JobQueueConfig;\n  \n  // Storage\n  storage: {\n    type: 'memory' | 'redis' | 'postgres';\n    connectionString?: string;\n  };\n  \n  // Worker configuration\n  worker: {\n    pollIntervalMs: number;      // How often to check for new jobs\n    shutdownTimeoutMs: number;   // Time to wait for jobs on shutdown\n  };\n  \n  // Metrics\n  metrics: {\n    enabled: boolean;\n    prefix: string;\n  };\n}\n```\n\n## File Locations\n\n- **Primary Service**: `apps/gateway/src/services/job.service.ts`\n- **Job Queue**: `apps/gateway/src/services/job-queue.service.ts`\n- **Job Handlers**: `apps/gateway/src/jobs/handlers/`\n  - `context-build.handler.ts`\n  - `codebase-scan.handler.ts`\n  - `session-export.handler.ts`\n  - `semantic-index.handler.ts`\n- **Types**: `apps/gateway/src/types/job.types.ts`\n- **Controller**: `apps/gateway/src/controllers/job.controller.ts`\n- **Tests**: `apps/gateway/src/services/__tests__/job.service.test.ts`\n\n## Dependencies\n\n- Priority queue implementation\n- Storage backend (Redis or PostgreSQL)\n- WebSocket gateway (for events)\n- Logger service\n\n## Acceptance Criteria\n\n1. **Job Creation**\n   - [ ] Jobs can be created with type, input, and optional priority\n   - [ ] Jobs are assigned unique IDs (ULID)\n   - [ ] Jobs start in PENDING status\n   - [ ] job.created event is emitted\n\n2. **Job Execution**\n   - [ ] Jobs execute in priority order\n   - [ ] Concurrency limits are respected (global and per-type)\n   - [ ] Timeouts are enforced\n   - [ ] job.started event is emitted\n\n3. **Progress Tracking**\n   - [ ] Progress updates are persisted\n   - [ ] job.progress events are emitted\n   - [ ] Progress includes percentage and message\n\n4. **Cancellation**\n   - [ ] Jobs can be cancelled via API\n   - [ ] Handlers receive cancellation signal\n   - [ ] Cleanup is performed\n   - [ ] job.cancelled event is emitted\n\n5. **Error Handling**\n   - [ ] Failed jobs retry according to configuration\n   - [ ] Exponential backoff is applied\n   - [ ] job.failed event includes retry information\n   - [ ] Non-retryable errors stop immediately\n\n6. **Checkpointing**\n   - [ ] Long jobs can checkpoint state\n   - [ ] Resumed jobs start from checkpoint\n   - [ ] Checkpoints are cleaned up on completion\n\n7. **Observability**\n   - [ ] All job state changes emit events\n   - [ ] Prometheus metrics for job counts, durations, failures\n   - [ ] Logs include job ID context\n\n## Reference\n\n- PLAN.md Section 8.9 - Job Queue for Long Operations\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Job state machine (queued → running → completed/failed/cancelled) enforces valid transitions\n- [ ] Progress event buffering and cursoring are deterministic and replay-safe\n- [ ] Cancellation semantics stop work and mark terminal state consistently\n\n### Integration Tests\n- [ ] Start a long-running job → stream progress via WebSocket → fetch final result via REST\n\n### Failure Mode Tests\n- [ ] Worker crash/restart resumes or fails jobs according to policy, without losing audit trail\n\n### Logging\n- [ ] Logs include correlationId + jobId + opName + timings; payloads are redacted\n","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:43:04.29681485-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:07:22.867107762-05:00","dependencies":[{"issue_id":"flywheel_gateway-7n4","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:53.658966693-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-89x","title":"History Tracking System","description":"\n## Testing Requirements\n\n### Unit Tests\n- [ ] HistoryEntry serialization/deserialization\n- [ ] Token counting accuracy\n- [ ] Cost calculation for different models\n- [ ] Pagination cursor encoding/decoding\n\n### Integration Tests\n- [ ] History entries are persisted correctly\n- [ ] Query by agent returns correct results\n- [ ] Date range filtering works\n- [ ] Starred items filter correctly\n\n### Performance Tests\n- [ ] Query 10,000 entries in \u003c 100ms\n- [ ] Write throughput \u003e 1000 entries/second\n- [ ] Pagination handles large result sets efficiently\n\n### Data Integrity Tests\n- [ ] Concurrent writes don't lose data\n- [ ] Unicode in prompts/responses preserved\n- [ ] Large responses (\u003e100KB) stored correctly\n\n\n\n## Acceptance Criteria\n\n- [ ] All mutating operations append a history entry with correlation ID and minimal structured metadata\n- [ ] History is queryable by time range, entity (agent/job/bead), and text search (where applicable)\n- [ ] Output is persisted and replayable; extraction supports quoting/copying with provenance\n- [ ] Redaction rules prevent leaking secrets/tokens in stored history and in API responses\n- [ ] REST endpoints support pagination + stable cursors; WebSocket can stream updates in real time\n- [ ] UI history browser supports filtering, drill-down, and sensible empty/loading/error states\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] HistoryEntry: records prompt\n- [ ] HistoryEntry: records response summary\n- [ ] HistoryEntry: tracks token counts\n- [ ] HistoryEntry: tracks duration\n- [ ] HistoryEntry: records outcome\n- [ ] Star: toggles starred state\n- [ ] Search: filters by keyword\n- [ ] Search: filters by date range\n- [ ] Search: filters by outcome\n- [ ] Export: formats as JSON\n- [ ] Export: formats as CSV\n- [ ] Pagination: cursor-based\n\n### Integration Tests\n- [ ] POST /agents/:id/send records history\n- [ ] GET /history returns entries\n- [ ] GET /history filters work\n- [ ] PUT /history/:id/star toggles star\n- [ ] GET /history/export downloads file\n- [ ] Pagination returns correct pages\n\n### E2E Tests\n- [ ] View history in UI\n- [ ] Search finds old prompts\n- [ ] Star entry for later\n- [ ] Export history to file\n\n### Performance Tests\n- [ ] History insert \u003c10ms\n- [ ] Query 1000 entries \u003c100ms\n- [ ] Search indexed \u003c200ms\n- [ ] Export streaming works\n\n### Failure Mode Tests\n- [ ] Storage full: warning shown\n- [ ] Corrupt entry: skipped in list\n- [ ] Long prompt: truncated in summary\n- [ ] Missing agent: history preserved","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:37:52.618472437-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:58:16.416643027-05:00","dependencies":[{"issue_id":"flywheel_gateway-89x","depends_on_id":"flywheel_gateway-398","type":"blocks","created_at":"2026-01-08T14:01:54.462780353-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-89x","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:55.923936692-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-bpg","title":"FEAT: UBS Scanner Integration","description":"## Background\n\nUBS (Universal Build Scanner) provides automated code analysis capabilities for detecting issues, vulnerabilities, and improvement opportunities across codebases. This integration enables Flywheel Gateway to leverage UBS for proactive code quality management with the unique ability to automatically create beads from findings.\n\n## Reasoning\n\nManual code review catches issues but:\n- Is time-consuming and inconsistent\n- Misses patterns that automated tools detect\n- Creates friction in the development workflow\n- Findings often get lost or forgotten\n\nUBS provides automated scanning with findings that can be directly converted to actionable beads, ensuring issues are tracked, prioritized, and resolved through the standard Flywheel workflow.\n\n## Technical Considerations\n\n### Client Architecture\n- Follow flywheel-clients pattern\n- Support async scanning with progress callbacks\n- Handle large scan results efficiently\n- Integrate with BV for bead creation\n\n### API Design\n```typescript\ninterface UBSClient {\n  // Scan Operations\n  startScan(config: ScanConfig): Promise\u003cScanJob\u003e;\n  getScanStatus(jobId: string): Promise\u003cScanStatus\u003e;\n  cancelScan(jobId: string): Promise\u003cvoid\u003e;\n  getScanResults(jobId: string): Promise\u003cScanResults\u003e;\n  \n  // Findings\n  getFindings(filters?: FindingFilters): Promise\u003cFinding[]\u003e;\n  getFindingById(id: string): Promise\u003cFinding\u003e;\n  getFindingsBySeverity(): Promise\u003cGroupedFindings\u003e;\n  dismissFinding(id: string, reason: DismissReason): Promise\u003cvoid\u003e;\n  bulkDismiss(ids: string[], reason: DismissReason): Promise\u003cvoid\u003e;\n  \n  // Auto-Bead\n  createBeadFromFinding(findingId: string, options?: BeadOptions): Promise\u003cBead\u003e;\n  bulkCreateBeads(findingIds: string[], options?: BeadOptions): Promise\u003cBead[]\u003e;\n  \n  // History\n  getScanHistory(filters?: HistoryFilters): Promise\u003cScanSummary[]\u003e;\n  compareScanResults(scanId1: string, scanId2: string): Promise\u003cScanComparison\u003e;\n  getTrends(period: TrendPeriod): Promise\u003cTrendData\u003e;\n}\n\ninterface ScanConfig {\n  projectPath: string;\n  scanTypes?: ('security' | 'quality' | 'performance' | 'style')[];\n  excludePaths?: string[];\n  severity?: SeverityLevel[];\n  rulesets?: string[];\n  incremental?: boolean;\n}\n\ninterface Finding {\n  id: string;\n  type: string;\n  severity: 'critical' | 'high' | 'medium' | 'low' | 'info';\n  title: string;\n  description: string;\n  file: string;\n  line?: number;\n  column?: number;\n  codeSnippet?: string;\n  suggestedFix?: string;\n  rule: string;\n  tags: string[];\n  status: 'open' | 'dismissed' | 'fixed' | 'converted';\n  createdAt: Date;\n  convertedBeadId?: string;\n}\n\ninterface ScanResults {\n  jobId: string;\n  status: 'completed' | 'failed' | 'partial';\n  findings: Finding[];\n  summary: {\n    total: number;\n    bySeverity: Record\u003cSeverityLevel, number\u003e;\n    byType: Record\u003cstring, number\u003e;\n  };\n  duration: number;\n  coverage: number;\n}\n```\n\n### Scanner Dashboard\nThe dashboard provides comprehensive visibility into scan results:\n- Summary cards (total findings, by severity)\n- Trend charts (findings over time)\n- Finding list with filters and search\n- File tree view of affected files\n- Quick actions (dismiss, create bead)\n- Scan configuration panel\n\n### Auto-Bead Feature\nThe killer feature: automatically creating beads from findings\n```typescript\n// Finding → Bead transformation\n{\n  title: `Fix ${finding.severity} ${finding.type}: ${finding.title}`,\n  body: `\n    ## Finding Details\n    - **Rule**: ${finding.rule}\n    - **File**: ${finding.file}:${finding.line}\n    \n    ## Description\n    ${finding.description}\n    \n    ## Suggested Fix\n    ${finding.suggestedFix}\n    \n    ## Code Context\n    \\`\\`\\`\n    ${finding.codeSnippet}\n    \\`\\`\\`\n  `,\n  labels: ['scanner', finding.type, finding.severity],\n  metadata: {\n    findingId: finding.id,\n    scanJobId: jobId\n  }\n}\n```\n\n### Performance Requirements\n- Scan initiation in \u003c1 second\n- Progress updates every 5 seconds\n- Results pagination for large finding sets\n- Background scanning option\n- Incremental scans for changed files only\n\n## Acceptance Criteria\n\n1. **UBS Client Implementation**\n   - [ ] UBSClient class with TypeScript types\n   - [ ] All scan operations functional\n   - [ ] Progress tracking with callbacks\n   - [ ] Error handling and retry logic\n   - [ ] Unit tests with mocked scanner\n\n2. **Scan Operations**\n   - [ ] Start scan with configuration\n   - [ ] Real-time progress updates\n   - [ ] Cancel running scans\n   - [ ] Incremental scan support\n   - [ ] Multiple scan type support\n\n3. **Findings Management**\n   - [ ] List findings with filters\n   - [ ] Group by severity functional\n   - [ ] Dismiss with reason (false positive, won't fix, etc.)\n   - [ ] Bulk dismiss support\n   - [ ] Finding status tracking\n\n4. **Auto-Bead Creation**\n   - [ ] Create bead from single finding\n   - [ ] Bulk bead creation\n   - [ ] Bead links back to finding\n   - [ ] Finding marked as converted\n   - [ ] Custom bead template support\n\n5. **Scan History**\n   - [ ] View past scan results\n   - [ ] Compare scans (new/fixed/persistent findings)\n   - [ ] Trend data (week, month, quarter)\n   - [ ] Export scan reports\n\n6. **Scanner Dashboard UI**\n   - [ ] Summary cards with severity counts\n   - [ ] Trend charts (line, bar)\n   - [ ] Finding list with virtual scroll\n   - [ ] Filter panel (severity, type, file, status)\n   - [ ] Scan configuration modal\n   - [ ] Progress indicator for active scans\n   - [ ] Quick action buttons\n\n7. **Integration**\n   - [ ] Dashboard accessible from main nav\n   - [ ] Findings link to file in code view\n   - [ ] Created beads appear in BV integration\n   - [ ] Notifications for critical findings\n\n## File Locations\n\n### Client Package\n- `packages/flywheel-clients/src/scanner/index.ts` - Main exports\n- `packages/flywheel-clients/src/scanner/client.ts` - UBSClient implementation\n- `packages/flywheel-clients/src/scanner/types.ts` - TypeScript interfaces\n- `packages/flywheel-clients/src/scanner/progress.ts` - Progress tracking\n- `packages/flywheel-clients/src/scanner/transforms.ts` - Finding → Bead transforms\n- `packages/flywheel-clients/src/scanner/__tests__/` - Unit tests\n\n### Web Components\n- `apps/web/src/components/scanner/ScannerDashboard.tsx` - Main dashboard\n- `apps/web/src/components/scanner/ScanSummaryCards.tsx` - Summary statistics\n- `apps/web/src/components/scanner/FindingsList.tsx` - Finding list component\n- `apps/web/src/components/scanner/FindingItem.tsx` - Individual finding row\n- `apps/web/src/components/scanner/FindingDetail.tsx` - Finding detail panel\n- `apps/web/src/components/scanner/ScanConfigModal.tsx` - Scan configuration\n- `apps/web/src/components/scanner/ScanProgress.tsx` - Active scan progress\n- `apps/web/src/components/scanner/TrendCharts.tsx` - Historical trends\n- `apps/web/src/components/scanner/ScanHistory.tsx` - Past scan list\n- `apps/web/src/hooks/useUBSScanner.ts` - React hook for scanner ops\n- `apps/web/src/hooks/useScanProgress.ts` - Real-time progress hook\n\n## References\n\n- PLAN.md §15: UBS Scanner Integration specifications\n- UBS Scanner API documentation (internal)\n- SonarQube/ESLint patterns for finding UX\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Scanner adapter parses UBS output into normalized findings (file/line/col/severity)\n- [ ] Result classification and deduping are deterministic\n\n### Integration Tests\n- [ ] When UBS is installed (or mocked): run a scan and persist results; results appear in REST + WS\n\n### Failure Mode Tests\n- [ ] UBS missing / non-zero exit / malformed output → actionable error code + partial diagnostics\n\n### Logging\n- [ ] Logs include correlationId + scanId + targetPaths + exitCode; raw code is not logged\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] UBSClient.scan: sends files to scanner\n- [ ] UBSClient.scan: parses findings\n- [ ] Finding: extracts category\n- [ ] Finding: extracts file:line:col\n- [ ] Finding: extracts suggestion\n- [ ] Finding: severity mapped correctly\n- [ ] AutoBead: creates bead from finding\n- [ ] AutoBead: sets correct priority\n- [ ] AutoBead: links to parent issue\n- [ ] FixWorkflow: navigates to finding\n- [ ] FixWorkflow: re-scans after fix\n- [ ] Language filter: --only flag works\n\n### Integration Tests\n- [ ] Scan returns findings as JSON\n- [ ] Findings parsed into structured data\n- [ ] Bead created for each finding\n- [ ] Beads linked to source issue\n- [ ] Re-scan after fix updates beads\n- [ ] Exit code reflects findings\n- [ ] --ci mode works in pipeline\n\n### E2E Tests\n- [ ] Agent runs UBS before commit\n- [ ] Findings shown in UI\n- [ ] Fix applied and re-scanned\n- [ ] Commit proceeds when clean\n\n### Performance Tests\n- [ ] Scan staged files \u003c1s\n- [ ] Large file scan \u003c5s\n- [ ] Bead creation \u003c100ms per finding\n- [ ] Concurrent scans supported\n\n### Failure Mode Tests\n- [ ] UBS not installed: clear message\n- [ ] Invalid language: validation error\n- [ ] Scan timeout: appropriate error\n- [ ] Binary file: skipped gracefully","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:46:02.878656771-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:07:34.95900281-05:00","dependencies":[{"issue_id":"flywheel_gateway-bpg","depends_on_id":"flywheel_gateway-p8j","type":"blocks","created_at":"2026-01-08T14:01:49.436551646-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-bqs","title":"DCG Advanced Features","description":"## Overview\n\nDCG (Dangerous Command Guard) Advanced Features extends the core content safety system with administrative capabilities, feedback mechanisms, and analytics. This enables operators to fine-tune content filtering behavior and track safety metrics.\n\n## Background \u0026 Reasoning\n\nThe base DCG implementation provides essential content filtering, but production deployments require:\n\n- Administrative control over allowlists and blocklists\n- Feedback loops to reduce false positives\n- Visibility into block statistics and patterns\n- Integration with CM (Claude Mind) for pattern learning\n\nThese advanced features transform DCG from a static filter into an adaptive safety system.\n\n## Feature Components\n\n### 1. Allowlist Management UI\n\nAdministrators need to manage exceptions for legitimate content that triggers false positives:\n\n```typescript\ninterface AllowlistEntry {\n  id: string;\n  pattern: string;           // Regex or exact match\n  matchType: 'exact' | 'regex' | 'contains';\n  scope: 'global' | 'repository' | 'agent';\n  scopeId?: string;          // Repository or agent ID if scoped\n  reason: string;            // Why this is allowed\n  createdBy: string;\n  createdAt: Date;\n  expiresAt?: Date;          // Optional expiration\n  usageCount: number;        // How often this rule matched\n}\n\ninterface AllowlistService {\n  addEntry(entry: CreateAllowlistEntry): Promise\u003cAllowlistEntry\u003e;\n  removeEntry(id: string): Promise\u003cvoid\u003e;\n  updateEntry(id: string, updates: Partial\u003cAllowlistEntry\u003e): Promise\u003cAllowlistEntry\u003e;\n  listEntries(scope?: AllowlistScope): Promise\u003cAllowlistEntry[]\u003e;\n  checkContent(content: string, context: ContentContext): Promise\u003cAllowlistMatch | null\u003e;\n}\n```\n\n### 2. False Positive Feedback Loop\n\nWhen content is incorrectly blocked, users can submit feedback:\n\n```typescript\ninterface FalsePositiveFeedback {\n  id: string;\n  blockedContent: string;      // The content that was blocked\n  blockReason: string;         // Which rule triggered the block\n  packId: string;              // Which pack contained the rule\n  submittedBy: string;\n  submittedAt: Date;\n  status: 'pending' | 'reviewed' | 'accepted' | 'rejected';\n  reviewedBy?: string;\n  reviewedAt?: Date;\n  resolution?: 'allowlisted' | 'rule-modified' | 'no-action';\n  notes?: string;\n}\n\ninterface FeedbackWorkflow {\n  submitFeedback(feedback: CreateFeedback): Promise\u003cFalsePositiveFeedback\u003e;\n  reviewFeedback(id: string, decision: FeedbackDecision): Promise\u003cFalsePositiveFeedback\u003e;\n  getPendingFeedback(): Promise\u003cFalsePositiveFeedback[]\u003e;\n  getFeedbackStats(): Promise\u003cFeedbackStats\u003e;\n}\n```\n\n### 3. Pack Enable/Disable Configuration\n\nDCG rules are organized into packs that can be individually enabled or disabled:\n\n```typescript\ninterface DCGPack {\n  id: string;\n  name: string;\n  description: string;\n  version: string;\n  ruleCount: number;\n  enabled: boolean;\n  priority: number;          // Higher priority packs evaluated first\n  scope: 'system' | 'organization' | 'repository';\n}\n\ninterface PackConfiguration {\n  enablePack(packId: string): Promise\u003cvoid\u003e;\n  disablePack(packId: string): Promise\u003cvoid\u003e;\n  setPriority(packId: string, priority: number): Promise\u003cvoid\u003e;\n  getPackStatus(): Promise\u003cDCGPack[]\u003e;\n  reloadPacks(): Promise\u003cvoid\u003e;\n}\n```\n\n### 4. Block Statistics Dashboard\n\nReal-time visibility into DCG activity:\n\n```typescript\ninterface BlockStatistics {\n  totalBlocks: number;\n  blocksToday: number;\n  blocksByPack: Record\u003cstring, number\u003e;\n  blocksByRule: Record\u003cstring, number\u003e;\n  blocksByAgent: Record\u003cstring, number\u003e;\n  blocksByHour: TimeSeriesData;\n  topBlockedPatterns: PatternStat[];\n  falsePositiveRate: number;\n}\n\ninterface StatisticsService {\n  getStatistics(timeRange: TimeRange): Promise\u003cBlockStatistics\u003e;\n  getBlockHistory(filters: BlockFilters): Promise\u003cBlockEvent[]\u003e;\n  exportStatistics(format: 'csv' | 'json'): Promise\u003cstring\u003e;\n}\n```\n\n### 5. CM Integration for Pattern Learning\n\nIntegration with Claude Mind enables the safety system to learn from patterns:\n\n```typescript\ninterface CMPatternLearning {\n  // Report patterns to CM for analysis\n  reportPattern(pattern: PatternReport): Promise\u003cvoid\u003e;\n  \n  // Request pattern classification from CM\n  classifyContent(content: string): Promise\u003cContentClassification\u003e;\n  \n  // Get suggested rules from CM analysis\n  getSuggestedRules(): Promise\u003cSuggestedRule[]\u003e;\n  \n  // Apply CM-suggested rule with human approval\n  applySuggestedRule(ruleId: string, approver: string): Promise\u003cvoid\u003e;\n}\n\ninterface PatternReport {\n  content: string;\n  wasBlocked: boolean;\n  wasFalsePositive: boolean;\n  context: ContentContext;\n}\n\ninterface ContentClassification {\n  category: 'safe' | 'suspicious' | 'dangerous';\n  confidence: number;\n  reasoning: string;\n  suggestedAction: 'allow' | 'block' | 'review';\n}\n```\n\n## Frontend Components\n\n### DCGDashboard.tsx\nMain dashboard showing:\n- Overall safety metrics\n- Block activity chart\n- Pack status overview\n- Quick actions\n\n### AllowlistManager.tsx\n- List of allowlist entries with search/filter\n- Add/edit/delete entry forms\n- Scope selection (global, repo, agent)\n- Usage statistics per entry\n\n### FeedbackQueue.tsx\n- Pending feedback review queue\n- Feedback detail view\n- Decision interface (accept/reject)\n- Resolution actions\n\n### PackConfigurator.tsx\n- Pack list with enable/disable toggles\n- Priority ordering (drag-and-drop)\n- Pack details and rule preview\n- Reload functionality\n\n### BlockStatisticsChart.tsx\n- Time series visualization of blocks\n- Breakdown by pack, rule, agent\n- Trend analysis\n- Export controls\n\n## File Locations\n\n- `apps/gateway/src/dcg/allowlist.service.ts` - Allowlist management\n- `apps/gateway/src/dcg/feedback.service.ts` - False positive feedback\n- `apps/gateway/src/dcg/pack-config.service.ts` - Pack configuration\n- `apps/gateway/src/dcg/statistics.service.ts` - Block statistics\n- `apps/gateway/src/dcg/cm-integration.service.ts` - CM pattern learning\n- `apps/gateway/src/controllers/dcg.controller.ts` - REST API\n- `apps/web/src/components/safety/DCGDashboard.tsx` - Main dashboard\n- `apps/web/src/components/safety/AllowlistManager.tsx` - Allowlist UI\n- `apps/web/src/components/safety/FeedbackQueue.tsx` - Feedback review\n- `apps/web/src/components/safety/PackConfigurator.tsx` - Pack config\n- `apps/web/src/components/safety/BlockStatisticsChart.tsx` - Statistics viz\n\n## Database Schema\n\n```sql\nCREATE TABLE dcg_allowlist (\n  id UUID PRIMARY KEY,\n  pattern TEXT NOT NULL,\n  match_type VARCHAR(50) NOT NULL,\n  scope VARCHAR(50) NOT NULL,\n  scope_id UUID,\n  reason TEXT,\n  created_by UUID REFERENCES users(id),\n  created_at TIMESTAMP DEFAULT NOW(),\n  expires_at TIMESTAMP,\n  usage_count INTEGER DEFAULT 0\n);\n\nCREATE TABLE dcg_feedback (\n  id UUID PRIMARY KEY,\n  blocked_content TEXT NOT NULL,\n  block_reason TEXT NOT NULL,\n  pack_id VARCHAR(255),\n  submitted_by UUID REFERENCES users(id),\n  submitted_at TIMESTAMP DEFAULT NOW(),\n  status VARCHAR(50) DEFAULT 'pending',\n  reviewed_by UUID REFERENCES users(id),\n  reviewed_at TIMESTAMP,\n  resolution VARCHAR(50),\n  notes TEXT\n);\n\nCREATE TABLE dcg_packs (\n  id VARCHAR(255) PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  description TEXT,\n  version VARCHAR(50),\n  rule_count INTEGER,\n  enabled BOOLEAN DEFAULT true,\n  priority INTEGER DEFAULT 0,\n  scope VARCHAR(50) DEFAULT 'system'\n);\n\nCREATE TABLE dcg_block_events (\n  id UUID PRIMARY KEY,\n  content_hash VARCHAR(64),\n  rule_id VARCHAR(255),\n  pack_id VARCHAR(255),\n  agent_id UUID,\n  repository_id UUID,\n  blocked_at TIMESTAMP DEFAULT NOW(),\n  metadata JSONB\n);\n\nCREATE INDEX idx_block_events_time ON dcg_block_events(blocked_at);\nCREATE INDEX idx_block_events_pack ON dcg_block_events(pack_id);\nCREATE INDEX idx_feedback_status ON dcg_feedback(status);\n```\n\n## Acceptance Criteria\n\n- [ ] Allowlist entries can be created, updated, and deleted via UI\n- [ ] Allowlist scoping correctly applies to global, repository, or agent level\n- [ ] False positive feedback queue displays pending items for review\n- [ ] Feedback decisions create appropriate allowlist entries when accepted\n- [ ] Packs can be enabled/disabled without service restart\n- [ ] Pack priority changes take effect immediately\n- [ ] Block statistics dashboard loads within 2 seconds\n- [ ] Statistics export produces valid CSV/JSON\n- [ ] CM integration classifies content with \u003e90% agreement on known patterns\n- [ ] CM-suggested rules require human approval before activation\n- [ ] All administrative actions logged with actor identity\n\n## Testing Requirements\n\n- Unit tests for allowlist matching logic\n- Integration tests for feedback workflow\n- E2E tests for pack configuration changes\n- Performance tests for statistics aggregation\n- Security tests for unauthorized access attempts\n\n## Security Considerations\n\n- Allowlist management requires admin permissions\n- Blocked content is hashed before storage (privacy)\n- Feedback submissions rate limited\n- CM integration uses authenticated API\n- Export functionality audit logged\n\n## References\n\n- PLAN.md §17.6 - DCG Architecture\n- Content safety best practices\n- Feedback loop design patterns","notes":"## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Allowlist matching logic correctly applies scope hierarchy (global \u003e repo \u003e agent)\n- [ ] Pattern priority resolution is deterministic when multiple packs match\n- [ ] Feedback state machine enforces valid transitions (pending → accepted/rejected)\n- [ ] Statistics aggregation handles time zone boundaries correctly\n\n### Integration Tests\n- [ ] Allowlist CRUD operations persist and take effect without restart\n- [ ] Feedback acceptance creates allowlist entry with correct scope\n- [ ] Pack enable/disable propagates to all active sessions immediately\n- [ ] CM classification returns consistent results for known patterns\n\n### E2E Tests\n- [ ] Complete workflow: block → feedback → review → allowlist → no-block\n- [ ] Dashboard loads statistics within 2s for 30-day range\n- [ ] Export produces valid CSV/JSON matching displayed data\n\n### Failure Mode Tests\n- [ ] CM unavailable → graceful fallback to pattern-only classification\n- [ ] Database unavailable → feedback queued in memory with size limit\n\n### Performance Tests\n- [ ] Statistics query under 500ms for 100K block events\n- [ ] Allowlist check adds \u003c 1ms to command latency\n\n### Security Tests\n- [ ] Unauthorized allowlist modification returns 403\n- [ ] Rate limiting prevents feedback spam (max 10/min per user)\n\n### Logging\n- [ ] Logs include correlationId + feedbackId + packId + decision; blocked content is hashed, not logged","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:49:44.387964795-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:39:05.943353145-05:00","dependencies":[{"issue_id":"flywheel_gateway-bqs","depends_on_id":"flywheel_gateway-5nq","type":"blocks","created_at":"2026-01-08T14:02:03.074070018-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-bqs","depends_on_id":"flywheel_gateway-1hv","type":"blocks","created_at":"2026-01-08T14:02:04.894494125-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-c4z","title":"FEAT: CASS Search Integration","description":"## Background\n\nCASS (Claude Associative Semantic Search) provides powerful semantic search capabilities across the Flywheel ecosystem. This integration enables users to search past sessions, code snippets, conversations, and documentation using natural language queries with relevance ranking.\n\n## Reasoning\n\nTraditional keyword search fails developers in several ways:\n- Cannot find code by describing what it does (\"the function that validates email addresses\")\n- No understanding of synonyms or related concepts\n- Poor ranking when multiple results match\n- No context awareness (what the user is currently working on)\n\nCASS uses embedding-based semantic search to understand query intent and return contextually relevant results, dramatically improving the developer experience when searching across their development history.\n\n## Technical Considerations\n\n### Client Architecture\n- Implement as flywheel-client following established patterns\n- Support streaming results for large result sets\n- Include result highlighting for matched content\n- Provide relevance scores for ranking transparency\n\n### API Design\n```typescript\ninterface CASSClient {\n  // Core Search\n  search(query: SearchQuery): Promise\u003cSearchResults\u003e;\n  searchSessions(query: string, options?: SessionSearchOptions): Promise\u003cSessionResult[]\u003e;\n  searchCode(query: string, options?: CodeSearchOptions): Promise\u003cCodeResult[]\u003e;\n  searchConversations(query: string, options?: ConversationSearchOptions): Promise\u003cConversationResult[]\u003e;\n  \n  // Indexing (for local content)\n  indexContent(content: IndexableContent): Promise\u003cIndexResult\u003e;\n  reindexProject(projectId: string): Promise\u003cReindexJob\u003e;\n  getIndexStatus(projectId: string): Promise\u003cIndexStatus\u003e;\n  \n  // Suggestions\n  getSuggestions(partial: string): Promise\u003cSuggestion[]\u003e;\n  getRelatedContent(contentId: string): Promise\u003cRelatedContent[]\u003e;\n}\n\ninterface SearchQuery {\n  query: string;\n  filters?: {\n    contentTypes?: ('session' | 'code' | 'conversation' | 'doc')[];\n    dateRange?: DateRange;\n    projects?: string[];\n    authors?: string[];\n  };\n  limit?: number;\n  offset?: number;\n  includeHighlights?: boolean;\n}\n\ninterface SearchResults {\n  results: SearchResult[];\n  total: number;\n  facets?: SearchFacets;\n  queryTime: number;\n}\n```\n\n### Search UI Component\nThe search UI must provide excellent UX:\n- Debounced input (300ms default, configurable)\n- Loading state with skeleton results\n- Keyboard navigation (arrow keys, enter to select)\n- Recent searches history\n- Search suggestions as user types\n- Filter chips for content type, date, project\n- Result preview on hover/focus\n\n### Performance Requirements\n- Search suggestions in \u003c50ms\n- Full search results in \u003c500ms\n- Debounce prevents excessive API calls\n- Virtual scrolling for large result sets\n- Cache recent searches locally\n\n### Security Considerations\n- Respect access control on indexed content\n- Sanitize queries to prevent injection\n- Rate limiting on search API\n- Audit log for search queries (optional, configurable)\n\n## Acceptance Criteria\n\n1. **CASS Client Implementation**\n   - [ ] CASSClient class with TypeScript types\n   - [ ] All search operations functional\n   - [ ] Streaming support for large results\n   - [ ] Error handling with retry logic\n   - [ ] Unit tests with mocked responses\n\n2. **Search Operations**\n   - [ ] General search across all content types\n   - [ ] Session-specific search with metadata\n   - [ ] Code search with syntax-aware highlighting\n   - [ ] Conversation search with message context\n   - [ ] Filter support (date, project, content type)\n\n3. **Search UI Component**\n   - [ ] Debounced search input (configurable delay)\n   - [ ] Loading states and error handling\n   - [ ] Result list with relevance scores\n   - [ ] Syntax highlighting for code results\n   - [ ] \"Load more\" pagination\n   - [ ] Empty state and no results state\n\n4. **Result Ranking**\n   - [ ] Relevance score displayed per result\n   - [ ] Sort options (relevance, date, type)\n   - [ ] Boost recent content option\n   - [ ] Project context boosting (current project ranked higher)\n\n5. **Performance**\n   - [ ] Debounce prevents API spam\n   - [ ] Results render progressively\n   - [ ] Virtual scrolling for 100+ results\n   - [ ] Search history cached locally\n\n6. **Accessibility**\n   - [ ] Full keyboard navigation\n   - [ ] Screen reader announcements for results\n   - [ ] Focus management on navigation\n   - [ ] ARIA labels and roles\n\n## File Locations\n\n### Client Package\n- `packages/flywheel-clients/src/cass/index.ts` - Main exports\n- `packages/flywheel-clients/src/cass/client.ts` - CASSClient implementation\n- `packages/flywheel-clients/src/cass/types.ts` - TypeScript interfaces\n- `packages/flywheel-clients/src/cass/streaming.ts` - Streaming result handler\n- `packages/flywheel-clients/src/cass/__tests__/` - Unit tests\n\n### Web Components\n- `apps/web/src/components/memory/SearchBar.tsx` - Main search input\n- `apps/web/src/components/memory/SearchResults.tsx` - Results container\n- `apps/web/src/components/memory/SearchResultItem.tsx` - Individual result\n- `apps/web/src/components/memory/SearchFilters.tsx` - Filter controls\n- `apps/web/src/components/memory/SearchSuggestions.tsx` - Autocomplete dropdown\n- `apps/web/src/components/memory/CodeResultPreview.tsx` - Code snippet preview\n- `apps/web/src/components/memory/SessionResultPreview.tsx` - Session preview\n- `apps/web/src/hooks/useCASSSearch.ts` - React hook with debouncing\n- `apps/web/src/hooks/useSearchHistory.ts` - Local search history\n\n## References\n\n- PLAN.md §14: CASS Search Integration specifications\n- CASS API documentation (internal)\n- Algolia InstantSearch patterns for UX inspiration\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] CASS adapter normalizes hits into a stable schema (id/title/snippet/score/timestamps)\n- [ ] Query building/escaping prevents injection into downstream CLI calls\n\n### Integration Tests\n- [ ] With cass available (or mocked): search returns hits and UI can render them\n\n### Failure Mode Tests\n- [ ] cass missing/unhealthy → actionable error code and degraded UI state (no crash)\n\n### Logging\n- [ ] Logs include correlationId + queryHash + hitCount + latencyMs; raw snippets are truncated/redacted\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] CASSClient.search: sends query with options\n- [ ] CASSClient.search: parses results correctly\n- [ ] CASSClient.view: returns session content\n- [ ] CASSClient.expand: returns context around match\n- [ ] CASSClient.health: returns index status\n- [ ] Search options: limit parameter respected\n- [ ] Search options: agent filter works\n- [ ] Search options: days filter works\n- [ ] Search options: fields minimal returns subset\n- [ ] Result parsing: extracts file path\n- [ ] Result parsing: extracts line number\n- [ ] Result parsing: extracts match snippet\n- [ ] Relevance scoring: recent higher\n- [ ] Relevance scoring: exact match higher\n\n### Integration Tests\n- [ ] Search returns results from indexed sessions\n- [ ] View returns full session content\n- [ ] Expand returns lines around match\n- [ ] Health shows index statistics\n- [ ] Empty query returns error\n- [ ] No results returns empty array\n- [ ] Large result set paginated\n\n### E2E Tests\n- [ ] Agent searches prior solutions\n- [ ] Search results help solve problem (qualitative)\n- [ ] Session archived and searchable\n\n### Performance Tests\n- [ ] Search \u003c200ms for typical query\n- [ ] View session \u003c100ms\n- [ ] Health check \u003c50ms\n- [ ] Concurrent searches don't block\n\n### Failure Mode Tests\n- [ ] CASS unavailable: graceful error\n- [ ] Invalid session path: 404\n- [ ] Index corrupt: clear error message\n- [ ] Search timeout: appropriate error","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:46:00.509465469-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:07:48.225975232-05:00","dependencies":[{"issue_id":"flywheel_gateway-c4z","depends_on_id":"flywheel_gateway-45c","type":"blocks","created_at":"2026-01-08T14:01:47.701271369-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-c6q","title":"FEAT: Real-Time Agent Collaboration Graph","description":"## Overview\n\nInteractive visualization showing agent coordination in real-time. The Collaboration Graph provides a dynamic, force-directed graph view of all active agents, their resource reservations, and inter-agent communication patterns within a session.\n\n## Background \u0026 Reasoning\n\nAs multi-agent systems grow in complexity, understanding coordination dynamics becomes critical. Operators frequently ask:\n\n- **\"Why is this agent waiting?\"** - Visualize blocking dependencies and resource contention\n- **\"Who has file X?\"** - Instantly see reservation ownership across the agent pool\n- **\"What's the communication flow?\"** - Trace message paths and handoff sequences\n- **\"Where are the bottlenecks?\"** - Identify coordination hotspots and deadlock risks\n\nWithout visibility into agent coordination, debugging multi-agent workflows becomes guesswork. The Collaboration Graph transforms abstract coordination state into intuitive visual patterns.\n\n## Technical Architecture\n\n### Graph Data Model\n\n```typescript\ninterface AgentNode {\n  id: string;\n  agentId: string;\n  status: 'active' | 'idle' | 'waiting' | 'blocked';\n  currentTask?: string;\n  reservationCount: number;\n  messagesSent: number;\n  messagesReceived: number;\n}\n\ninterface ReservationNode {\n  id: string;\n  resourcePath: string;\n  resourceType: 'file' | 'directory' | 'lock';\n  holderId: string;\n  waiters: string[];\n  acquiredAt: Date;\n}\n\ninterface ConflictNode {\n  id: string;\n  conflictType: 'deadlock' | 'contention' | 'timeout';\n  involvedAgents: string[];\n  involvedResources: string[];\n  severity: 'warning' | 'critical';\n  detectedAt: Date;\n}\n```\n\n### Edge Types\n\n| Edge Type | Description | Visual Style |\n|-----------|-------------|--------------|\n| `message` | Agent-to-agent communication | Animated dashed line, directional arrow |\n| `handoff` | Task delegation between agents | Thick solid line, pulse animation |\n| `dependency` | Blocking relationship (waiting for resource) | Red dotted line when blocked |\n| `reservation` | Agent owns resource | Green solid line to reservation node |\n| `waiting` | Agent waiting for resource | Orange dashed line to reservation node |\n\n### Real-Time Updates\n\n```typescript\n// WebSocket subscription for graph updates\nconst subscriptions = {\n  'agent.status': updateAgentNode,\n  'reservation.acquired': addReservationEdge,\n  'reservation.released': removeReservationEdge,\n  'message.sent': animateMessageEdge,\n  'conflict.detected': highlightConflictNode,\n  'conflict.resolved': removeConflictNode,\n};\n```\n\nUpdates are batched at 100ms intervals to prevent UI thrashing during high-activity periods.\n\n### View Modes\n\n| Mode | Shows | Use Case |\n|------|-------|----------|\n| **Agents Only** | Agent nodes + message/handoff edges | Communication flow analysis |\n| **Files** | Agent nodes + reservation nodes + ownership edges | Resource contention debugging |\n| **Full** | All nodes + all edges | Complete system state |\n\n### Layout Algorithm\n\n- **Base**: Force-directed layout using D3-force\n- **Clustering**: Semantic grouping by active task similarity\n- **Collision**: Node repulsion prevents overlap\n- **Centering**: Active/blocked agents pulled toward center\n- **Stabilization**: Layout settles within 500ms of changes\n\n## Key Components\n\n```\napps/web/src/components/collaboration/\n├── CollaborationGraph.tsx       # Main container, manages state \u0026 subscriptions\n├── nodes/\n│   ├── AgentGraphNode.tsx       # Agent visualization with status indicators\n│   ├── ReservationGraphNode.tsx # Resource node with holder/waiter counts\n│   └── ConflictGraphNode.tsx    # Conflict alert with severity styling\n├── edges/\n│   ├── MessageEdge.tsx          # Animated message flow visualization\n│   ├── HandoffEdge.tsx          # Task delegation indicator\n│   └── DependencyEdge.tsx       # Blocking relationship with state color\n├── controls/\n│   ├── ViewModeSelector.tsx     # Toggle between view modes\n│   ├── GraphLegend.tsx          # Visual key for node/edge types\n│   └── GraphStats.tsx           # Real-time metrics panel\n├── hooks/\n│   ├── useGraphSubscription.ts  # WebSocket subscription management\n│   ├── useGraphLayout.ts        # D3-force layout integration\n│   └── useGraphSelection.ts     # Node/edge selection state\n└── utils/\n    ├── graphTransforms.ts       # API data to React Flow format\n    └── layoutConfig.ts          # D3-force parameters\n```\n\n## Technology\n\n- **React Flow** (`@xyflow/react`) - Graph rendering and interaction\n- **D3-force** - Physics-based layout algorithm\n- **WebSocket** - Real-time state synchronization\n- **Zustand** - Graph state management\n\n## File Locations\n\n| Component | Path |\n|-----------|------|\n| Main graph component | `apps/web/src/components/collaboration/CollaborationGraph.tsx` |\n| Graph nodes | `apps/web/src/components/collaboration/nodes/` |\n| Graph edges | `apps/web/src/components/collaboration/edges/` |\n| Graph hooks | `apps/web/src/components/collaboration/hooks/` |\n| Graph utilities | `apps/web/src/components/collaboration/utils/` |\n| Graph tests | `apps/web/src/components/collaboration/__tests__/` |\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] Graph layout algorithm produces stable positions\n- [ ] Node components render correct status indicators\n- [ ] Edge components animate on message events\n- [ ] View mode filtering shows/hides correct elements\n- [ ] Graph transforms handle malformed API data\n\n### Integration Tests\n- [ ] WebSocket subscription receives and processes updates\n- [ ] Multiple rapid updates batch correctly\n- [ ] Disconnection/reconnection maintains graph state\n- [ ] Selection state persists across updates\n\n### E2E Tests\n- [ ] View mode switching updates graph immediately\n- [ ] Clicking agent node opens agent detail panel\n- [ ] Clicking reservation node shows resource info\n- [ ] Graph renders correctly with 10+ agents\n- [ ] Conflict highlighting draws user attention\n\n### Performance Tests\n- [ ] Graph renders 50+ agents at 60fps\n- [ ] Layout stabilizes within 500ms\n- [ ] Memory usage stable over 1hr session\n- [ ] WebSocket message processing \u003c 10ms\n\n## Logging Requirements\n\n### Graph State Changes\n```typescript\nlogger.debug('graph.node.added', { nodeType, nodeId, timestamp });\nlogger.debug('graph.edge.added', { edgeType, source, target });\nlogger.debug('graph.layout.stabilized', { nodeCount, edgeCount, duration });\n```\n\n### WebSocket Metrics\n```typescript\nlogger.info('graph.subscription.connected', { sessionId });\nlogger.warn('graph.subscription.reconnecting', { attempt, backoff });\nlogger.info('graph.messages.processed', { count, batchDuration });\n```\n\n## Acceptance Criteria\n\n- [ ] Graph displays all active agents with correct status indicators\n- [ ] Reservation ownership edges update within 200ms of acquisition\n- [ ] Message animations visible for inter-agent communication\n- [ ] Conflict nodes appear immediately when detected\n- [ ] View mode toggle switches display within 100ms\n- [ ] Graph legend accurately describes all visual elements\n- [ ] Stats panel shows real-time agent/reservation counts\n- [ ] Graph remains responsive with 50+ concurrent agents\n- [ ] Keyboard navigation supported for accessibility\n- [ ] Graph state persists across browser refresh (session storage)\n\n## Reference\n\nPLAN.md §22.4 - Real-Time Agent Collaboration Graph\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] GraphNode: represents agent with position\n- [ ] GraphNode: updates on state change\n- [ ] GraphEdge: represents communication\n- [ ] GraphEdge: updates on message sent\n- [ ] FileHeatMap: tracks file activity\n- [ ] FileHeatMap: calculates heat scores\n- [ ] Timeline: records interactions chronologically\n- [ ] Timeline: filters by time range\n- [ ] Layout: force-directed positions nodes\n- [ ] Layout: minimizes edge crossings\n- [ ] Animation: transitions smooth\n- [ ] Legend: shows all status colors\n\n### Integration Tests\n- [ ] Graph updates when agent spawns\n- [ ] Graph updates when agent terminates\n- [ ] Edge appears on message send\n- [ ] Heat map updates on file edit\n- [ ] Timeline shows recent events\n- [ ] WebSocket pushes graph updates\n- [ ] Multiple clients see same graph\n\n### E2E Tests\n- [ ] Open collaboration view shows agents\n- [ ] Agents move as layout updates\n- [ ] Click node shows agent details\n- [ ] Filter by project works\n- [ ] Timeline scrubbing replays state\n\n### Performance Tests\n- [ ] Render 50 agents at 60fps\n- [ ] Update latency \u003c100ms\n- [ ] Memory stable over time\n- [ ] Animation frame drops \u003c5%\n\n### Failure Mode Tests\n- [ ] Agent disconnect: graceful removal\n- [ ] WebSocket disconnect: reconnect with state\n- [ ] Many events: throttling applied\n- [ ] Browser tab hidden: pauses updates","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:48:13.758143457-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:56:21.616028336-05:00","dependencies":[{"issue_id":"flywheel_gateway-c6q","depends_on_id":"flywheel_gateway-5nm","type":"blocks","created_at":"2026-01-08T14:01:56.683242029-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-c6q","depends_on_id":"flywheel_gateway-msz","type":"blocks","created_at":"2026-01-08T14:01:58.427270934-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-d18","title":"FEAT: Structured Logging + Correlation IDs + Audit Pipeline","description":"## Background\n\nObservability is foundational for operating a production agent orchestration system. Without structured logging and correlation IDs, debugging distributed request flows becomes nearly impossible. The audit pipeline provides compliance capabilities and operational insights.\n\n## Reasoning\n\n### Why Structured JSON Logging?\n- **Machine Parseable**: JSON logs can be ingested by log aggregation systems (ELK, Datadog, CloudWatch)\n- **Consistent Schema**: All log entries follow a predictable format with timestamp, level, service, message, and metadata\n- **Queryable**: Enables powerful filtering and analysis across all system components\n- **Production Ready**: Essential for SRE workflows and incident response\n\n### Why Correlation IDs?\n- **Request Tracing**: Track a single user request through gateway, agent service, and all downstream components\n- **Debugging**: When something fails, find all related log entries instantly\n- **Performance Analysis**: Measure latency across the full request lifecycle\n- **Multi-workspace Safety**: Ensure logs can be filtered per-workspace for support inquiries\n\n### Why Audit Pipeline?\n- **Compliance**: Many advanced customers require audit trails for agent actions\n- **Security**: Detect and investigate suspicious activity patterns\n- **Analytics**: Understand system usage patterns and optimize accordingly\n- **Accountability**: Track which user/API key triggered which agent operations\n\n## Technical Considerations\n\n### Logging Implementation\n- Use `pino` for high-performance JSON logging (10x faster than winston)\n- Configure log levels: trace, debug, info, warn, error, fatal\n- Default to `info` in production, `debug` in development\n- Implement log rotation and size limits for local development\n- Redact sensitive fields: API keys, tokens, passwords, PII\n\n### Correlation ID Strategy\n- Generate UUID v7 (time-ordered) for new requests at gateway entry\n- Accept incoming `X-Correlation-ID` header to support distributed tracing\n- Propagate via AsyncLocalStorage for automatic inclusion in all logs\n- Include in all HTTP responses for client-side correlation\n- Pass to spawned agents via environment variable\n\n### Audit Event Schema\n```typescript\ninterface AuditEvent {\n  id: string;                    // UUID v7\n  timestamp: string;             // ISO 8601\n  correlationId: string;         // Request correlation\n  workspaceId: string;              // Multi-workspace isolation\n  userId?: string;               // Authenticated user\n  apiKeyId?: string;             // API key used\n  action: AuditAction;           // Enum of auditable actions\n  resource: string;              // Resource identifier\n  resourceType: ResourceType;    // agent, session, output, etc.\n  outcome: 'success' | 'failure';\n  metadata: Record\u003cstring, unknown\u003e;\n  ipAddress?: string;            // For security analysis\n  userAgent?: string;            // Client identification\n}\n```\n\n### Sensitive Data Redaction\n- API keys: Show only last 4 characters\n- Passwords: Replace entirely with `[REDACTED]`\n- Email addresses: Partial redaction `j***@example.com`\n- Custom redaction rules via configuration\n\n## Acceptance Criteria\n\n- [ ] All HTTP requests receive correlation ID (generated or propagated)\n- [ ] All log entries include: timestamp, level, correlationId, service, message\n- [ ] Sensitive fields are automatically redacted in logs\n- [ ] Log level is configurable via environment variable\n- [ ] Audit events are emitted for: agent spawn, agent terminate, session create, authentication\n- [ ] Audit events are written to both log stream and audit table\n- [ ] Correlation ID appears in HTTP response headers\n- [ ] AsyncLocalStorage correctly propagates context through async operations\n- [ ] Unit tests for redaction logic with edge cases\n- [ ] Integration test for correlation ID propagation\n\n## File Locations\n\n### Middleware\n- `apps/gateway/src/middleware/correlation.middleware.ts` - Correlation ID generation/propagation\n- `apps/gateway/src/middleware/logging.middleware.ts` - Request/response logging\n\n### Services\n- `apps/gateway/src/services/audit.service.ts` - Audit event creation and persistence\n- `apps/gateway/src/services/logger.service.ts` - Configured pino logger instance\n\n### Utilities\n- `apps/gateway/src/utils/redaction.ts` - Sensitive data redaction functions\n- `apps/gateway/src/utils/async-context.ts` - AsyncLocalStorage helpers\n\n### Configuration\n- `apps/gateway/src/config/logging.config.ts` - Log levels, formats, destinations\n\n### Types\n- `packages/shared-types/src/audit.types.ts` - Audit event interfaces and enums\n\n## Reference\n\n- PLAN.md §24: Observability and Logging\n- OpenTelemetry Logging Data Model for schema inspiration\n- OWASP Logging Cheat Sheet for security considerations\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Correlation ID generation/propagation across middleware, services, and WS events\n- [ ] Redaction utilities remove secrets deterministically\n- [ ] Audit event builder produces schema-valid events with required metadata\n\n### Integration Tests\n- [ ] REST request with correlation header → response + logs include same correlationId\n- [ ] WS event emission includes correlationId and matches event schema\n\n### Failure Mode Tests\n- [ ] Logging backend unavailable → non-fatal fallback without dropping requests\n\n### Logging\n- [ ] Tests assert logs are structured JSON and contain expected keys (no console.log noise)\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:31:55.959839309-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:29:10.079422085-05:00","dependencies":[{"issue_id":"flywheel_gateway-d18","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T14:01:51.33497195-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-d8b","title":"TASK: Testing Infrastructure and Standards","description":"## Overview\nEstablish comprehensive testing infrastructure, patterns, and standards that apply across all Flywheel Gateway features. This bead defines the testing strategy that all other beads must follow.\n\n## Background \u0026 Reasoning\nTesting is not an afterthought - it's integral to each feature. This bead establishes:\n1. **Consistent test structure** across the monorepo\n2. **Shared test utilities** for common patterns\n3. **Performance baselines** that guard against regressions\n4. **E2E test framework** for critical user journeys\n5. **Detailed logging in tests** so failures are diagnosable\n\nEvery feature bead must include testing requirements that reference these standards.\n\n## Testing Pyramid\n\n### Unit Tests (80% coverage target)\n- **Framework**: Bun test (native, fast)\n- **Location**: `*.test.ts` co-located with source\n- **Scope**: Individual functions, classes, React components\n- **Mocking**: Prefer dependency injection over mocking\n- **Speed**: \u003c 100ms per test file\n\n### Integration Tests (70% coverage target)\n- **Framework**: Bun test with test database\n- **Location**: `tests/integration/`\n- **Scope**: API routes with real database, service combinations\n- **Database**: Fresh SQLite per test suite (in-memory or temp file)\n- **Speed**: \u003c 5s per test file\n\n### E2E Tests (Critical paths)\n- **Framework**: Playwright\n- **Location**: `tests/e2e/`\n- **Scope**: Full user journeys through UI\n- **Browser**: Chromium, Firefox, Safari (CI matrix)\n- **Artifacts**: Screenshots/videos on failure\n\n### Contract Tests (100% API coverage)\n- **Framework**: Bun test + OpenAPI validator\n- **Location**: `tests/contract/`\n- **Scope**: REST responses match OpenAPI spec\n- **Validation**: Response schema, status codes, headers\n\n### Load Tests (Key endpoints)\n- **Framework**: k6\n- **Location**: `tests/load/`\n- **Scope**: WebSocket connections, API throughput, database operations\n- **Thresholds**: P95 \u003c 100ms for reads, P95 \u003c 200ms for writes\n\n## Test Utilities Package\n\n```typescript\n// packages/test-utils/src/index.ts\n\n// Database utilities\nexport { createTestDatabase, seedTestData, cleanupTestData } from './db';\n\n// API testing\nexport { createTestClient, mockAuthContext, assertApiResponse } from './api';\n\n// WebSocket testing\nexport { createTestWsClient, waitForWsEvent, mockWsHub } from './ws';\n\n// Agent testing\nexport { mockAgentDriver, createTestAgent, simulateAgentOutput } from './agent';\n\n// Time utilities\nexport { freezeTime, advanceTime, mockDateNow } from './time';\n\n// Assertion helpers\nexport { expectApiError, expectEvent, expectDatabaseState } from './assertions';\n\n// Logging capture\nexport { captureTestLogs, assertLogContains, getTestLogSummary } from './logging';\n```\n\n## Test Logging Standards\n\nAll tests must produce **detailed, structured logs** for debugging failures:\n\n```typescript\n// Pattern for test setup logging\ntest.beforeEach(({ testInfo }) =\u003e {\n  testLogger.info('Test starting', {\n    testName: testInfo.title,\n    file: testInfo.file,\n    timestamp: new Date().toISOString(),\n  });\n});\n\n// Pattern for assertion context\nexpect.extend({\n  toHaveAgentStatus(agent, status) {\n    const pass = agent.status === status;\n    testLogger.debug('Assertion: toHaveAgentStatus', {\n      agentId: agent.id,\n      expected: status,\n      actual: agent.status,\n      pass,\n    });\n    return { pass, message: () =\u003e `Expected ${agent.id} to have status ${status}, got ${agent.status}` };\n  },\n});\n\n// Pattern for async operation logging\nasync function waitForCondition(check: () =\u003e boolean, timeout: number) {\n  const start = Date.now();\n  while (!check() \u0026\u0026 Date.now() - start \u003c timeout) {\n    testLogger.trace('Waiting for condition', { elapsed: Date.now() - start });\n    await sleep(50);\n  }\n  testLogger.debug('Wait completed', { \n    elapsed: Date.now() - start, \n    success: check(),\n  });\n}\n```\n\n## File Locations\n\n| Location | Purpose |\n|----------|---------|\n| `packages/test-utils/` | Shared test utilities |\n| `apps/gateway/src/**/*.test.ts` | Unit tests (co-located) |\n| `apps/gateway/tests/integration/` | Integration tests |\n| `apps/web/src/**/*.test.tsx` | Component unit tests |\n| `tests/e2e/` | Playwright E2E tests |\n| `tests/contract/` | OpenAPI contract tests |\n| `tests/load/` | k6 load tests |\n| `tests/fixtures/` | Shared test data |\n\n## CI Pipeline Integration\n\n```yaml\n# .github/workflows/test.yml\nname: Test Suite\n\non: [push, pull_request]\n\njobs:\n  unit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: oven-sh/setup-bun@v2\n      - run: bun install\n      - run: bun test --coverage\n      - run: bun run test:coverage-check  # Fail if below threshold\n\n  integration:\n    runs-on: ubuntu-latest\n    services:\n      postgres:  # For certain integration tests\n        image: postgres:16\n        env:\n          POSTGRES_PASSWORD: test\n    steps:\n      - uses: oven-sh/setup-bun@v2\n      - run: bun install\n      - run: bun test:integration\n\n  e2e:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: oven-sh/setup-bun@v2\n      - run: bun install\n      - run: bunx playwright install --with-deps\n      - run: bun run build\n      - run: bun test:e2e\n      - uses: actions/upload-artifact@v4\n        if: failure()\n        with:\n          name: playwright-traces\n          path: tests/e2e/test-results/\n\n  contract:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: oven-sh/setup-bun@v2\n      - run: bun install\n      - run: bun test:contract\n\n  load:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n    steps:\n      - uses: grafana/k6-action@v0.3.1\n        with:\n          filename: tests/load/api.k6.js\n```\n\n## Testing Requirements for Each Bead\n\nEvery feature bead MUST include:\n\n1. **Unit Test Cases** (specific scenarios to test)\n2. **Integration Test Cases** (API/service combinations)\n3. **E2E Test Cases** (user journeys, if UI involved)\n4. **Performance Test Cases** (if latency-sensitive)\n5. **Failure Mode Tests** (what happens when dependencies fail)\n\nExample testing section format for feature beads:\n\n```markdown\n## Testing Requirements\n\n### Unit Tests\n- [ ] Test A: Description of what's being tested\n- [ ] Test B: Description\n- [ ] Test C: Edge case for X\n\n### Integration Tests\n- [ ] Test D: API endpoint with real database\n- [ ] Test E: Service combination scenario\n\n### E2E Tests (if applicable)\n- [ ] Test F: User journey description\n\n### Failure Mode Tests\n- [ ] Test G: Behavior when dependency X is unavailable\n- [ ] Test H: Behavior on timeout\n\n### Performance Tests\n- [ ] P95 latency \u003c Xms for operation Y\n```\n\n## Acceptance Criteria\n\n### Test Infrastructure\n- [ ] packages/test-utils package created with all utilities\n- [ ] Database utilities support SQLite and PostgreSQL\n- [ ] WebSocket test client supports reconnection testing\n- [ ] Agent mock driver is feature-complete\n- [ ] Time utilities allow deterministic time-based tests\n\n### Test Runner Configuration\n- [ ] Bun test configured with coverage thresholds\n- [ ] Playwright configured with all browsers\n- [ ] k6 configured with CI-appropriate thresholds\n- [ ] Test reports generated in CI\n\n### CI/CD Integration\n- [ ] Unit tests run on every push\n- [ ] Integration tests run on every push\n- [ ] E2E tests run on PR\n- [ ] Load tests run on PR with baselines\n- [ ] Coverage reports posted to PR\n\n### Logging Standards\n- [ ] Test logger configured and documented\n- [ ] Failure logs include full context\n- [ ] Test artifacts preserved on failure\n- [ ] Log verbosity configurable via environment\n\n## Reference\n- PLAN.md §25 (Testing Strategy)\n- AGENTS.md (Testing conventions)\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-08T17:23:36.972977234-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:23:36.972977234-05:00","dependencies":[{"issue_id":"flywheel_gateway-d8b","depends_on_id":"flywheel_gateway-hnv","type":"blocks","created_at":"2026-01-08T18:04:16.375945037-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-dje","title":"FEAT: Developer Utilities Auto-Install (giil, csctf)","description":"## Background\n\nFlywheel Gateway integrates with two specialized developer utilities that enhance AI-assisted workflows:\n\n1. **giil** (Google Image Import Library): Downloads photos from Google Photos for AI visual analysis\n2. **csctf** (Claude Session Chat to File): Archives AI chat conversations for documentation and training\n\nThese utilities are optional but provide significant value when available. The gateway should detect their presence, offer auto-installation, and provide health monitoring.\n\n### Why Auto-Install?\n\n- Reduces friction for new developers\n- Ensures consistent versions across team\n- Simplifies CI/CD pipeline setup\n- Enables features that depend on these utilities\n\n## Technical Architecture\n\n### Installation Detection\n\n```typescript\n// apps/gateway/src/utilities/detection.service.ts\ninterface UtilityStatus {\n  name: string;\n  installed: boolean;\n  version?: string;\n  path?: string;\n  lastChecked: Date;\n  healthy: boolean;\n  healthDetails?: string;\n}\n\nclass DetectionService {\n  async detectGiil(): Promise\u003cUtilityStatus\u003e;\n  async detectCsctf(): Promise\u003cUtilityStatus\u003e;\n  async detectAll(): Promise\u003cUtilityStatus[]\u003e;\n  \n  // Detection methods:\n  // 1. Check PATH for executable\n  // 2. Check common install locations\n  // 3. Check package managers (npm global, cargo, pip)\n  // 4. Verify version compatibility\n}\n```\n\n### Auto-Install Scripts\n\n```typescript\n// apps/gateway/src/utilities/installer.service.ts\ninterface InstallOptions {\n  method: 'npm' | 'cargo' | 'pip' | 'binary';\n  version?: string;\n  global: boolean;\n  sudo: boolean;\n}\n\ninterface InstallResult {\n  success: boolean;\n  method: string;\n  version: string;\n  path: string;\n  error?: string;\n  logs: string[];\n}\n\nclass InstallerService {\n  async installGiil(options?: InstallOptions): Promise\u003cInstallResult\u003e;\n  async installCsctf(options?: InstallOptions): Promise\u003cInstallResult\u003e;\n  \n  // Installation priority:\n  // 1. npm (if Node.js available)\n  // 2. Direct binary download\n  // 3. Build from source (cargo/pip)\n}\n```\n\n### Health Check Endpoint\n\n```typescript\n// apps/gateway/src/utilities/utilities.controller.ts\n@Controller('utilities')\nclass UtilitiesController {\n  @Get('health')\n  async healthCheck(): Promise\u003cUtilitiesHealth\u003e {\n    return {\n      giil: await this.detectionService.detectGiil(),\n      csctf: await this.detectionService.detectCsctf(),\n      timestamp: new Date()\n    };\n  }\n  \n  @Post('install/:utility')\n  async install(\n    @Param('utility') utility: 'giil' | 'csctf',\n    @Body() options: InstallOptions\n  ): Promise\u003cInstallResult\u003e;\n  \n  @Get(':utility/version')\n  async getVersion(@Param('utility') utility: string): Promise\u003cstring\u003e;\n}\n```\n\n## giil: Google Image Import Library\n\n### Purpose\nDownloads photos from Google Photos for AI visual analysis. Enables Claude and other AI models to analyze personal photos, screenshots, and visual content stored in Google Photos.\n\n### Features\n- OAuth2 authentication with Google Photos API\n- Album and date-range filtering\n- Batch download with progress tracking\n- Image optimization for AI analysis (resize, format conversion)\n- Metadata extraction and indexing\n- Local caching to avoid re-downloads\n\n### Integration Points\n\n```typescript\n// apps/gateway/src/utilities/giil/giil.service.ts\ninterface GiilConfig {\n  credentialsPath: string;\n  downloadPath: string;\n  maxConcurrent: number;\n  imageMaxSize: number;\n  supportedFormats: string[];\n}\n\ninterface PhotoDownloadRequest {\n  albumId?: string;\n  dateRange?: { start: Date; end: Date };\n  limit?: number;\n  includeMetadata: boolean;\n}\n\nclass GiilService {\n  async authenticate(): Promise\u003cboolean\u003e;\n  async listAlbums(): Promise\u003cAlbum[]\u003e;\n  async downloadPhotos(request: PhotoDownloadRequest): Promise\u003cDownloadResult\u003e;\n  async getPhotoForAnalysis(photoId: string): Promise\u003cBuffer\u003e;\n}\n```\n\n### Use Cases\n1. \"Analyze my vacation photos from last month\"\n2. \"Find all screenshots containing error messages\"\n3. \"Describe the architecture diagram I photographed\"\n4. \"Extract text from whiteboard photos\"\n\n## csctf: Claude Session Chat to File\n\n### Purpose\nArchives AI chat conversations from Claude, ChatGPT, and other AI assistants. Creates searchable documentation of AI interactions for:\n- Knowledge management\n- Training data collection\n- Compliance and audit trails\n- Team knowledge sharing\n\n### Features\n- Browser extension integration\n- API-based capture for programmatic chats\n- Markdown and JSON export formats\n- Full-text search indexing\n- Conversation tagging and categorization\n- Privacy controls (redaction, anonymization)\n\n### Integration Points\n\n```typescript\n// apps/gateway/src/utilities/csctf/csctf.service.ts\ninterface CsctfConfig {\n  archivePath: string;\n  exportFormat: 'markdown' | 'json' | 'both';\n  autoCapture: boolean;\n  redactionPatterns: string[];\n}\n\ninterface Conversation {\n  id: string;\n  source: 'claude' | 'chatgpt' | 'other';\n  startTime: Date;\n  endTime: Date;\n  messages: Message[];\n  metadata: ConversationMetadata;\n  tags: string[];\n}\n\nclass CsctfService {\n  async captureConversation(conversation: Conversation): Promise\u003cstring\u003e;\n  async searchConversations(query: string): Promise\u003cConversation[]\u003e;\n  async exportConversation(id: string, format: string): Promise\u003cBuffer\u003e;\n  async getStatistics(): Promise\u003cArchiveStatistics\u003e;\n}\n```\n\n### Use Cases\n1. \"Archive this debugging session for the team wiki\"\n2. \"Find all conversations about database optimization\"\n3. \"Export last week's code reviews for documentation\"\n4. \"Search for that solution we discussed last month\"\n\n## File Structure\n\n```\napps/gateway/src/utilities/\n├── index.ts                      # Module exports\n├── utilities.module.ts           # NestJS module\n├── utilities.controller.ts       # REST endpoints\n├── detection.service.ts          # Utility detection\n├── installer.service.ts          # Auto-installation\n├── giil/\n│   ├── giil.service.ts          # Main giil integration\n│   ├── giil.config.ts           # Configuration\n│   ├── google-photos.client.ts  # API client\n│   └── image-processor.ts       # Image optimization\n├── csctf/\n│   ├── csctf.service.ts         # Main csctf integration\n│   ├── csctf.config.ts          # Configuration\n│   ├── conversation.parser.ts   # Parse chat formats\n│   ├── archive.repository.ts    # Storage layer\n│   └── search.service.ts        # Full-text search\n├── types/\n│   ├── utility-status.ts\n│   ├── install-result.ts\n│   └── health-response.ts\n└── __tests__/\n    ├── detection.service.spec.ts\n    ├── installer.service.spec.ts\n    ├── giil.service.spec.ts\n    └── csctf.service.spec.ts\n```\n\n## Configuration\n\n```yaml\n# config/utilities.yaml\nutilities:\n  giil:\n    enabled: true\n    autoInstall: true\n    version: \"^2.0.0\"\n    config:\n      downloadPath: \"./data/photos\"\n      maxConcurrent: 5\n      imageMaxSize: 4096\n  \n  csctf:\n    enabled: true\n    autoInstall: true\n    version: \"^1.5.0\"\n    config:\n      archivePath: \"./data/conversations\"\n      exportFormat: \"both\"\n      autoCapture: false\n```\n\n## API Endpoints\n\n| Method | Path | Description |\n|--------|------|-------------|\n| GET | /utilities/health | Health status of all utilities |\n| POST | /utilities/install/giil | Install giil |\n| POST | /utilities/install/csctf | Install csctf |\n| GET | /utilities/giil/albums | List Google Photos albums |\n| POST | /utilities/giil/download | Download photos |\n| GET | /utilities/csctf/conversations | List archived conversations |\n| POST | /utilities/csctf/capture | Capture new conversation |\n| GET | /utilities/csctf/search | Search conversations |\n\n## Acceptance Criteria\n\n- [ ] Detection correctly identifies installed utilities\n- [ ] Version detection works for npm, cargo, pip installations\n- [ ] Auto-install works on Linux, macOS, Windows\n- [ ] Health endpoint returns accurate status within 5 seconds\n- [ ] giil OAuth flow completes successfully\n- [ ] giil downloads photos with progress tracking\n- [ ] csctf captures conversations in markdown format\n- [ ] csctf full-text search returns relevant results\n- [ ] Error handling for network failures, auth errors\n- [ ] Graceful degradation when utilities unavailable\n- [ ] Installation logs captured for debugging\n- [ ] 85%+ test coverage\n\n## Security Considerations\n\n- OAuth tokens stored securely (encrypted at rest)\n- No credentials logged or exposed in errors\n- Redaction patterns for sensitive data in csctf\n- Rate limiting on installation endpoints\n- Validation of download paths (no path traversal)\n\n## Dependencies\n\n- Node.js runtime (for npm installations)\n- Network access for downloads\n- Google OAuth credentials (for giil)\n- SQLite/PostgreSQL (for csctf archive)\n\n## References\n\n- PLAN.md Section 17.7: Developer Utilities\n- giil repository: github.com/anthropics/giil\n- csctf repository: github.com/anthropics/csctf\n- Google Photos API documentation\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Utility detection for multiple install methods (path lookup + version parsing)\n- [ ] Installer validates target paths and refuses unsafe destinations (no traversal)\n- [ ] Capability reporting is stable and schema-valid\n\n### Integration Tests\n- [ ] When utilities are missing: endpoints report unavailable and UI shows actionable install guidance\n- [ ] When utilities are present (mocked): run a no-op command and capture structured results\n\n### Failure Mode Tests\n- [ ] Network/install failures surface clear error codes and preserve logs for debugging\n\n### Logging\n- [ ] Logs include correlationId + utility + version + installAttemptId; never log OAuth tokens\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:32:15.061618044-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:28:38.236233564-05:00","dependencies":[{"issue_id":"flywheel_gateway-dje","depends_on_id":"flywheel_gateway-w4g","type":"blocks","created_at":"2026-01-08T14:01:58.611985027-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-e73","title":"Tmux Agent Driver","description":"## Overview\n\nThe Tmux Agent Driver provides a fallback mechanism for terminal-based agent execution when native drivers are unavailable or unsuitable. It leverages tmux for PTY management and session isolation.\n\n## Background \u0026 Reasoning\n\nWhile native agent drivers (Claude Code SDK, API-based) offer superior integration, some scenarios require terminal-based execution:\n\n- Legacy agent tools without API support\n- Debugging and development workflows\n- Environments where native drivers fail\n- Manual intervention capabilities\n\nTmux provides robust session management with:\n- Detached execution (survives driver disconnect)\n- Full PTY support (handles interactive prompts)\n- Session capture (complete output history)\n- Scriptable control interface\n\n## Technical Architecture\n\n### AgentDriver Interface Compliance\n\nThe Tmux driver implements the standard AgentDriver interface:\n\n```typescript\ninterface AgentDriver {\n  id: string;\n  name: string;\n  type: 'native' | 'api' | 'terminal';\n  \n  initialize(config: DriverConfig): Promise\u003cvoid\u003e;\n  start(agent: Agent, task: Task): Promise\u003cAgentSession\u003e;\n  stop(sessionId: string): Promise\u003cvoid\u003e;\n  sendInput(sessionId: string, input: string): Promise\u003cvoid\u003e;\n  getOutput(sessionId: string): Promise\u003cOutputChunk[]\u003e;\n  getStatus(sessionId: string): Promise\u003cSessionStatus\u003e;\n  cleanup(): Promise\u003cvoid\u003e;\n}\n```\n\n### TmuxAgentDriver Implementation\n\n```typescript\nclass TmuxAgentDriver implements AgentDriver {\n  readonly id = 'tmux-driver';\n  readonly name = 'Tmux Terminal Driver';\n  readonly type = 'terminal';\n  \n  private sessions: Map\u003cstring, TmuxSession\u003e = new Map();\n  private tmuxSocketPath: string;\n  \n  async initialize(config: TmuxDriverConfig): Promise\u003cvoid\u003e {\n    // Verify tmux installation\n    // Create dedicated socket for isolation\n    // Set up output capture directory\n  }\n  \n  async start(agent: Agent, task: Task): Promise\u003cAgentSession\u003e {\n    // Create new tmux session with unique name\n    // Configure PTY dimensions\n    // Start agent command\n    // Begin output capture\n    // Return session handle\n  }\n  \n  async stop(sessionId: string): Promise\u003cvoid\u003e {\n    // Send SIGTERM to session\n    // Wait for graceful shutdown\n    // Force kill if timeout\n    // Clean up session resources\n  }\n  \n  async sendInput(sessionId: string, input: string): Promise\u003cvoid\u003e {\n    // Send keys to tmux session\n    // Handle special characters\n    // Support escape sequences\n  }\n  \n  async getOutput(sessionId: string): Promise\u003cOutputChunk[]\u003e {\n    // Capture pane contents\n    // Parse into structured chunks\n    // Track output position\n    // Handle ANSI codes\n  }\n  \n  async getStatus(sessionId: string): Promise\u003cSessionStatus\u003e {\n    // Check if session exists\n    // Get running process info\n    // Calculate resource usage\n    // Return structured status\n  }\n  \n  async cleanup(): Promise\u003cvoid\u003e {\n    // Kill all managed sessions\n    // Remove socket file\n    // Clean up capture directory\n  }\n}\n```\n\n### PTY Management\n\n```typescript\ninterface TmuxSession {\n  sessionName: string;\n  windowId: string;\n  paneId: string;\n  createdAt: Date;\n  lastActivity: Date;\n  outputFile: string;\n  outputPosition: number;\n  pid?: number;\n}\n\ninterface TmuxManager {\n  // Session lifecycle\n  createSession(name: string, command: string): Promise\u003cTmuxSession\u003e;\n  destroySession(name: string): Promise\u003cvoid\u003e;\n  listSessions(): Promise\u003cTmuxSession[]\u003e;\n  \n  // Input/Output\n  sendKeys(session: string, keys: string): Promise\u003cvoid\u003e;\n  capturePane(session: string, options: CaptureOptions): Promise\u003cstring\u003e;\n  \n  // Session management\n  hasSession(name: string): Promise\u003cboolean\u003e;\n  getSessionPid(name: string): Promise\u003cnumber | null\u003e;\n  resizePane(session: string, width: number, height: number): Promise\u003cvoid\u003e;\n}\n```\n\n### Output Capture Strategy\n\nTwo complementary capture mechanisms:\n\n1. **Pipe Capture** (for real-time streaming)\n   ```bash\n   tmux pipe-pane -t $SESSION -o \"cat \u003e\u003e /path/to/output.log\"\n   ```\n\n2. **Pane Capture** (for complete history)\n   ```bash\n   tmux capture-pane -t $SESSION -p -S - -E -\n   ```\n\n```typescript\ninterface OutputCapture {\n  // Real-time streaming via pipe\n  startCapture(sessionId: string): Promise\u003cvoid\u003e;\n  stopCapture(sessionId: string): Promise\u003cvoid\u003e;\n  \n  // On-demand full capture\n  captureAll(sessionId: string): Promise\u003cstring\u003e;\n  \n  // Incremental capture since last read\n  captureNew(sessionId: string): Promise\u003cOutputChunk[]\u003e;\n  \n  // ANSI processing\n  parseAnsi(raw: string): ParsedOutput;\n  stripAnsi(raw: string): string;\n}\n\ninterface OutputChunk {\n  timestamp: Date;\n  content: string;\n  type: 'stdout' | 'stderr' | 'prompt';\n  ansiCodes?: AnsiCode[];\n}\n```\n\n### Error Handling\n\n```typescript\nclass TmuxDriverError extends Error {\n  constructor(\n    message: string,\n    public code: TmuxErrorCode,\n    public sessionId?: string,\n    public cause?: Error\n  ) {\n    super(message);\n  }\n}\n\nenum TmuxErrorCode {\n  TMUX_NOT_FOUND = 'TMUX_NOT_FOUND',\n  SESSION_EXISTS = 'SESSION_EXISTS',\n  SESSION_NOT_FOUND = 'SESSION_NOT_FOUND',\n  COMMAND_FAILED = 'COMMAND_FAILED',\n  CAPTURE_FAILED = 'CAPTURE_FAILED',\n  SEND_KEYS_FAILED = 'SEND_KEYS_FAILED',\n  SOCKET_ERROR = 'SOCKET_ERROR',\n}\n```\n\n## File Locations\n\n- `packages/agent-drivers/src/tmux/TmuxAgentDriver.ts` - Main driver implementation\n- `packages/agent-drivers/src/tmux/TmuxManager.ts` - Low-level tmux operations\n- `packages/agent-drivers/src/tmux/OutputCapture.ts` - Output capture logic\n- `packages/agent-drivers/src/tmux/AnsiParser.ts` - ANSI code processing\n- `packages/agent-drivers/src/tmux/types.ts` - TypeScript interfaces\n- `packages/agent-drivers/src/tmux/errors.ts` - Error definitions\n- `packages/agent-drivers/src/tmux/__tests__/` - Test files\n- `packages/agent-drivers/src/index.ts` - Export driver\n\n## Configuration\n\n```typescript\ninterface TmuxDriverConfig {\n  // Tmux executable path (default: 'tmux')\n  tmuxPath?: string;\n  \n  // Socket path for session isolation\n  socketPath?: string;\n  \n  // Directory for output capture files\n  captureDir?: string;\n  \n  // Default PTY dimensions\n  defaultWidth?: number;   // default: 120\n  defaultHeight?: number;  // default: 40\n  \n  // Session naming prefix\n  sessionPrefix?: string;  // default: 'flywheel-'\n  \n  // Cleanup stale sessions on startup\n  cleanupOnStart?: boolean;\n  \n  // Maximum concurrent sessions\n  maxSessions?: number;\n  \n  // Output capture settings\n  captureMode?: 'pipe' | 'pane' | 'both';\n  captureInterval?: number;  // ms between captures\n}\n```\n\n## Acceptance Criteria\n\n- [ ] Driver implements complete AgentDriver interface\n- [ ] Sessions create successfully with unique names\n- [ ] Input sent to sessions via sendKeys\n- [ ] Output captured in real-time with \u003c100ms latency\n- [ ] Sessions survive driver restart (detached mode)\n- [ ] ANSI escape codes properly parsed and handled\n- [ ] Graceful shutdown sends SIGTERM before SIGKILL\n- [ ] Resource cleanup removes all session artifacts\n- [ ] Error messages provide actionable information\n- [ ] Driver degrades gracefully when tmux unavailable\n\n## Testing Requirements\n\n- Unit tests for tmux command generation\n- Integration tests with actual tmux sessions\n- E2E tests for complete agent workflow\n- Stress tests for concurrent session management\n- Compatibility tests across tmux versions (2.x, 3.x)\n- Cleanup tests for orphan session handling\n\n## Dependencies\n\n- tmux \u003e= 2.6 (recommended 3.x)\n- Node.js child_process for command execution\n- fs/promises for file operations\n- Optional: node-pty for enhanced PTY handling\n\n## Security Considerations\n\n- Session names sanitized to prevent injection\n- Socket permissions restrict access\n- Output files created with secure permissions\n- Environment variables filtered before pass-through\n- Command execution uses shell: false where possible\n\n## Performance Notes\n\n- Session creation: ~50ms\n- Send keys latency: \u003c10ms\n- Output capture: ~20ms per capture\n- Memory per session: ~1MB baseline\n- Disk per session: varies by output volume\n\n## References\n\n- PLAN.md §5 - Agent Driver Architecture\n- PLAN.md §6 - Terminal Execution Patterns\n- tmux man page and documentation\n- PTY best practices for terminal emulation","notes":"## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] TmuxManager command generation produces correct tmux syntax for all operations\n- [ ] Session name sanitization prevents shell injection\n- [ ] ANSI parser correctly extracts codes and strips for plain text\n- [ ] Output chunk parsing preserves ordering and handles partial lines\n\n### Integration Tests\n- [ ] Session lifecycle: create → send input → capture output → terminate\n- [ ] Session survives driver restart (detached mode verification)\n- [ ] Concurrent sessions (up to maxSessions) operate independently\n- [ ] PTY resize propagates correctly to running session\n\n### E2E Tests\n- [ ] Complete agent workflow: start task → stream output → complete\n- [ ] Agent interrupt handling via SIGINT/SIGTERM\n\n### Failure Mode Tests\n- [ ] Tmux not installed → clear error with install hint\n- [ ] Session already exists → appropriate error code\n- [ ] Orphan session cleanup on startup works correctly\n- [ ] Socket permission errors → actionable error message\n\n### Performance Tests\n- [ ] Session creation \u003c 100ms\n- [ ] Output capture latency \u003c 100ms\n- [ ] Memory per session \u003c 2MB baseline\n\n### Compatibility Tests\n- [ ] Works with tmux 2.6, 3.0, 3.3 (major versions)\n\n### Logging\n- [ ] Logs include correlationId + sessionId + tmuxCommand + exitCode; never log raw output content","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T13:49:45.836617442-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:38:15.840056653-05:00","dependencies":[{"issue_id":"flywheel_gateway-e73","depends_on_id":"flywheel_gateway-w55","type":"blocks","created_at":"2026-01-08T14:02:05.926207108-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-ew1","title":"Auto-Healing Context Window Management","description":"## Background\n\nAuto-Healing Context Window Management is a proactive system that monitors context window health and takes corrective action before problems occur. Rather than waiting for context overflow errors, this system maintains optimal context health through graduated interventions.\n\n### Why This Matters\n\n1. **Proactive vs Reactive**: Waiting for context overflow means lost work and degraded agent performance. Proactive management prevents these issues entirely.\n\n2. **Seamless Experience**: Users and agents should never experience sudden context loss. Graduated interventions maintain continuity.\n\n3. **Cost Optimization**: Compaction and summarization reduce token usage while preserving essential information.\n\n4. **Agent Continuity**: When rotation is necessary, automatic context transfer ensures the new agent starts with full awareness.\n\n## Technical Design\n\n### Health Thresholds\n\n```typescript\ninterface ContextHealthThresholds {\n  // Warning level - start preparing\n  warning: {\n    percentage: 75;              // 75% of context used\n    actions: ['log', 'event', 'prepare_summary'];\n  };\n  \n  // Critical level - active intervention\n  critical: {\n    percentage: 85;              // 85% of context used\n    actions: ['summarize', 'compact', 'event'];\n  };\n  \n  // Emergency level - rotation required\n  emergency: {\n    percentage: 95;              // 95% of context used\n    actions: ['checkpoint', 'rotate', 'transfer', 'event'];\n  };\n}\n\nenum ContextHealthStatus {\n  HEALTHY = 'healthy',           // \u003c 75%\n  WARNING = 'warning',           // 75-84%\n  CRITICAL = 'critical',         // 85-94%\n  EMERGENCY = 'emergency'        // \u003e= 95%\n}\n```\n\n### Health Monitor\n\n```typescript\ninterface ContextHealth {\n  sessionId: string;\n  status: ContextHealthStatus;\n  currentTokens: number;\n  maxTokens: number;\n  percentUsed: number;\n  \n  // Projections\n  projectedOverflowInMessages: number | null;\n  estimatedTimeToWarning: number | null;  // milliseconds\n  \n  // History\n  tokenHistory: TokenHistoryEntry[];\n  lastCompaction: Date | null;\n  lastRotation: Date | null;\n  \n  // Recommendations\n  recommendations: HealthRecommendation[];\n}\n\ninterface TokenHistoryEntry {\n  timestamp: Date;\n  tokens: number;\n  delta: number;\n  event: string;  // 'message', 'compaction', 'rotation', etc.\n}\n\ninterface HealthRecommendation {\n  action: 'summarize' | 'compact' | 'rotate' | 'none';\n  urgency: 'low' | 'medium' | 'high' | 'critical';\n  reason: string;\n  estimatedTokenSavings: number;\n}\n\nclass ContextHealthMonitor {\n  private healthCache = new Map\u003cstring, ContextHealth\u003e();\n  private checkInterval = 10000; // 10 seconds\n  \n  async checkHealth(sessionId: string): Promise\u003cContextHealth\u003e {\n    const session = await this.sessionService.get(sessionId);\n    const currentTokens = await this.tokenizer.countSession(session);\n    const maxTokens = this.getModelLimit(session.model);\n    const percentUsed = (currentTokens / maxTokens) * 100;\n    \n    const status = this.determineStatus(percentUsed);\n    const history = await this.getTokenHistory(sessionId);\n    \n    const health: ContextHealth = {\n      sessionId,\n      status,\n      currentTokens,\n      maxTokens,\n      percentUsed,\n      projectedOverflowInMessages: this.projectOverflow(history, maxTokens),\n      estimatedTimeToWarning: this.estimateTimeToThreshold(history, 75, maxTokens),\n      tokenHistory: history,\n      lastCompaction: await this.getLastCompaction(sessionId),\n      lastRotation: await this.getLastRotation(sessionId),\n      recommendations: this.generateRecommendations(status, percentUsed, history)\n    };\n    \n    this.healthCache.set(sessionId, health);\n    \n    // Trigger actions based on status\n    await this.handleStatus(health);\n    \n    return health;\n  }\n  \n  private determineStatus(percentUsed: number): ContextHealthStatus {\n    if (percentUsed \u003e= 95) return ContextHealthStatus.EMERGENCY;\n    if (percentUsed \u003e= 85) return ContextHealthStatus.CRITICAL;\n    if (percentUsed \u003e= 75) return ContextHealthStatus.WARNING;\n    return ContextHealthStatus.HEALTHY;\n  }\n  \n  private async handleStatus(health: ContextHealth): Promise\u003cvoid\u003e {\n    switch (health.status) {\n      case ContextHealthStatus.WARNING:\n        await this.handleWarning(health);\n        break;\n      case ContextHealthStatus.CRITICAL:\n        await this.handleCritical(health);\n        break;\n      case ContextHealthStatus.EMERGENCY:\n        await this.handleEmergency(health);\n        break;\n    }\n  }\n}\n```\n\n### Proactive Summarization\n\n```typescript\ninterface SummarizationConfig {\n  // Target reduction\n  targetReduction: number;       // Target token reduction (e.g., 0.3 = 30%)\n  \n  // What to summarize\n  summarizable: {\n    conversationHistory: boolean;\n    searchResults: boolean;\n    beadContent: boolean;\n  };\n  \n  // Preservation rules\n  preserve: {\n    lastNMessages: number;       // Always keep last N messages verbatim\n    recentMinutes: number;       // Keep messages from last N minutes\n    keyDecisions: boolean;       // Preserve decision points\n    errorContext: boolean;       // Preserve error-related context\n  };\n}\n\nclass ProactiveSummarizer {\n  async summarize(\n    sessionId: string,\n    config: SummarizationConfig\n  ): Promise\u003cSummarizationResult\u003e {\n    const session = await this.sessionService.get(sessionId);\n    const beforeTokens = await this.tokenizer.countSession(session);\n    \n    // Identify summarizable content\n    const summarizable = this.identifySummarizable(session, config);\n    \n    // Generate summaries\n    const summaries = await Promise.all(\n      summarizable.map(content =\u003e this.generateSummary(content))\n    );\n    \n    // Replace content with summaries\n    const updatedSession = this.applySummaries(session, summaries, config.preserve);\n    \n    const afterTokens = await this.tokenizer.countSession(updatedSession);\n    \n    return {\n      beforeTokens,\n      afterTokens,\n      reduction: beforeTokens - afterTokens,\n      reductionPercent: ((beforeTokens - afterTokens) / beforeTokens) * 100,\n      summarizedSections: summaries.map(s =\u003e s.section),\n      preservedSections: this.getPreservedSections(config.preserve)\n    };\n  }\n  \n  private async generateSummary(content: SummarizableContent): Promise\u003cSummary\u003e {\n    // Use LLM to generate concise summary\n    const prompt = this.buildSummaryPrompt(content);\n    const summary = await this.llm.complete(prompt);\n    \n    return {\n      section: content.section,\n      originalTokens: content.tokens,\n      summaryTokens: await this.tokenizer.count(summary),\n      summary,\n      keyPoints: this.extractKeyPoints(summary)\n    };\n  }\n}\n```\n\n### Agent Rotation with Context Transfer\n\n```typescript\ninterface RotationConfig {\n  // When to rotate\n  triggers: {\n    contextPercentage: number;   // Rotate at this % (default: 95)\n    messageCount: number;        // Rotate after N messages\n    timeMinutes: number;         // Rotate after N minutes\n  };\n  \n  // How to transfer\n  transfer: {\n    includeFullSummary: boolean;\n    includeRecentMessages: number;\n    includeActiveBeads: boolean;\n    includeMemoryRules: boolean;\n  };\n  \n  // New agent setup\n  newAgent: {\n    model: string;\n    warmupPrompt: string;\n  };\n}\n\ninterface ContextTransfer {\n  sourceSessionId: string;\n  targetSessionId: string;\n  checkpointId: string;\n  \n  // Transferred content\n  summary: string;\n  recentMessages: Message[];\n  activeBeads: string[];\n  memoryRules: string[];\n  \n  // Metadata\n  sourceTokens: number;\n  transferTokens: number;\n  compressionRatio: number;\n}\n\nclass AgentRotationManager {\n  async rotate(\n    sessionId: string,\n    config: RotationConfig\n  ): Promise\u003cRotationResult\u003e {\n    // 1. Create checkpoint before rotation\n    const checkpoint = await this.checkpointService.create(sessionId, {\n      trigger: 'rotation',\n      metadata: { rotationConfig: config }\n    });\n    \n    // 2. Build context transfer\n    const transfer = await this.buildTransfer(sessionId, config.transfer);\n    \n    // 3. Create new session\n    const newSession = await this.sessionService.create({\n      model: config.newAgent.model,\n      parentSessionId: sessionId,\n      rotatedFrom: checkpoint.id\n    });\n    \n    // 4. Initialize new agent with transferred context\n    await this.initializeRotatedAgent(newSession.id, transfer, config.newAgent);\n    \n    // 5. Mark old session as rotated\n    await this.sessionService.update(sessionId, {\n      status: 'rotated',\n      rotatedTo: newSession.id\n    });\n    \n    // 6. Emit rotation event\n    await this.events.emit('context.emergency_rotated', {\n      sourceSessionId: sessionId,\n      targetSessionId: newSession.id,\n      checkpointId: checkpoint.id,\n      transfer: {\n        sourceTokens: transfer.sourceTokens,\n        transferTokens: transfer.transferTokens,\n        compressionRatio: transfer.compressionRatio\n      }\n    });\n    \n    return {\n      newSessionId: newSession.id,\n      checkpointId: checkpoint.id,\n      transfer\n    };\n  }\n  \n  private async buildTransfer(\n    sessionId: string,\n    config: RotationConfig['transfer']\n  ): Promise\u003cContextTransfer\u003e {\n    const session = await this.sessionService.get(sessionId);\n    \n    // Generate comprehensive summary\n    const summary = config.includeFullSummary\n      ? await this.summarizer.generateFullSummary(session)\n      : await this.summarizer.generateBriefSummary(session);\n    \n    // Get recent messages\n    const recentMessages = session.messages.slice(-config.includeRecentMessages);\n    \n    // Get active beads\n    const activeBeads = config.includeActiveBeads\n      ? await this.beadService.getActiveBeads(sessionId)\n      : [];\n    \n    // Get relevant memory rules\n    const memoryRules = config.includeMemoryRules\n      ? await this.memoryService.getSessionRules(sessionId)\n      : [];\n    \n    const sourceTokens = await this.tokenizer.countSession(session);\n    const transferTokens = await this.tokenizer.count(\n      this.formatTransfer(summary, recentMessages, activeBeads, memoryRules)\n    );\n    \n    return {\n      sourceSessionId: sessionId,\n      targetSessionId: '', // Will be set after new session creation\n      checkpointId: '', // Will be set after checkpoint creation\n      summary,\n      recentMessages,\n      activeBeads: activeBeads.map(b =\u003e b.id),\n      memoryRules: memoryRules.map(r =\u003e r.content),\n      sourceTokens,\n      transferTokens,\n      compressionRatio: sourceTokens / transferTokens\n    };\n  }\n}\n```\n\n### WebSocket Events\n\n```typescript\n// Context warning event\n{\n  event: 'context.warning',\n  data: {\n    sessionId: string,\n    percentUsed: number,\n    currentTokens: number,\n    maxTokens: number,\n    recommendations: HealthRecommendation[]\n  }\n}\n\n// Context compacted event\n{\n  event: 'context.compacted',\n  data: {\n    sessionId: string,\n    beforeTokens: number,\n    afterTokens: number,\n    reduction: number,\n    reductionPercent: number,\n    method: 'summarization' | 'pruning' | 'both'\n  }\n}\n\n// Emergency rotation event\n{\n  event: 'context.emergency_rotated',\n  data: {\n    sourceSessionId: string,\n    targetSessionId: string,\n    checkpointId: string,\n    reason: 'context_overflow' | 'manual' | 'scheduled',\n    transfer: {\n      sourceTokens: number,\n      transferTokens: number,\n      compressionRatio: number\n    }\n  }\n}\n```\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Get context health\nGET /api/v1/sessions/:sessionId/context/health\nResponse: ContextHealth\n\n// Trigger manual compaction\nPOST /api/v1/sessions/:sessionId/context/compact\nRequest: { strategy?: 'summarize' | 'prune' | 'both' }\nResponse: CompactionResult\n\n// Trigger manual rotation\nPOST /api/v1/sessions/:sessionId/context/rotate\nRequest: { config?: RotationConfig }\nResponse: RotationResult\n\n// Get context history\nGET /api/v1/sessions/:sessionId/context/history\nQuery: { since?: Date, limit?: number }\nResponse: { entries: TokenHistoryEntry[] }\n```\n\n## Configuration\n\n```typescript\ninterface ContextHealthConfig {\n  // Thresholds\n  thresholds: ContextHealthThresholds;\n  \n  // Monitoring\n  monitoring: {\n    checkIntervalMs: number;     // How often to check health\n    historyRetentionHours: number;\n  };\n  \n  // Auto-healing\n  autoHealing: {\n    enabled: boolean;\n    summarizationEnabled: boolean;\n    rotationEnabled: boolean;\n  };\n  \n  // Summarization\n  summarization: SummarizationConfig;\n  \n  // Rotation\n  rotation: RotationConfig;\n}\n```\n\n## File Locations\n\n- **Primary Service**: `apps/gateway/src/services/context-health.service.ts`\n- **Health Monitor**: `apps/gateway/src/services/context-health-monitor.service.ts`\n- **Summarizer**: `apps/gateway/src/services/context-summarizer.service.ts`\n- **Rotation Manager**: `apps/gateway/src/services/agent-rotation.service.ts`\n- **Types**: `apps/gateway/src/types/context-health.types.ts`\n- **Controller**: `apps/gateway/src/controllers/context-health.controller.ts`\n- **Tests**: `apps/gateway/src/services/__tests__/context-health.service.test.ts`\n\n## Dependencies\n\n- Context service (for current context state)\n- Checkpoint service (for pre-rotation checkpoints)\n- Session service (for session management)\n- Tokenizer service (for token counting)\n- LLM service (for summarization)\n- WebSocket gateway (for events)\n\n## Acceptance Criteria\n\n1. **Health Monitoring**\n   - [ ] Accurately calculates context utilization percentage\n   - [ ] Correctly determines health status based on thresholds\n   - [ ] Projects future overflow based on token history\n   - [ ] Generates actionable recommendations\n\n2. **Warning Level (75%)**\n   - [ ] Emits context.warning event\n   - [ ] Logs warning with recommendations\n   - [ ] Prepares summarization strategy\n\n3. **Critical Level (85%)**\n   - [ ] Automatically triggers summarization\n   - [ ] Achieves \u003e20% token reduction\n   - [ ] Preserves recent messages and key decisions\n   - [ ] Emits context.compacted event\n\n4. **Emergency Level (95%)**\n   - [ ] Creates checkpoint before rotation\n   - [ ] Builds comprehensive context transfer\n   - [ ] Creates new session with transferred context\n   - [ ] Emits context.emergency_rotated event\n   - [ ] New agent starts with full awareness\n\n5. **Context Transfer**\n   - [ ] Includes summary of full session history\n   - [ ] Includes recent messages verbatim\n   - [ ] Includes active bead references\n   - [ ] Includes relevant memory rules\n   - [ ] Achieves \u003e5:1 compression ratio\n\n6. **Observability**\n   - [ ] All events include relevant metrics\n   - [ ] Token history is queryable\n   - [ ] Health status is exposed via API\n   - [ ] Prometheus metrics for health status\n\n## Reference\n\n- PLAN.md Section 7.6 - Auto-Healing Context Window Management\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Threshold evaluation chooses the correct action (warn → compact → rotate) based on usage percent\n- [ ] Agent capability detection selects correct compaction commands per driver/agent type\n- [ ] Rotation decision logic avoids thrash (cooldowns) and preserves required context\n\n### Integration Tests\n- [ ] Simulated high-usage session triggers compaction workflow and emits expected events\n\n### Failure Mode Tests\n- [ ] Compaction attempt fails → fallback behavior is safe and surfaces actionable guidance\n\n### Logging\n- [ ] Logs include correlationId + agentId + usageBefore/After + method + reclaimedTokens\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] ContextMonitor: tracks token usage\n- [ ] ContextMonitor: calculates percentage\n- [ ] ThresholdChecker: warning at 75%\n- [ ] ThresholdChecker: critical at 85%\n- [ ] ThresholdChecker: emergency at 95%\n- [ ] Summarizer: compresses old messages\n- [ ] Summarizer: preserves key context\n- [ ] Summarizer: reduces token count\n- [ ] RotationTrigger: initiates handoff\n- [ ] RotationTrigger: packages context\n- [ ] GraduatedResponse: applies correct action\n- [ ] GraduatedResponse: escalates appropriately\n\n### Integration Tests\n- [ ] Context window tracked in real-time\n- [ ] Warning event at 75% threshold\n- [ ] Summarization triggered at 85%\n- [ ] Rotation triggered at 95%\n- [ ] New agent receives context pack\n- [ ] User notified of rotation\n- [ ] Seamless conversation continuity\n\n### E2E Tests\n- [ ] Long conversation triggers warning\n- [ ] Summarization visible in UI\n- [ ] Rotation happens transparently\n- [ ] New agent continues work\n\n### Performance Tests\n- [ ] Token counting \u003c10ms\n- [ ] Summarization \u003c2s\n- [ ] Rotation handoff \u003c5s\n- [ ] No message loss during transition\n\n### Failure Mode Tests\n- [ ] Summarization fails: skip and warn\n- [ ] Rotation target unavailable: retry\n- [ ] Context too large: emergency truncation\n- [ ] Threshold missed: catch at next check","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:43:02.155941785-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:08:37.103355117-05:00","dependencies":[{"issue_id":"flywheel_gateway-ew1","depends_on_id":"flywheel_gateway-45c","type":"blocks","created_at":"2026-01-08T14:01:51.82260636-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ew1","depends_on_id":"flywheel_gateway-36m","type":"blocks","created_at":"2026-01-08T14:01:52.523046043-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-f8f","title":"EPIC: Phase 3 - Flywheel Integration","description":"## Overview\nPhase 3 integrates with the full Flywheel ecosystem including Beads/BV, CASS, CM, UBS, and enables intelligent conflict resolution with AI assistance.\n\n## Phase 3 Goal\nFull integration with Flywheel ecosystem\n\n## Key Deliverables\n\n### Flywheel Tool Integration\n- Beads/BV integration\n  - BVClient for CRUD operations\n  - Triage API (ready beads, blocked beads, triageWork)\n  - Insights API (bottlenecks, keystones)\n  - Galaxy View dependency visualization\n  - Graph rendering with WebGL (react-force-graph)\n- CASS search integration\n  - Search across agent conversations\n  - Session context retrieval\n  - History indexing\n- CM memory integration\n  - Playbook rules retrieval\n  - Context queries before tasks\n  - Learning feedback loop\n- UBS scanner integration\n  - Scan before commit\n  - Auto-bead creation for findings\n  - Fix workflow integration\n\n### Advanced Conflict Resolution\n- Intelligent Conflict Resolution Assistant\n  - AI-powered merge suggestions\n  - Semantic understanding of changes\n  - Auto-resolution rules\n  - User preference learning\n\n### Session Management\n- First-Class Session Handoff Protocol\n  - Structured context transfer\n  - Resource handover\n  - Pending work queue transfer\n  - Handoff audit trail\n\n### Collaboration Visualization\n- Real-Time Agent Collaboration Graph\n  - Live visualization of agent activity\n  - File heat maps\n  - Communication flow visualization\n  - Interaction timeline\n\n### Safety \u0026 Coordination\n- SLB Safety Guardrails integration\n  - Pre-flight checks\n  - Approval workflows\n  - Escalation paths\n- Git coordination service\n  - Branch management\n  - Merge orchestration\n  - Conflict prevention\n\n### Fleet Management\n- RU (Repo Updater) integration\n  - Fleet status dashboard\n  - Multi-repo sync status\n  - Agent-sweep orchestration\n  - Three-phase review workflow\n\n### DCG Advanced Features\n- Allowlist management UI\n- False positive feedback loop\n- Pack configuration UI\n- Custom pattern editor\n\n## Phase Completion Criteria\n- [ ] BV triage returns ready work for agents\n- [ ] Galaxy View renders dependency graph interactively\n- [ ] CASS search finds relevant prior solutions\n- [ ] CM provides context rules for tasks\n- [ ] UBS findings create beads automatically\n- [ ] Conflict Resolution Assistant suggests merges\n- [ ] Session handoffs preserve full context\n- [ ] Collaboration graph shows live agent activity\n- [ ] RU fleet status visible in dashboard\n- [ ] Agent-sweep runs through Gateway\n\n## Testing Requirements\n- Unit test coverage \u003e80% for all clients\n- Integration tests for all Flywheel tool APIs\n- E2E tests for triage → work → complete cycle\n- Visual regression tests for Galaxy View\n- Performance tests for graph rendering (1000+ nodes)\n\n\n## Success Criteria\n\n- [ ] Full flywheel loop works: Beads/BV → Agent Mail coordination → Gateway execution → UBS scan → CASS index/search → CM rule extraction → context packs\n- [ ] Intelligent conflict resolution produces actionable suggestions and logs rationale/audit trail\n- [ ] First-class session handoff protocol transfers context + resources safely (with acknowledgements)\n- [ ] Git coordination + RU orchestration can run end-to-end on a repo fleet (dry-run + execute modes)\n- [ ] Tests: contract tests cover all integrated REST surfaces + E2E covers critical user workflows per `flywheel_gateway-d8b`\n","notes":"## Constituent Beads\n\nThis EPIC encompasses the following beads:\n\n### Flywheel Tool Integrations\n- flywheel_gateway-p8j: Beads/BV Integration [P2]\n- flywheel_gateway-c4z: CASS Search Integration [P2]\n- flywheel_gateway-1hv: CM Memory Integration [P2]\n- flywheel_gateway-bpg: UBS Scanner Integration [P2]\n\n### Advanced Coordination\n- flywheel_gateway-3b1: Intelligent Conflict Resolution Assistant [P2]\n- flywheel_gateway-2pl: First-Class Session Handoff Protocol [P2]\n- flywheel_gateway-c6q: Real-Time Agent Collaboration Graph [P2]\n\n### Safety \u0026 Coordination\n- flywheel_gateway-p0l: SLB Safety Guardrails [P2]\n- flywheel_gateway-toe: Git Coordination Service [P2]\n\n### Fleet Management\n- flywheel_gateway-zno: RU (Repo Updater) Integration [P2]\n- flywheel_gateway-bqs: DCG Advanced Features [P2]\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-08T13:43:45.13883281-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:05:41.199958775-05:00","dependencies":[{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-jp1","type":"blocks","created_at":"2026-01-08T14:01:44.893930815-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-p8j","type":"blocks","created_at":"2026-01-08T18:22:01.076998672-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-c4z","type":"blocks","created_at":"2026-01-08T18:22:06.109174665-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-1hv","type":"blocks","created_at":"2026-01-08T18:22:11.141019514-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-bpg","type":"blocks","created_at":"2026-01-08T18:22:16.174607727-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-3b1","type":"blocks","created_at":"2026-01-08T18:22:21.207068506-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-2pl","type":"blocks","created_at":"2026-01-08T18:22:26.235822323-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-c6q","type":"blocks","created_at":"2026-01-08T18:22:31.269131911-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-p0l","type":"blocks","created_at":"2026-01-08T18:22:36.301995529-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-toe","type":"blocks","created_at":"2026-01-08T18:22:41.331217708-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-zno","type":"blocks","created_at":"2026-01-08T18:22:46.364528288-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-f8f","depends_on_id":"flywheel_gateway-bqs","type":"blocks","created_at":"2026-01-08T18:22:51.397231043-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-f9d","title":"FEAT: Metrics and Alerts System","description":"\n## Testing Requirements\n\n### Unit Tests\n- [ ] MetricsService.record() creates correct metric types\n- [ ] AlertRule.evaluate() returns correct state for each condition type\n- [ ] Alert deduplication works for repeated violations\n- [ ] Histogram bucket boundaries are correct\n\n### Integration Tests\n- [ ] Metrics are persisted and queryable\n- [ ] Alert triggers create database records\n- [ ] Alert acknowledgment updates state correctly\n- [ ] Metric aggregation returns correct summaries\n\n### Load Tests\n- [ ] System handles 10,000 metric points/second\n- [ ] P95 metric recording latency \u003c 1ms\n- [ ] Alert evaluation completes within 100ms for 1000 rules\n\n### Failure Mode Tests\n- [ ] Metric recording continues if database is slow\n- [ ] Alerts fire even if notification delivery fails\n\n\n\n## Acceptance Criteria\n\n- [ ] Metrics model + storage implemented for core dimensions (agents, jobs, WS, scans, reservations)\n- [ ] Alert rules can be created/updated/disabled and evaluate deterministically (with debounce/cooldowns)\n- [ ] REST endpoints return consistent envelopes + correlation IDs; errors use shared taxonomy\n- [ ] WebSocket emits metric/alert events using the standard event envelope and supports replay/cursor resume\n- [ ] UI dashboard renders key charts + alert list, with clear empty/error states\n- [ ] Structured logging ties alerts/metrics to correlation IDs and relevant entity IDs\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Metric: counter increments correctly\n- [ ] Metric: gauge sets value\n- [ ] Metric: histogram records distribution\n- [ ] Metric: labels attached correctly\n- [ ] OpenTelemetry: span created\n- [ ] OpenTelemetry: span attributes set\n- [ ] OpenTelemetry: span parent linked\n- [ ] Alert rule: condition evaluation\n- [ ] Alert rule: threshold comparison\n- [ ] Alert rule: duration requirement\n- [ ] Alert notification: formats message\n- [ ] Alert notification: routes to channel\n\n### Integration Tests\n- [ ] Prometheus endpoint exports metrics\n- [ ] Metrics include correct labels\n- [ ] Histograms have correct buckets\n- [ ] Traces correlate with logs\n- [ ] Alert fires when threshold exceeded\n- [ ] Alert resolves when condition clears\n- [ ] Notification delivered to Slack/email\n\n### E2E Tests\n- [ ] Grafana dashboard shows metrics\n- [ ] Dashboard refreshes in real-time\n- [ ] Alert visible in UI\n- [ ] Alert can be acknowledged\n- [ ] Historical metrics queryable\n\n### Performance Tests\n- [ ] Metric recording \u003c1ms\n- [ ] Prometheus scrape \u003c500ms\n- [ ] 10k metrics exported efficiently\n- [ ] Trace sampling works correctly\n\n### Failure Mode Tests\n- [ ] Prometheus unavailable: metrics buffered\n- [ ] Invalid metric name: validation error\n- [ ] Alert loop: debounced\n- [ ] Notification failure: retried","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:56:39.384834188-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:57:50.111682598-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-f9d","depends_on_id":"flywheel_gateway-d18","type":"blocks","created_at":"2026-01-08T14:01:43.605649429-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-hnv","title":"FEAT: Project Scaffolding and Monorepo Setup","description":"## Overview\n\nProject scaffolding is the foundational infrastructure that enables all other Flywheel Gateway development. This bead establishes the monorepo structure, build tooling, shared package architecture, and CI quality gates that all Phase 1+ features depend on.\n\n## Background \u0026 Reasoning\n\n### Why a monorepo?\n- **Atomic changes**: cross-package changes are committed together\n- **Shared tooling**: single TypeScript + Biome config, consistent scripts\n- **Type safety**: local packages type-check together\n- **Dev experience**: fast iteration without publish/install cycles\n\n### Why Bun workspaces?\n- **Speed**: fast installs + script execution\n- **Native TypeScript**: streamlined dev workflow\n- **Workspace support**: first-class monorepo support\n\n### Technology Choices\n\n| Technology | Rationale |\n|------------|-----------|\n| **Bun** | Runtime + package manager + test runner |\n| **TypeScript** | Strict type safety, IDE support |\n| **Biome** | Unified linting/formatting |\n| **Hono** | Backend HTTP framework |\n| **Drizzle** | Type-safe ORM for SQLite |\n| **React** | UI framework |\n| **Tailwind** | Styling system |\n| **TanStack Router/Query** | Routing + data fetching |\n\n## Scope \u0026 Requirements\n\n### Monorepo Structure\n\n```\nflywheel_gateway/\n├── apps/\n│   ├── gateway/\n│   │   ├── src/\n│   │   │   ├── routes/\n│   │   │   ├── services/\n│   │   │   ├── middleware/\n│   │   │   ├── db/\n│   │   │   ├── ws/\n│   │   │   ├── openapi/\n│   │   │   └── index.ts\n│   │   ├── tests/\n│   │   └── package.json\n│   └── web/\n│       ├── src/\n│       │   ├── components/\n│       │   ├── hooks/\n│       │   ├── lib/\n│       │   ├── pages/\n│       │   ├── stores/\n│       │   └── main.tsx\n│       ├── tests/\n│       └── package.json\n├── packages/\n│   ├── shared/\n│   │   ├── src/\n│   │   │   ├── types/\n│   │   │   ├── schemas/\n│   │   │   ├── commands/\n│   │   │   └── utils/\n│   │   └── package.json\n│   ├── agent-drivers/\n│   │   ├── src/\n│   │   │   ├── sdk/\n│   │   │   ├── acp/\n│   │   │   ├── tmux/\n│   │   │   └── interface.ts\n│   │   └── package.json\n│   ├── flywheel-clients/\n│   │   ├── src/\n│   │   │   ├── agentmail/\n│   │   │   ├── bv/\n│   │   │   ├── cass/\n│   │   │   ├── cm/\n│   │   │   └── scanner/\n│   │   └── package.json\n│   └── test-utils/\n│       ├── src/\n│       │   ├── db.ts\n│       │   ├── api.ts\n│       │   ├── ws.ts\n│       │   ├── agent.ts\n│       │   ├── time.ts\n│       │   ├── assertions.ts\n│       │   ├── logging.ts\n│       │   └── index.ts\n│       └── package.json\n├── tests/\n│   ├── e2e/\n│   ├── contract/\n│   └── load/\n├── docs/\n│   └── PLAN.md\n├── .beads/\n├── package.json\n├── tsconfig.json\n└── biome.json\n```\n\n### Root `package.json` (workspace wiring)\n\n```json\n{\n  \"name\": \"flywheel-gateway\",\n  \"private\": true,\n  \"workspaces\": [\"apps/*\", \"packages/*\"],\n  \"scripts\": {\n    \"dev\": \"bun dev\",\n    \"dev:gateway\": \"bun dev:gateway\",\n    \"dev:web\": \"bun dev:web\",\n    \"build\": \"bun run --filter '*' build\",\n    \"test\": \"bun test\",\n    \"test:integration\": \"bun test --filter 'tests/integration/**'\",\n    \"test:e2e\": \"bunx playwright test\",\n    \"lint\": \"bun lint\",\n    \"lint:fix\": \"bun lint:fix\",\n    \"format\": \"bun format\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"db:generate\": \"bun db:generate\",\n    \"db:migrate\": \"bun db:migrate\",\n    \"db:studio\": \"bun db:studio\"\n  }\n}\n```\n\n### TypeScript configuration\n\n- Strict mode enabled\n- Base tsconfig shared across packages\n- Workspace path aliases for local packages\n\n### Biome configuration\n\n- Lint + format configured for the repo\n- CI runs `biome check .` (no auto-write)\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] TypeScript compilation succeeds with strict mode\n- [ ] All package exports are typed correctly\n- [ ] Path aliases resolve correctly\n- [ ] Biome linting passes on representative code\n\n### Integration Tests\n- [ ] Bun workspaces resolve inter-package dependencies\n- [ ] Changes in `packages/shared` reflect in consuming packages\n- [ ] `bun dev` starts gateway + web concurrently\n\n### E2E Tests\n- [ ] `bun test:e2e` boots the system and validates a minimal smoke flow (gateway health + UI loads)\n\n### Failure Mode Tests\n- [ ] Missing dependency / misconfigured workspace fails with actionable error output\n\n### Logging\n- [ ] Test logs include a run-level `correlationId` and redact secrets\n\n## Acceptance Criteria\n\n- [ ] Monorepo structure created with all required directories\n- [ ] Root `package.json` configured for Bun workspaces and common scripts\n- [ ] Base `tsconfig.json` strict settings applied repo-wide\n- [ ] `biome.json` present; `bun lint` and `bun format` are wired\n- [ ] Gateway app starts and responds to a health check endpoint\n- [ ] Web app starts and renders a placeholder page\n- [ ] CI runs: typecheck + lint + unit tests (+ e2e smoke on PR)\n\n## References\n\n- `docs/PLAN.md` (Phases + File Structure + Testing)\n","status":"open","priority":0,"issue_type":"feature","created_at":"2026-01-08T18:03:32.834946194-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:28:19.267337613-05:00"}
{"id":"flywheel_gateway-i6c","title":"Custom Dashboard Builder","description":"## Background\n\nAs the Flywheel Gateway platform matures, users need the ability to create personalized views of their agent ecosystem, costs, and activity metrics. A custom dashboard builder enables users to construct tailored monitoring interfaces without requiring engineering intervention, democratizing data visualization across the organization.\n\n## Problem Statement\n\nCurrently, users are limited to predefined dashboard layouts that may not align with their specific monitoring needs. Different roles (developers, managers, finance) have distinct requirements for data visualization. Without customization capabilities, users either lack visibility into relevant metrics or must request engineering resources for custom reports.\n\n## Technical Approach\n\n### Core Architecture\n\nThe dashboard builder will leverage react-grid-layout for drag-and-drop widget placement, providing a familiar interface similar to tools like Grafana or Datadog dashboards.\n\n```typescript\n// apps/web/src/components/analytics/DashboardBuilder.tsx\ninterface Dashboard {\n  id: string;\n  name: string;\n  description?: string;\n  ownerId: string;\n  visibility: 'private' | 'team' | 'public';\n  teamId?: string;\n  layout: DashboardLayout;\n  widgets: Widget[];\n  refreshInterval: number; // seconds, 0 = manual only\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ninterface DashboardLayout {\n  columns: number; // typically 12 or 24\n  rowHeight: number;\n  margin: [number, number];\n  containerPadding: [number, number];\n}\n\ninterface Widget {\n  id: string;\n  type: WidgetType;\n  title: string;\n  position: { x: number; y: number; w: number; h: number };\n  config: WidgetConfig;\n  dataSource: DataSourceConfig;\n}\n\ntype WidgetType = \n  | 'metric-card'      // Single KPI with trend\n  | 'line-chart'       // Time series\n  | 'bar-chart'        // Categorical comparison\n  | 'pie-chart'        // Distribution\n  | 'table'            // Tabular data\n  | 'agent-list'       // Agent status list\n  | 'activity-feed'    // Recent events stream\n  | 'cost-breakdown'   // Cost visualization\n  | 'heatmap'          // Usage patterns\n  | 'gauge'            // Progress/capacity\n  | 'text'             // Markdown content\n  | 'iframe';          // External embeds\n```\n\n### Widget Type Specifications\n\n**Metric Cards:**\n- Single value display with optional sparkline\n- Trend indicator (up/down/neutral with percentage)\n- Threshold-based coloring (green/yellow/red)\n- Click-through to detailed view\n\n**Charts (Line, Bar, Pie):**\n- Built on Chart.js or Recharts\n- Configurable time ranges\n- Multiple series support\n- Legend positioning\n- Tooltip customization\n- Export as PNG/SVG\n\n**Tables:**\n- Sortable columns\n- Pagination\n- Column visibility toggles\n- Row click actions\n- Inline search/filter\n- CSV export\n\n**Agent Lists:**\n- Status indicators (active/idle/error/offline)\n- Quick actions (pause, configure, view logs)\n- Grouping by team/project/model\n- Search and filter\n\n**Activity Feeds:**\n- Real-time updates via WebSocket\n- Event type filtering\n- Expandable details\n- Jump to related entity\n\n### Widget Configuration Panel\n\n```typescript\ninterface WidgetConfigPanel {\n  // Common settings\n  title: string;\n  description?: string;\n  refreshInterval?: number;\n  \n  // Data source\n  dataSource: {\n    type: 'api' | 'query' | 'static';\n    endpoint?: string;\n    query?: string; // For custom queries\n    filters?: Record\u003cstring, any\u003e;\n    timeRange?: TimeRange;\n  };\n  \n  // Display settings (type-specific)\n  display: {\n    colorScheme?: string;\n    showLegend?: boolean;\n    showGrid?: boolean;\n    // ... type-specific options\n  };\n  \n  // Thresholds\n  thresholds?: {\n    warning?: number;\n    critical?: number;\n  };\n}\n```\n\n### Auto-Refresh Configuration\n\n```typescript\ninterface RefreshConfig {\n  globalInterval: number; // Dashboard-wide default\n  widgetOverrides: Map\u003cstring, number\u003e; // Per-widget overrides\n  pauseOnHidden: boolean; // Pause when tab not visible\n  pauseOnError: boolean; // Pause widget on consecutive errors\n  maxRetries: number; // Before pausing\n}\n```\n\n### Sharing and Access Control\n\n```typescript\ninterface DashboardSharing {\n  visibility: 'private' | 'team' | 'public';\n  teamId?: string; // Required for 'team' visibility\n  \n  // Granular permissions\n  viewers: string[]; // User IDs with read access\n  editors: string[]; // User IDs with edit access\n  \n  // Public options\n  publicSlug?: string; // URL-friendly identifier\n  requireAuth: boolean; // Require login even for public\n  embedEnabled: boolean; // Allow iframe embedding\n  embedToken?: string; // For secure embedding\n}\n```\n\n### Backend Storage\n\n```sql\n-- Dashboards table\nCREATE TABLE dashboards (\n  id UUID PRIMARY KEY,\n  org_id UUID NOT NULL REFERENCES organizations(id),\n  owner_id UUID NOT NULL REFERENCES users(id),\n  name VARCHAR(255) NOT NULL,\n  description TEXT,\n  visibility VARCHAR(20) DEFAULT 'private',\n  team_id UUID REFERENCES teams(id),\n  layout JSONB NOT NULL,\n  widgets JSONB NOT NULL,\n  refresh_interval INTEGER DEFAULT 60,\n  public_slug VARCHAR(100) UNIQUE,\n  embed_enabled BOOLEAN DEFAULT false,\n  embed_token VARCHAR(64),\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Dashboard permissions\nCREATE TABLE dashboard_permissions (\n  dashboard_id UUID REFERENCES dashboards(id) ON DELETE CASCADE,\n  user_id UUID REFERENCES users(id) ON DELETE CASCADE,\n  permission VARCHAR(20) NOT NULL, -- 'view' or 'edit'\n  PRIMARY KEY (dashboard_id, user_id)\n);\n\n-- Dashboard favorites for quick access\nCREATE TABLE dashboard_favorites (\n  user_id UUID REFERENCES users(id) ON DELETE CASCADE,\n  dashboard_id UUID REFERENCES dashboards(id) ON DELETE CASCADE,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  PRIMARY KEY (user_id, dashboard_id)\n);\n```\n\n### API Endpoints\n\n```typescript\n// Dashboard CRUD\nGET    /api/v1/dashboards                    // List user's dashboards\nPOST   /api/v1/dashboards                    // Create dashboard\nGET    /api/v1/dashboards/:id                // Get dashboard\nPUT    /api/v1/dashboards/:id                // Update dashboard\nDELETE /api/v1/dashboards/:id                // Delete dashboard\nPOST   /api/v1/dashboards/:id/duplicate      // Clone dashboard\n\n// Sharing\nPUT    /api/v1/dashboards/:id/sharing        // Update sharing settings\nGET    /api/v1/dashboards/:id/permissions    // List permissions\nPOST   /api/v1/dashboards/:id/permissions    // Add permission\nDELETE /api/v1/dashboards/:id/permissions/:userId\n\n// Widget data\nGET    /api/v1/dashboards/:id/widgets/:widgetId/data  // Fetch widget data\n\n// Public access\nGET    /api/v1/public/dashboards/:slug       // Public dashboard view\nGET    /api/v1/embed/:token                  // Embedded dashboard\n```\n\n## File Locations\n\n- apps/web/src/components/analytics/DashboardBuilder.tsx - Main builder component\n- apps/web/src/components/analytics/DashboardGrid.tsx - react-grid-layout wrapper\n- apps/web/src/components/analytics/widgets/ - Widget components directory\n- apps/web/src/components/analytics/WidgetConfigPanel.tsx - Configuration sidebar\n- apps/web/src/hooks/useDashboard.ts - Dashboard state management\n- apps/gateway/src/services/dashboard.service.ts - Backend service\n- apps/gateway/src/controllers/dashboard.controller.ts - API controller\n- packages/shared/src/types/dashboard.ts - Shared type definitions\n\n## Dependencies\n\n- react-grid-layout: ^1.4.0 (drag-and-drop grid)\n- recharts: ^2.8.0 (charting library)\n- @tanstack/react-query: For data fetching and caching\n- date-fns: Time range calculations\n- react-markdown: For text widgets\n\n## Acceptance Criteria\n\n1. Users can create, edit, and delete custom dashboards\n2. Drag-and-drop widget placement works smoothly on desktop browsers\n3. All specified widget types are implemented and functional\n4. Widget configuration panel allows customizing all relevant settings\n5. Auto-refresh works with configurable intervals (15s, 30s, 1m, 5m, 15m, off)\n6. Dashboards can be shared with teams or made public\n7. Public dashboards are accessible via slug URLs\n8. Dashboard state persists correctly across sessions\n9. Performance: Dashboard with 20 widgets loads in \u003c 3 seconds\n10. Mobile-responsive layout degrades gracefully\n11. Widgets display loading states and error handling\n12. Export functionality available for charts and tables\n\n## Testing Strategy\n\n- Unit tests for widget components\n- Integration tests for dashboard CRUD operations\n- E2E tests for drag-and-drop interactions\n- Performance tests for large dashboards\n- Cross-browser testing (Chrome, Firefox, Safari, Edge)\n\n## Reference\n\nPLAN.md section 21.8 - Custom Dashboard Builder\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Dashboard layout serialization/deserialization is stable and backward-compatible within a major version\n- [ ] Widget registry rejects invalid configs with actionable errors\n- [ ] Grid/layout constraints prevent overlapping/invalid placements\n\n### Integration Tests\n- [ ] Create/update/delete dashboard via REST and verify persistence + retrieval\n\n### E2E Tests (UI)\n- [ ] Drag/drop widgets, resize, save, reload → layout persists and renders correctly\n\n### Logging\n- [ ] Logs include correlationId + dashboardId + widgetCount + action; widget payloads are validated and sanitized\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] Widget: creates from definition\n- [ ] Widget: validates configuration\n- [ ] Widget: renders data correctly\n- [ ] Layout: places widgets on grid\n- [ ] Layout: handles responsive breakpoints\n- [ ] Layout: persists to JSON\n- [ ] Dashboard: creates with name\n- [ ] Dashboard: adds/removes widgets\n- [ ] Dashboard: saves layout\n- [ ] WidgetGallery: lists available types\n- [ ] DragDrop: calculates drop position\n- [ ] DragDrop: validates placement\n\n### Integration Tests\n- [ ] POST /dashboards creates dashboard\n- [ ] GET /dashboards lists user dashboards\n- [ ] PUT /dashboards/:id updates layout\n- [ ] DELETE /dashboards/:id removes dashboard\n- [ ] Widget data fetched correctly\n- [ ] Layout persisted and restored\n- [ ] Share dashboard with others\n\n### E2E Tests\n- [ ] Create dashboard from scratch\n- [ ] Drag widget from gallery\n- [ ] Resize widget on grid\n- [ ] Save and reload dashboard\n- [ ] View shared dashboard\n\n### Performance Tests\n- [ ] Dashboard load \u003c1s\n- [ ] Widget render \u003c200ms each\n- [ ] Drag preview 60fps\n- [ ] Layout save \u003c500ms\n\n### Failure Mode Tests\n- [ ] Invalid widget config: error shown\n- [ ] Data source unavailable: error state\n- [ ] Layout corruption: reset to default\n- [ ] Widget crash: isolated error boundary","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:59:32.031402337-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:08:59.241406945-05:00","dependencies":[{"issue_id":"flywheel_gateway-i6c","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T14:01:51.072723089-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-jp1","title":"EPIC: Phase 2 - Core Features","description":"## Overview\nPhase 2 adds multi-agent coordination capabilities, state management, and account management for production use.\n\n## Phase 2 Goal\nMulti-agent coordination and state management\n\n## Key Deliverables\n\n### Additional Agent Drivers\n- ACP Agent Driver (Agent Client Protocol)\n  - JSON-RPC 2.0 over stdio\n  - IDE integration compatibility\n  - Protocol adapter for different agents\n\n### Agent Communication\n- Agent Mail integration (MCP client)\n  - Messaging between agents\n  - Thread management\n  - Inbox/outbox operations\n- File reservation system\n  - Advisory locks with TTL\n  - Exclusive/shared modes\n  - Reservation map UI component\n\n### Conflict Management\n- Conflict detection baseline\n  - File conflict detection\n  - WebSocket events for conflicts\n  - Alert generation\n\n### State Management\n- Checkpoint/restore system\n  - Delta-based progressive checkpointing\n  - Full checkpoint every 5th\n  - Compression with zstd\n  - Bounded restore time\n- Auto-Healing Context Window Management\n  - Graduated thresholds (warning 75%, critical 85%, emergency 95%)\n  - Proactive summarization\n  - Seamless agent rotation with context transfer\n- Context pack builder\n  - Token budgeting\n  - Source prioritization\n  - Overflow handling\n\n### Operations\n- Job orchestration for long-running operations\n  - Context builds, scans, exports\n  - Progress events via WebSocket\n  - Job status endpoints\n- History tracking system\n  - Prompt/response summaries\n  - Token usage tracking\n  - Outcome recording\n\n### Reliability\n- Idempotency middleware\n  - Idempotency key header\n  - Response caching\n  - Duplicate request handling\n\n### Account Management\n- CAAM integration (BYOA + BYOK)\n  - Profile vault management\n  - Account rotation on limits\n  - Usage tracking per profile\n  - Health monitoring\n\n## Phase Completion Criteria\n- [ ] Multiple agents can coordinate via Agent Mail\n- [ ] File reservations prevent edit conflicts\n- [ ] Conflicts detected and alert generated\n- [ ] Checkpoints created automatically with deltas\n- [ ] Restore from checkpoint works within 200ms\n- [ ] Context window auto-heals before hitting limit\n- [ ] Long-running operations show progress\n- [ ] BYOA accounts rotate on rate limit\n- [ ] All operations are idempotent\n\n## Testing Requirements\n- Unit test coverage \u003e80% for all new services\n- Integration tests for Agent Mail operations\n- Integration tests for checkpoint/restore cycle\n- E2E tests for multi-agent coordination scenarios\n- Performance tests for checkpoint restoration time\n- Load tests for context window management\n- Structured test logging + artifact capture per `flywheel_gateway-d8b`\n\n\n## Success Criteria\n\n- [ ] Multi-agent coordination works end-to-end: Agent Mail integration + reservations + conflict alerts + checkpoints + context packs\n- [ ] Auto-healing context window management demonstrated (thresholds, compaction/rotation, safe handoff)\n- [ ] Long-running operations return job IDs + progress events; jobs are observable and cancelable\n- [ ] Idempotency middleware prevents duplicated side effects for mutating endpoints\n- [ ] BYOA-gated execution is enforced (no account → actionable error with recovery hints)\n- [ ] Tests: unit + integration + E2E coverage for new UX flows and failure modes per `flywheel_gateway-d8b`\n\n","notes":"## Constituent Beads\n\nThis EPIC encompasses the following beads:\n\n### Additional Agent Drivers\n- flywheel_gateway-o54: ACP Agent Driver [P2]\n- flywheel_gateway-e73: Tmux Agent Driver [P2]\n\n### Agent Communication\n- flywheel_gateway-61i: Agent Mail Integration (MCP Client) [P2]\n- flywheel_gateway-5nm: File Reservation System [P2]\n\n### Conflict Management\n- flywheel_gateway-msz: Conflict Detection and Alerts [P2]\n\n### State Management\n- flywheel_gateway-36m: Checkpoint/Restore System with Delta-Based Progressive Checkpointing [P2]\n- flywheel_gateway-ew1: Auto-Healing Context Window Management [P2]\n- flywheel_gateway-45c: Context Pack Builder with Token Budgeting [P2]\n\n### Operations\n- flywheel_gateway-7n4: Job Orchestration for Long-Running Operations [P2]\n- flywheel_gateway-89x: History Tracking System [P2]\n\n### Reliability\n- flywheel_gateway-350: Idempotency Middleware [P2]\n\n### Account Management\n- flywheel_gateway-41h: CAAM Account Management (BYOA + Rotation) [P2]\n","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-08T13:33:38.459901861-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:32:18.074352581-05:00","dependencies":[{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-2ao","type":"blocks","created_at":"2026-01-08T14:01:40.696712516-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-o54","type":"blocks","created_at":"2026-01-08T18:20:54.458989058-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-e73","type":"blocks","created_at":"2026-01-08T18:20:59.51669958-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-61i","type":"blocks","created_at":"2026-01-08T18:21:04.550057423-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-5nm","type":"blocks","created_at":"2026-01-08T18:21:09.583034951-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-msz","type":"blocks","created_at":"2026-01-08T18:21:14.617228237-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-36m","type":"blocks","created_at":"2026-01-08T18:21:19.649455542-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-ew1","type":"blocks","created_at":"2026-01-08T18:21:24.682114689-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-45c","type":"blocks","created_at":"2026-01-08T18:21:29.71595974-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-7n4","type":"blocks","created_at":"2026-01-08T18:21:34.75023498-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-89x","type":"blocks","created_at":"2026-01-08T18:21:39.782179022-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-350","type":"blocks","created_at":"2026-01-08T18:21:44.817282512-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-jp1","depends_on_id":"flywheel_gateway-41h","type":"blocks","created_at":"2026-01-08T18:21:49.851113476-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-lil","title":"TASK: Parity Gate Tests","description":"## Background\n\nParity Gate Tests ensure that the Flywheel Gateway maintains consistency across all its interfaces and documentation. As the system grows with multiple access methods (REST API, WebSocket, CLI, AI-assisted), it becomes critical to verify that:\n\n1. Every command is accessible through all intended interfaces\n2. Documentation stays synchronized with implementation\n3. Schema definitions match actual behavior\n4. No commands are accidentally \"orphaned\" without proper bindings\n\n### The Parity Problem\n\nWithout automated verification, systems tend to drift:\n- New commands added without REST bindings\n- AI hints outdated or missing for commands\n- OpenAPI spec doesn't match actual endpoints\n- WebSocket events undocumented\n- Schema validation inconsistent\n\nParity Gate Tests run in CI to catch these issues before merge.\n\n## Technical Architecture\n\n### Test Categories\n\n```typescript\n// scripts/parity-gate.test.ts\n\ndescribe('Command Registry Parity', () =\u003e {\n  // Category 1: REST Binding Coverage\n  describe('REST Bindings', () =\u003e {\n    it('every registered command has a REST endpoint');\n    it('REST endpoints match command signatures');\n    it('HTTP methods are appropriate for command type');\n    it('route parameters match command inputs');\n  });\n  \n  // Category 2: AI Hint Coverage\n  describe('AI Hints', () =\u003e {\n    it('every command has AI hints defined');\n    it('AI hints include description');\n    it('AI hints include example usage');\n    it('AI hints include parameter explanations');\n    it('AI hints are under 500 tokens');\n  });\n  \n  // Category 3: Schema Coverage\n  describe('Input/Output Schemas', () =\u003e {\n    it('every command has input schema');\n    it('every command has output schema');\n    it('schemas are valid JSON Schema draft-07');\n    it('required fields are marked');\n    it('examples validate against schema');\n  });\n  \n  // Category 4: OpenAPI Consistency\n  describe('OpenAPI Spec', () =\u003e {\n    it('all REST endpoints are in OpenAPI spec');\n    it('OpenAPI schemas match TypeScript types');\n    it('response codes are documented');\n    it('error responses are standardized');\n    it('OpenAPI examples are valid');\n  });\n  \n  // Category 5: WebSocket Documentation\n  describe('WebSocket Events', () =\u003e {\n    it('all events are documented');\n    it('event payloads have schemas');\n    it('subscription patterns are documented');\n    it('error events are standardized');\n  });\n});\n```\n\n### Command Registry Scanner\n\n```typescript\n// scripts/lib/registry-scanner.ts\ninterface RegisteredCommand {\n  name: string;\n  module: string;\n  handler: string;\n  inputType: string;\n  outputType: string;\n  restBinding?: RestBinding;\n  aiHints?: AIHints;\n  inputSchema?: JSONSchema;\n  outputSchema?: JSONSchema;\n}\n\ninterface RestBinding {\n  method: 'GET' | 'POST' | 'PUT' | 'PATCH' | 'DELETE';\n  path: string;\n  pathParams: string[];\n  queryParams: string[];\n  bodyParam?: string;\n}\n\ninterface AIHints {\n  description: string;\n  examples: string[];\n  parameterHints: Record\u003cstring, string\u003e;\n  relatedCommands: string[];\n  tokenCount: number;\n}\n\nclass RegistryScanner {\n  async scanCommands(): Promise\u003cRegisteredCommand[]\u003e;\n  async scanRestControllers(): Promise\u003cRestBinding[]\u003e;\n  async scanAIHints(): Promise\u003cMap\u003cstring, AIHints\u003e\u003e;\n  async scanSchemas(): Promise\u003cMap\u003cstring, JSONSchema\u003e\u003e;\n}\n```\n\n### OpenAPI Validator\n\n```typescript\n// scripts/lib/openapi-validator.ts\ninterface OpenAPIValidationResult {\n  valid: boolean;\n  errors: ValidationError[];\n  warnings: ValidationWarning[];\n  coverage: {\n    documentedEndpoints: number;\n    totalEndpoints: number;\n    percentage: number;\n  };\n}\n\nclass OpenAPIValidator {\n  async loadSpec(path: string): Promise\u003cOpenAPIDocument\u003e;\n  async validateAgainstRoutes(spec: OpenAPIDocument, routes: Route[]): Promise\u003cOpenAPIValidationResult\u003e;\n  async validateSchemas(spec: OpenAPIDocument, types: TypeDefinition[]): Promise\u003cSchemaValidationResult\u003e;\n  async validateExamples(spec: OpenAPIDocument): Promise\u003cExampleValidationResult\u003e;\n}\n```\n\n### WebSocket Documentation Checker\n\n```typescript\n// scripts/lib/websocket-doc-checker.ts\ninterface WebSocketEvent {\n  name: string;\n  direction: 'client-to-server' | 'server-to-client' | 'bidirectional';\n  payloadSchema: JSONSchema;\n  documented: boolean;\n  documentationPath?: string;\n}\n\nclass WebSocketDocChecker {\n  async scanEventHandlers(): Promise\u003cWebSocketEvent[]\u003e;\n  async scanDocumentation(): Promise\u003cDocumentedEvent[]\u003e;\n  async findUndocumentedEvents(): Promise\u003cstring[]\u003e;\n  async validateEventSchemas(): Promise\u003cValidationResult[]\u003e;\n}\n```\n\n## Test Implementation\n\n```typescript\n// scripts/parity-gate.test.ts\nimport { describe, it, expect, beforeAll } from 'vitest';\nimport { RegistryScanner } from './lib/registry-scanner';\nimport { OpenAPIValidator } from './lib/openapi-validator';\nimport { WebSocketDocChecker } from './lib/websocket-doc-checker';\n\ndescribe('Parity Gate Tests', () =\u003e {\n  let commands: RegisteredCommand[];\n  let restBindings: RestBinding[];\n  let openAPISpec: OpenAPIDocument;\n  \n  beforeAll(async () =\u003e {\n    const scanner = new RegistryScanner();\n    commands = await scanner.scanCommands();\n    restBindings = await scanner.scanRestControllers();\n    openAPISpec = await new OpenAPIValidator().loadSpec('./docs/openapi.yaml');\n  });\n  \n  describe('REST Binding Coverage', () =\u003e {\n    it('every registered command has a REST endpoint', () =\u003e {\n      const commandNames = commands.map(c =\u003e c.name);\n      const boundCommands = restBindings.map(b =\u003e b.commandName);\n      \n      const unbound = commandNames.filter(n =\u003e !boundCommands.includes(n));\n      \n      expect(unbound).toEqual([]);\n      expect(unbound.length).toBe(0);\n    });\n    \n    it('REST methods match command semantics', () =\u003e {\n      for (const binding of restBindings) {\n        const command = commands.find(c =\u003e c.name === binding.commandName);\n        \n        if (command.name.startsWith('get') || command.name.startsWith('list')) {\n          expect(binding.method).toBe('GET');\n        }\n        if (command.name.startsWith('create')) {\n          expect(binding.method).toBe('POST');\n        }\n        if (command.name.startsWith('update')) {\n          expect(['PUT', 'PATCH']).toContain(binding.method);\n        }\n        if (command.name.startsWith('delete')) {\n          expect(binding.method).toBe('DELETE');\n        }\n      }\n    });\n  });\n  \n  describe('AI Hint Coverage', () =\u003e {\n    it('every command has AI hints', () =\u003e {\n      const missingHints = commands.filter(c =\u003e !c.aiHints);\n      \n      expect(missingHints.map(c =\u003e c.name)).toEqual([]);\n    });\n    \n    it('AI hints have required fields', () =\u003e {\n      for (const command of commands) {\n        if (command.aiHints) {\n          expect(command.aiHints.description).toBeTruthy();\n          expect(command.aiHints.description.length).toBeGreaterThan(10);\n          expect(command.aiHints.examples.length).toBeGreaterThan(0);\n        }\n      }\n    });\n    \n    it('AI hints are concise (under 500 tokens)', () =\u003e {\n      for (const command of commands) {\n        if (command.aiHints) {\n          expect(command.aiHints.tokenCount).toBeLessThan(500);\n        }\n      }\n    });\n  });\n  \n  describe('Schema Coverage', () =\u003e {\n    it('every command has input schema', () =\u003e {\n      const missingInput = commands.filter(c =\u003e !c.inputSchema);\n      expect(missingInput.map(c =\u003e c.name)).toEqual([]);\n    });\n    \n    it('every command has output schema', () =\u003e {\n      const missingOutput = commands.filter(c =\u003e !c.outputSchema);\n      expect(missingOutput.map(c =\u003e c.name)).toEqual([]);\n    });\n    \n    it('schemas are valid JSON Schema', async () =\u003e {\n      const Ajv = await import('ajv');\n      const ajv = new Ajv.default();\n      \n      for (const command of commands) {\n        if (command.inputSchema) {\n          expect(() =\u003e ajv.compile(command.inputSchema)).not.toThrow();\n        }\n        if (command.outputSchema) {\n          expect(() =\u003e ajv.compile(command.outputSchema)).not.toThrow();\n        }\n      }\n    });\n  });\n  \n  describe('OpenAPI Consistency', () =\u003e {\n    it('all REST endpoints are in OpenAPI spec', async () =\u003e {\n      const validator = new OpenAPIValidator();\n      const result = await validator.validateAgainstRoutes(openAPISpec, restBindings);\n      \n      expect(result.coverage.percentage).toBe(100);\n      expect(result.errors).toEqual([]);\n    });\n    \n    it('OpenAPI response codes are documented', () =\u003e {\n      for (const path of Object.values(openAPISpec.paths)) {\n        for (const operation of Object.values(path)) {\n          expect(operation.responses['200'] || operation.responses['201']).toBeTruthy();\n          expect(operation.responses['400']).toBeTruthy();\n          expect(operation.responses['500']).toBeTruthy();\n        }\n      }\n    });\n  });\n  \n  describe('WebSocket Event Documentation', () =\u003e {\n    it('all events are documented', async () =\u003e {\n      const checker = new WebSocketDocChecker();\n      const undocumented = await checker.findUndocumentedEvents();\n      \n      expect(undocumented).toEqual([]);\n    });\n  });\n});\n```\n\n## File Structure\n\n```\nscripts/\n├── parity-gate.test.ts          # Main test file\n├── lib/\n│   ├── registry-scanner.ts      # Command registry analysis\n│   ├── openapi-validator.ts     # OpenAPI validation\n│   ├── websocket-doc-checker.ts # WebSocket docs check\n│   ├── schema-validator.ts      # JSON Schema validation\n│   └── ai-hints-analyzer.ts     # AI hints analysis\n├── fixtures/\n│   ├── sample-commands.json     # Test fixtures\n│   └── sample-openapi.yaml      # Test OpenAPI spec\n└── reports/\n    └── .gitkeep                 # Generated reports directory\n```\n\n## CI Integration\n\n```yaml\n# .github/workflows/parity-gate.yml\nname: Parity Gate\n\non:\n  pull_request:\n    branches: [main]\n  push:\n    branches: [main]\n\njobs:\n  parity-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          \n      - name: Install dependencies\n        run: npm ci\n        \n      - name: Run Parity Gate Tests\n        run: npm run test:parity\n        \n      - name: Upload Coverage Report\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: parity-report\n          path: scripts/reports/\n```\n\n## Output Reports\n\n```typescript\n// Generated report structure\ninterface ParityReport {\n  timestamp: Date;\n  summary: {\n    totalCommands: number;\n    restCoverage: number;\n    aiHintsCoverage: number;\n    schemaCoverage: number;\n    openAPICoverage: number;\n    websocketCoverage: number;\n  };\n  issues: {\n    critical: Issue[];\n    warning: Issue[];\n    info: Issue[];\n  };\n  recommendations: string[];\n}\n```\n\n## Acceptance Criteria\n\n- [ ] Test discovers all registered commands automatically\n- [ ] Test fails if command lacks REST binding\n- [ ] Test fails if command lacks AI hints\n- [ ] Test fails if command lacks input/output schema\n- [ ] Test fails if OpenAPI spec is out of sync\n- [ ] Test fails if WebSocket events undocumented\n- [ ] HTML report generated with coverage percentages\n- [ ] CI workflow runs on every PR\n- [ ] Test execution completes in under 60 seconds\n- [ ] Clear error messages identify specific missing items\n- [ ] Fixture data allows testing the test itself\n- [ ] Documentation for adding new commands correctly\n\n## Error Message Examples\n\n```\nFAIL: Command 'user.updateProfile' missing REST binding\n  Expected: POST /api/users/:id/profile\n  Found: No binding registered\n  \nFAIL: Command 'project.archive' missing AI hints\n  Expected: AIHints with description, examples\n  Found: undefined\n  \nFAIL: OpenAPI spec missing endpoint\n  Expected: GET /api/projects/{id}/members documented\n  Found: Not in openapi.yaml\n  \nWARN: AI hints exceed token limit\n  Command: 'report.generateComplex'\n  Tokens: 623 (limit: 500)\n  Suggestion: Reduce examples or split command\n```\n\n## Dependencies\n\n- Vitest (test runner)\n- Ajv (JSON Schema validation)\n- TypeScript compiler API (for type extraction)\n- OpenAPI parser library\n- Glob (for file scanning)\n\n## References\n\n- PLAN.md Section 25.7: Parity Gate Tests\n- Command Registry specification\n- OpenAPI 3.1 specification\n- JSON Schema draft-07\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Parity checks detect: missing REST binding, missing AI hints, missing OpenAPI examples, and unsafe DELETE metadata\n- [ ] Path matching logic correctly handles path params and method normalization\n\n### Integration Tests\n- [ ] Run parity gate against a minimal command registry fixture and ensure failures are actionable\n\n### Logging\n- [ ] Test output logs include the exact violating command names and suggested fixes\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-08T13:32:16.623468038-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:28:38.914643764-05:00","dependencies":[{"issue_id":"flywheel_gateway-lil","depends_on_id":"flywheel_gateway-2kf","type":"blocks","created_at":"2026-01-08T14:01:59.547297828-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-ls4","title":"FEAT: Shared Error Taxonomy + AI Hints","description":"## Background\n\nFlywheel Gateway requires a unified error handling system that serves three distinct audiences:\n1. **Human Developers** - Need clear, actionable error messages during development\n2. **AI Agents** - Need structured hints to understand what went wrong and how to recover\n3. **Client Applications** - Need consistent HTTP status codes and error formats for programmatic handling\n\nThe error taxonomy must be comprehensive enough to cover all failure modes across the gateway ecosystem while remaining extensible for future use cases.\n\n## Technical Rationale\n\n### Why a Shared Error Package?\n- **Consistency**: All packages (gateway, drivers, SDK) use identical error codes\n- **Type Safety**: TypeScript discriminated unions ensure exhaustive error handling\n- **AI Integration**: Built-in hints help AI agents self-correct without human intervention\n- **Observability**: Structured errors enable better logging, metrics, and alerting\n\n### Error Code Design Philosophy\nError codes follow the pattern: `{DOMAIN}_{SPECIFIC_ERROR}`\n- Domain prefixes: `AGENT_`, `SPAWN_`, `DRIVER_`, `WS_`, `AUTH_`, `RATE_`, `SYSTEM_`\n- This enables filtering/routing by domain while maintaining specificity\n\n## Scope \u0026 Requirements\n\n### Core Error Codes to Define\n\n**Agent Lifecycle Errors:**\n- `AGENT_NOT_FOUND` - Agent ID does not exist or was garbage collected\n- `AGENT_ALREADY_EXISTS` - Attempt to spawn with duplicate ID\n- `AGENT_TERMINATED` - Operation on already-terminated agent\n- `AGENT_BUSY` - Agent currently processing, cannot accept new commands\n- `AGENT_TIMEOUT` - Agent did not respond within configured timeout\n\n**Spawn Errors:**\n- `SPAWN_FAILED` - Generic spawn failure (driver-specific details in metadata)\n- `SPAWN_QUOTA_EXCEEDED` - User/workspace has reached agent spawn limit\n- `SPAWN_INVALID_CONFIG` - Invalid spawn configuration parameters\n- `SPAWN_DRIVER_UNAVAILABLE` - Requested driver not available/healthy\n\n**Driver Errors:**\n- `DRIVER_NOT_FOUND` - Unknown driver type requested\n- `DRIVER_INIT_FAILED` - Driver failed to initialize\n- `DRIVER_COMMUNICATION_ERROR` - Lost connection to underlying agent process\n- `DRIVER_PROTOCOL_ERROR` - Unexpected message format from agent\n\n**WebSocket Errors:**\n- `WS_CONNECTION_FAILED` - Failed to establish WebSocket connection\n- `WS_AUTHENTICATION_REQUIRED` - Missing or invalid auth token\n- `WS_SUBSCRIPTION_DENIED` - Not authorized for requested channel\n- `WS_CURSOR_EXPIRED` - Requested replay cursor no longer in ring buffer\n- `WS_RATE_LIMITED` - Too many messages/connections\n\n**Authentication/Authorization:**\n- `AUTH_TOKEN_INVALID` - Malformed or expired token\n- `AUTH_TOKEN_EXPIRED` - Token past expiration time\n- `AUTH_INSUFFICIENT_SCOPE` - Token lacks required permissions\n- `AUTH_TENANT_SUSPENDED` - Tenant account suspended\n\n**Rate Limiting:**\n- `RATE_LIMIT_EXCEEDED` - Request rate limit exceeded\n- `RATE_CONCURRENT_LIMIT` - Too many concurrent operations\n\n**System Errors:**\n- `SYSTEM_UNAVAILABLE` - Service temporarily unavailable\n- `SYSTEM_INTERNAL_ERROR` - Unexpected internal error\n- `SYSTEM_RESOURCE_EXHAUSTED` - Memory/CPU/disk limits reached\n\n### HTTP Status Mappings\n\n```typescript\nconst HTTP_STATUS_MAP: Record\u003cErrorCode, number\u003e = {\n  // 4xx Client Errors\n  AGENT_NOT_FOUND: 404,\n  AGENT_ALREADY_EXISTS: 409,\n  AGENT_TERMINATED: 410,  // Gone\n  AGENT_BUSY: 423,        // Locked\n  AGENT_TIMEOUT: 408,\n  \n  SPAWN_INVALID_CONFIG: 400,\n  SPAWN_QUOTA_EXCEEDED: 429,\n  SPAWN_DRIVER_UNAVAILABLE: 503,\n  \n  DRIVER_NOT_FOUND: 400,\n  \n  WS_AUTHENTICATION_REQUIRED: 401,\n  WS_SUBSCRIPTION_DENIED: 403,\n  WS_CURSOR_EXPIRED: 410,\n  WS_RATE_LIMITED: 429,\n  \n  AUTH_TOKEN_INVALID: 401,\n  AUTH_TOKEN_EXPIRED: 401,\n  AUTH_INSUFFICIENT_SCOPE: 403,\n  AUTH_TENANT_SUSPENDED: 403,\n  \n  RATE_LIMIT_EXCEEDED: 429,\n  RATE_CONCURRENT_LIMIT: 429,\n  \n  // 5xx Server Errors\n  SPAWN_FAILED: 500,\n  DRIVER_INIT_FAILED: 500,\n  DRIVER_COMMUNICATION_ERROR: 502,\n  DRIVER_PROTOCOL_ERROR: 502,\n  WS_CONNECTION_FAILED: 502,\n  SYSTEM_UNAVAILABLE: 503,\n  SYSTEM_INTERNAL_ERROR: 500,\n  SYSTEM_RESOURCE_EXHAUSTED: 503,\n};\n```\n\n### AI-Friendly Error Structure\n\n```typescript\ninterface GatewayError {\n  code: ErrorCode;\n  message: string;           // Human-readable message\n  httpStatus: number;\n  \n  // AI Hints - structured guidance for agent recovery\n  aiHint: {\n    severity: 'recoverable' | 'terminal' | 'retry';\n    suggestedAction: string;\n    retryAfterMs?: number;\n    alternativeApproach?: string;\n  };\n  \n  // Context for debugging\n  context?: {\n    agentId?: string;\n    driverId?: string;\n    correlationId?: string;\n    timestamp: string;\n  };\n  \n  // Original error chain for debugging\n  cause?: Error;\n}\n```\n\n### AI Hint Examples\n\n```typescript\nAGENT_NOT_FOUND: {\n  severity: 'terminal',\n  suggestedAction: 'List available agents with GET /agents to find valid agent IDs',\n  alternativeApproach: 'Spawn a new agent if the intended agent was terminated'\n}\n\nRATE_LIMIT_EXCEEDED: {\n  severity: 'retry',\n  suggestedAction: 'Wait for the specified duration before retrying',\n  retryAfterMs: 60000  // Populated dynamically\n}\n\nSPAWN_QUOTA_EXCEEDED: {\n  severity: 'recoverable',\n  suggestedAction: 'Terminate unused agents before spawning new ones',\n  alternativeApproach: 'Request quota increase if more concurrent agents needed'\n}\n```\n\n## File Structure\n\n```\npackages/shared/src/errors/\n├── index.ts                 # Public exports\n├── codes.ts                 # Error code enum and HTTP mappings\n├── factory.ts               # Error creation functions\n├── types.ts                 # TypeScript interfaces\n├── ai-hints.ts              # AI hint definitions per error code\n├── serialization.ts         # JSON serialization/deserialization\n└── __tests__/\n    ├── factory.test.ts\n    └── serialization.test.ts\n```\n\n## References\n\n- PLAN.md §8.5 - Error Response Format\n- PLAN.md §29.2 - AI-Friendly Error Messages\n- RFC 7807 - Problem Details for HTTP APIs (inspiration)\n\n## Acceptance Criteria\n\n- [ ] All error codes defined as TypeScript enum with exhaustive type checking\n- [ ] HTTP status mapping covers all error codes\n- [ ] AI hints defined for all error codes with severity levels\n- [ ] Factory functions create properly structured errors\n- [ ] Errors serialize to JSON matching documented format\n- [ ] Unit tests cover all error codes and edge cases\n- [ ] JSDoc documentation on all public exports\n- [ ] No runtime dependencies beyond TypeScript stdlib\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] GatewayError: constructs with code, message, httpStatus\n- [ ] GatewayError: includes aiHint with severity and suggestion\n- [ ] GatewayError: serializes to JSON correctly\n- [ ] GatewayError: fromCode factory creates correct errors\n- [ ] ErrorCode enum: all codes have unique values\n- [ ] ErrorCode: maps to correct HTTP status codes\n- [ ] AI hints: severity levels (terminal, recoverable, transient)\n- [ ] AI hints: suggestions are actionable strings\n- [ ] Error context: includes correlation ID\n- [ ] Error context: includes timestamp\n- [ ] Error context: optional context data preserved\n- [ ] ValidationError: includes field-level errors\n- [ ] ValidationError: Zod errors mapped correctly\n- [ ] NotFoundError: includes resource type and ID\n- [ ] ConflictError: includes conflicting resources\n- [ ] RateLimitError: includes retry-after\n\n### Integration Tests\n- [ ] API returns 404 with AGENT_NOT_FOUND code\n- [ ] API returns 409 with AGENT_ALREADY_RUNNING code  \n- [ ] API returns 410 with AGENT_TERMINATED code\n- [ ] API returns 400 with INVALID_REQUEST on validation fail\n- [ ] API returns 429 with RATE_LIMITED after threshold\n- [ ] API returns 403 with SAFETY_VIOLATION from SLB\n- [ ] API returns 412 with BYOA_REQUIRED when no accounts\n- [ ] Error response includes correlationId from request header\n- [ ] Error response JSON matches GatewayError schema\n\n### E2E Tests\n- [ ] Agent-consumable: error responses parseable by Claude\n- [ ] AI hints: suggestions lead to successful retry\n- [ ] Error chains: nested errors preserve context\n\n### Contract Tests\n- [ ] All error responses match OpenAPI error schema\n- [ ] Error codes match documented values\n- [ ] HTTP status codes match documented mappings\n\n### Failure Mode Tests\n- [ ] Internal error: 500 with INTERNAL_ERROR, no stack in response\n- [ ] Uncaught exception: wrapped in GatewayError\n- [ ] Database error: mapped to appropriate code\n- [ ] SDK error: mapped to appropriate code with provider hint\n","status":"in_progress","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:32:56.359551298-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:46:20.943038936-05:00","labels":["foundation","phase-1","shared"],"dependencies":[{"issue_id":"flywheel_gateway-ls4","depends_on_id":"flywheel_gateway-hnv","type":"blocks","created_at":"2026-01-08T18:04:07.840251147-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-mag","title":"Performance Optimization","description":"## Background\n\nAs the Flywheel Gateway scales to handle more agents, sessions, and real-time events, performance becomes critical. Users expect instantaneous UI responses, smooth animations, and efficient resource usage. This bead addresses performance at multiple levels: network (WebSocket), rendering (virtualization), bundle size, and computation offloading.\n\n## Reasoning\n\nPerformance directly impacts user experience and system reliability:\n\n1. **WebSocket Backpressure**: Prevents memory exhaustion when server sends data faster than client can process\n2. **Virtualization**: Enables displaying thousands of log lines without DOM bloat\n3. **Bundle Optimization**: Faster initial load times, especially on mobile networks\n4. **Web Workers**: Keeps UI responsive during heavy computations\n5. **CI Budgets**: Prevents performance regressions from reaching production\n\n## Technical Considerations\n\n### WebSocket Backpressure Handling\n\n```typescript\n// apps/web/src/lib/websocket/BackpressureManager.ts\ninterface BackpressureConfig {\n  highWaterMark: number;    // Start applying backpressure (default: 1000 messages)\n  lowWaterMark: number;     // Resume normal flow (default: 100 messages)\n  maxQueueSize: number;     // Drop oldest messages if exceeded (default: 5000)\n  processingInterval: number; // Batch processing interval (default: 16ms)\n}\n\nclass BackpressureManager {\n  private queue: Message[] = [];\n  private isPaused = false;\n  \n  enqueue(message: Message): void {\n    if (this.queue.length \u003e= this.config.maxQueueSize) {\n      // Drop oldest messages, keep newest\n      this.queue = this.queue.slice(-this.config.lowWaterMark);\n      console.warn('WebSocket queue overflow, dropped old messages');\n    }\n    \n    this.queue.push(message);\n    \n    if (this.queue.length \u003e= this.config.highWaterMark \u0026\u0026 !this.isPaused) {\n      this.pause();\n    }\n  }\n  \n  processQueue(): Message[] {\n    const batch = this.queue.splice(0, 100); // Process 100 at a time\n    \n    if (this.queue.length \u003c= this.config.lowWaterMark \u0026\u0026 this.isPaused) {\n      this.resume();\n    }\n    \n    return batch;\n  }\n}\n```\n\n### Output Virtualization with react-window\n\n```typescript\n// apps/web/src/components/VirtualizedOutput.tsx\nimport { VariableSizeList } from 'react-window';\nimport AutoSizer from 'react-virtualized-auto-sizer';\n\ninterface OutputLine {\n  id: string;\n  content: string;\n  timestamp: number;\n  type: 'stdout' | 'stderr' | 'system';\n}\n\nfunction VirtualizedOutput({ lines }: { lines: OutputLine[] }) {\n  const listRef = useRef\u003cVariableSizeList\u003e(null);\n  const rowHeights = useRef\u003cMap\u003cnumber, number\u003e\u003e(new Map());\n  \n  // Dynamic row heights for wrapped text\n  const getRowHeight = (index: number) =\u003e {\n    return rowHeights.current.get(index) || 24; // Default single line height\n  };\n  \n  const setRowHeight = (index: number, height: number) =\u003e {\n    if (rowHeights.current.get(index) !== height) {\n      rowHeights.current.set(index, height);\n      listRef.current?.resetAfterIndex(index);\n    }\n  };\n  \n  return (\n    \u003cAutoSizer\u003e\n      {({ height, width }) =\u003e (\n        \u003cVariableSizeList\n          ref={listRef}\n          height={height}\n          width={width}\n          itemCount={lines.length}\n          itemSize={getRowHeight}\n          overscanCount={20}\n        \u003e\n          {({ index, style }) =\u003e (\n            \u003cOutputRow \n              line={lines[index]} \n              style={style}\n              onHeightChange={(h) =\u003e setRowHeight(index, h)}\n            /\u003e\n          )}\n        \u003c/VariableSizeList\u003e\n      )}\n    \u003c/AutoSizer\u003e\n  );\n}\n```\n\n### Bundle Size Optimization\n\n```typescript\n// vite.config.ts - Code splitting configuration\nexport default defineConfig({\n  build: {\n    rollupOptions: {\n      output: {\n        manualChunks: {\n          // Vendor chunks\n          'vendor-react': ['react', 'react-dom', 'react-router-dom'],\n          'vendor-ui': ['@radix-ui/react-dialog', '@radix-ui/react-dropdown-menu'],\n          'vendor-charts': ['recharts'],\n          'vendor-editor': ['@monaco-editor/react'],\n          \n          // Feature chunks\n          'feature-agents': [\n            './src/pages/agents/AgentList.tsx',\n            './src/pages/agents/AgentDetail.tsx'\n          ],\n          'feature-sessions': [\n            './src/pages/sessions/SessionList.tsx',\n            './src/pages/sessions/SessionDetail.tsx'\n          ]\n        }\n      }\n    },\n    // Tree shaking\n    treeshake: {\n      moduleSideEffects: false,\n      propertyReadSideEffects: false\n    }\n  }\n});\n```\n\n### Image Optimization\n\n```typescript\n// apps/web/src/components/OptimizedImage.tsx\ninterface OptimizedImageProps {\n  src: string;\n  alt: string;\n  width: number;\n  height: number;\n  priority?: boolean;\n}\n\nfunction OptimizedImage({ src, alt, width, height, priority = false }: OptimizedImageProps) {\n  // Generate srcset for responsive images\n  const srcSet = [1, 2, 3].map(scale =\u003e \n    `${src}?w=${width * scale}\u0026format=webp ${scale}x`\n  ).join(', ');\n  \n  return (\n    \u003cpicture\u003e\n      \u003csource srcSet={srcSet} type=\"image/webp\" /\u003e\n      \u003cimg\n        src={src}\n        alt={alt}\n        width={width}\n        height={height}\n        loading={priority ? 'eager' : 'lazy'}\n        decoding={priority ? 'sync' : 'async'}\n      /\u003e\n    \u003c/picture\u003e\n  );\n}\n```\n\n### Lazy Loading Routes\n\n```typescript\n// apps/web/src/routes/index.tsx\nimport { lazy, Suspense } from 'react';\nimport { RouteObject } from 'react-router-dom';\nimport { PageSkeleton } from '@/components/PageSkeleton';\n\n// Lazy load route components\nconst Dashboard = lazy(() =\u003e import('@/pages/Dashboard'));\nconst AgentList = lazy(() =\u003e import('@/pages/agents/AgentList'));\nconst AgentDetail = lazy(() =\u003e import('@/pages/agents/AgentDetail'));\nconst SessionDetail = lazy(() =\u003e import('@/pages/sessions/SessionDetail'));\nconst Settings = lazy(() =\u003e import('@/pages/Settings'));\n\n// Wrapper for lazy components\nconst LazyPage = ({ component: Component }: { component: React.LazyExoticComponent\u003cany\u003e }) =\u003e (\n  \u003cSuspense fallback={\u003cPageSkeleton /\u003e}\u003e\n    \u003cComponent /\u003e\n  \u003c/Suspense\u003e\n);\n\nexport const routes: RouteObject[] = [\n  { path: '/', element: \u003cLazyPage component={Dashboard} /\u003e },\n  { path: '/agents', element: \u003cLazyPage component={AgentList} /\u003e },\n  { path: '/agents/:id', element: \u003cLazyPage component={AgentDetail} /\u003e },\n  // ... etc\n];\n```\n\n### Web Workers for Heavy Computation\n\n```typescript\n// apps/web/src/workers/logParser.worker.ts\nimport { ParsedLog, RawLog } from '@/types/logs';\n\nself.onmessage = (event: MessageEvent\u003cRawLog[]\u003e) =\u003e {\n  const rawLogs = event.data;\n  \n  // Heavy parsing/filtering that would block main thread\n  const parsed: ParsedLog[] = rawLogs.map(log =\u003e ({\n    ...log,\n    parsed: parseAnsiCodes(log.content),\n    searchableText: stripAnsi(log.content).toLowerCase(),\n    timestamp: new Date(log.timestamp),\n    level: detectLogLevel(log.content)\n  }));\n  \n  self.postMessage(parsed);\n};\n\n// apps/web/src/hooks/useLogParser.ts\nexport function useLogParser() {\n  const workerRef = useRef\u003cWorker | null\u003e(null);\n  \n  useEffect(() =\u003e {\n    workerRef.current = new Worker(\n      new URL('../workers/logParser.worker.ts', import.meta.url),\n      { type: 'module' }\n    );\n    \n    return () =\u003e workerRef.current?.terminate();\n  }, []);\n  \n  const parseLogs = useCallback((logs: RawLog[]): Promise\u003cParsedLog[]\u003e =\u003e {\n    return new Promise((resolve) =\u003e {\n      if (!workerRef.current) {\n        // Fallback to main thread if worker unavailable\n        resolve(parseLogsSync(logs));\n        return;\n      }\n      \n      workerRef.current.onmessage = (e) =\u003e resolve(e.data);\n      workerRef.current.postMessage(logs);\n    });\n  }, []);\n  \n  return { parseLogs };\n}\n```\n\n### Performance Budgets in CI\n\n```yaml\n# .github/workflows/performance.yml\nname: Performance Budget Check\n\non: [push, pull_request]\n\njobs:\n  bundle-size:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: oven-sh/setup-bun@v1\n      \n      - name: Install dependencies\n        run: bun install\n        \n      - name: Build\n        run: bun run build\n        \n      - name: Check bundle sizes\n        run: |\n          # Main bundle should be under 200KB gzipped\n          MAIN_SIZE=$(gzip -c dist/assets/index-*.js | wc -c)\n          if [ $MAIN_SIZE -gt 204800 ]; then\n            echo \"Main bundle too large: ${MAIN_SIZE} bytes (max: 200KB)\"\n            exit 1\n          fi\n          \n          # Total JS should be under 500KB gzipped\n          TOTAL_SIZE=$(gzip -c dist/assets/*.js | wc -c)\n          if [ $TOTAL_SIZE -gt 512000 ]; then\n            echo \"Total JS too large: ${TOTAL_SIZE} bytes (max: 500KB)\"\n            exit 1\n          fi\n          \n      - name: Lighthouse CI\n        uses: treosh/lighthouse-ci-action@v10\n        with:\n          configPath: ./lighthouserc.json\n          budgetPath: ./lighthouse-budget.json\n```\n\n```json\n// lighthouse-budget.json\n{\n  \"budget\": [\n    {\n      \"resourceType\": \"script\",\n      \"budget\": 500\n    },\n    {\n      \"resourceType\": \"total\",\n      \"budget\": 1000\n    },\n    {\n      \"timings\": [\n        { \"metric\": \"first-contentful-paint\", \"budget\": 1500 },\n        { \"metric\": \"time-to-interactive\", \"budget\": 3000 },\n        { \"metric\": \"largest-contentful-paint\", \"budget\": 2500 }\n      ]\n    }\n  ]\n}\n```\n\n## File Locations\n\n### WebSocket\n- `apps/web/src/lib/websocket/BackpressureManager.ts` - Backpressure handling\n- `apps/web/src/lib/websocket/MessageQueue.ts` - Queue management\n- `apps/web/src/lib/websocket/FlowControl.ts` - Flow control signals\n\n### Virtualization\n- `apps/web/src/components/VirtualizedOutput.tsx` - Output virtualization\n- `apps/web/src/components/VirtualizedList.tsx` - Generic virtualized list\n- `apps/web/src/components/VirtualizedTable.tsx` - Virtualized data tables\n\n### Bundle \u0026 Loading\n- `apps/web/vite.config.ts` - Build optimization config\n- `apps/web/src/routes/index.tsx` - Lazy route definitions\n- `apps/web/src/components/LazyComponent.tsx` - Lazy loading wrapper\n\n### Workers\n- `apps/web/src/workers/logParser.worker.ts` - Log parsing worker\n- `apps/web/src/workers/search.worker.ts` - Search indexing worker\n- `apps/web/src/hooks/useWorker.ts` - Worker management hook\n\n### CI/Monitoring\n- `.github/workflows/performance.yml` - Performance CI checks\n- `lighthouse-budget.json` - Lighthouse budgets\n- `apps/web/src/lib/performance/monitor.ts` - Runtime performance monitoring\n\n## Acceptance Criteria\n\n### WebSocket Backpressure\n- [ ] Queue size monitored and capped at maxQueueSize\n- [ ] Oldest messages dropped when queue overflows (preserves recent data)\n- [ ] Backpressure signal sent to server when highWaterMark reached\n- [ ] Normal flow resumes at lowWaterMark\n- [ ] No memory leaks under sustained high load\n\n### Virtualization\n- [ ] Smoothly renders 100,000+ log lines\n- [ ] Variable height rows supported (wrapped text)\n- [ ] Scroll position maintained on data updates\n- [ ] Auto-scroll to bottom when following output\n- [ ] Keyboard navigation works in virtualized lists\n\n### Bundle Size\n- [ ] Initial bundle under 200KB gzipped\n- [ ] Total JS under 500KB gzipped\n- [ ] Vendor chunks properly split\n- [ ] No duplicate dependencies in chunks\n- [ ] Source maps generated but not shipped\n\n### Lazy Loading\n- [ ] All routes lazy loaded except shell\n- [ ] Loading skeleton shown during chunk load\n- [ ] Prefetch hints for likely navigation\n- [ ] Error boundary for failed chunk loads\n- [ ] Retry mechanism for network failures\n\n### Web Workers\n- [ ] Log parsing offloaded to worker\n- [ ] Search indexing in worker\n- [ ] Graceful fallback if workers unavailable\n- [ ] Workers terminated on component unmount\n- [ ] No main thread blocking for \u003e50ms\n\n### CI Budgets\n- [ ] Bundle size check fails build if exceeded\n- [ ] Lighthouse scores checked on every PR\n- [ ] Performance regression alerts\n- [ ] Historical performance tracking\n- [ ] Budget configuration in repo\n\n### Runtime Performance\n- [ ] 60fps during normal operation\n- [ ] Input latency under 100ms\n- [ ] Time to Interactive under 3 seconds\n- [ ] First Contentful Paint under 1.5 seconds\n- [ ] Core Web Vitals pass thresholds\n\n## Reference\n\nPLAN.md §22.5 - Performance Optimization\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Backpressure/queueing logic (WS + output) respects configured limits\n- [ ] Virtualized lists render correct ranges and preserve scroll positions\n\n### Integration Tests\n- [ ] High-volume output stream does not crash UI and remains interactive\n\n### Load/Performance Tests\n- [ ] Representative WS + REST concurrency scenario meets defined latency targets\n\n### Logging\n- [ ] Perf tests emit structured summaries (p50/p95, dropped messages, memory) for regression tracking\n","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:57:51.870670119-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:09:26.25282888-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-mag","depends_on_id":"flywheel_gateway-r3p","type":"blocks","created_at":"2026-01-08T14:01:55.357871276-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-mag","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T17:22:55.331208773-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-msz","title":"Conflict Detection and Alerts","description":"## Background\n\nConflict Detection and Alerts provides proactive identification of potential conflicts before they cause problems. While the File Reservation System prevents conflicts through coordination, this system detects conflicts that occur despite reservations or in uncoordinated scenarios.\n\nThree types of conflicts are detected:\n1. **Reservation Overlaps**: Two agents request conflicting file patterns\n2. **Git Conflicts**: Actual merge conflicts in version control\n3. **Resource Contention**: Competition for shared resources (APIs, databases)\n\n## Technical Architecture\n\n### Conflict Types\n```typescript\ntype ConflictType = \n  | 'reservation_overlap'    // Pattern intersection\n  | 'git_merge_conflict'     // Actual file conflict\n  | 'git_potential_conflict' // Same file, different branches\n  | 'resource_contention'    // API rate limits, DB locks\n  | 'deadlock_detected';     // Circular wait condition\n\ninterface Conflict {\n  id: string;\n  type: ConflictType;\n  severity: 'info' | 'warning' | 'error' | 'critical';\n  projectId: string;\n  involvedAgents: string[];\n  affectedResources: string[];  // Files, APIs, etc.\n  detectedAt: Date;\n  resolvedAt?: Date;\n  resolution?: ConflictResolution;\n  metadata: Record\u003cstring, any\u003e;\n}\n```\n\n### Detection Strategies\n\n#### 1. Reservation Overlap Detection\nReal-time detection when reservations are created:\n```typescript\nasync detectReservationOverlap(\n  newReservation: ReservationRequest\n): Promise\u003cOverlapConflict[]\u003e {\n  const activeReservations = await this.getActiveReservations(\n    newReservation.projectId\n  );\n  \n  return activeReservations\n    .filter(r =\u003e r.agentId !== newReservation.agentId)\n    .map(r =\u003e ({\n      existing: r,\n      overlap: this.computeOverlap(r.patterns, newReservation.patterns)\n    }))\n    .filter(r =\u003e r.overlap.length \u003e 0);\n}\n```\n\n#### 2. Git Conflict Detection\nPeriodic and event-driven git status checking:\n```typescript\nasync detectGitConflicts(projectId: string): Promise\u003cGitConflict[]\u003e {\n  const conflicts: GitConflict[] = [];\n  \n  // Check for actual merge conflicts\n  const mergeStatus = await this.git.status();\n  if (mergeStatus.conflicted.length \u003e 0) {\n    conflicts.push({\n      type: 'git_merge_conflict',\n      files: mergeStatus.conflicted,\n      severity: 'critical'\n    });\n  }\n  \n  // Check for potential conflicts (same file modified on different branches)\n  const branches = await this.getActiveBranches(projectId);\n  for (const [b1, b2] of combinations(branches, 2)) {\n    const commonFiles = await this.findCommonModifiedFiles(b1, b2);\n    if (commonFiles.length \u003e 0) {\n      conflicts.push({\n        type: 'git_potential_conflict',\n        files: commonFiles,\n        branches: [b1, b2],\n        severity: 'warning'\n      });\n    }\n  }\n  \n  return conflicts;\n}\n```\n\n#### 3. Resource Contention Detection\nMonitor shared resource access patterns:\n```typescript\ninterface ResourceAccess {\n  resourceId: string;\n  agentId: string;\n  accessType: 'read' | 'write' | 'exclusive';\n  timestamp: Date;\n}\n\nasync detectResourceContention(\n  projectId: string,\n  windowMs: number = 5000\n): Promise\u003cContentionConflict[]\u003e {\n  const recentAccesses = await this.getRecentAccesses(projectId, windowMs);\n  \n  // Group by resource\n  const byResource = groupBy(recentAccesses, 'resourceId');\n  \n  return Object.entries(byResource)\n    .filter(([_, accesses]) =\u003e this.hasContention(accesses))\n    .map(([resourceId, accesses]) =\u003e ({\n      type: 'resource_contention',\n      resourceId,\n      involvedAgents: unique(accesses.map(a =\u003e a.agentId)),\n      severity: 'warning'\n    }));\n}\n```\n\n### Alert System\n\n#### Alert Configuration\n```typescript\ninterface AlertConfig {\n  channels: AlertChannel[];  // websocket, email, slack, webhook\n  thresholds: {\n    [K in ConflictType]: {\n      minSeverity: Severity;\n      cooldownMs: number;    // Prevent alert spam\n    };\n  };\n  escalation: {\n    afterMs: number;\n    escalateTo: AlertChannel[];\n  };\n}\n```\n\n#### WebSocket Events\n```typescript\n// Emitted events\n'conflict:detected'     // New conflict found\n'conflict:updated'      // Conflict status changed\n'conflict:resolved'     // Conflict resolved\n'conflict:escalated'    // Conflict escalated\n\n// Event payload\ninterface ConflictEvent {\n  eventType: string;\n  conflict: Conflict;\n  timestamp: Date;\n  recommendedActions: Action[];\n}\n```\n\n### Recommended Actions\nSystem suggests resolutions based on conflict type:\n```typescript\nfunction getRecommendedActions(conflict: Conflict): Action[] {\n  switch (conflict.type) {\n    case 'reservation_overlap':\n      return [\n        { action: 'wait', description: 'Wait for existing reservation to expire' },\n        { action: 'negotiate', description: 'Request partial pattern release' },\n        { action: 'force', description: 'Override (requires admin)' }\n      ];\n    \n    case 'git_merge_conflict':\n      return [\n        { action: 'manual_resolve', description: 'Human intervention required' },\n        { action: 'abort_merge', description: 'Abort and retry later' },\n        { action: 'accept_ours', description: 'Keep current branch changes' },\n        { action: 'accept_theirs', description: 'Accept incoming changes' }\n      ];\n    \n    case 'resource_contention':\n      return [\n        { action: 'queue', description: 'Queue request for later' },\n        { action: 'retry_backoff', description: 'Retry with exponential backoff' },\n        { action: 'alternative', description: 'Use alternative resource' }\n      ];\n    \n    default:\n      return [{ action: 'investigate', description: 'Manual investigation needed' }];\n  }\n}\n```\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `apps/gateway/src/services/conflict.service.ts` | Core conflict detection |\n| `apps/gateway/src/services/conflict.types.ts` | TypeScript interfaces |\n| `apps/gateway/src/services/git-conflict-detector.ts` | Git-specific detection |\n| `apps/gateway/src/services/contention-detector.ts` | Resource contention |\n| `apps/gateway/src/services/alert.service.ts` | Alert dispatching |\n| `apps/gateway/src/websocket/conflict.gateway.ts` | WebSocket handlers |\n| `apps/gateway/src/controllers/conflict.controller.ts` | REST API |\n| `apps/web/src/components/ConflictPanel.tsx` | UI component |\n| `apps/gateway/src/__tests__/conflict.service.test.ts` | Unit tests |\n\n## Acceptance Criteria\n\n- [ ] Detect reservation overlap conflicts in real-time\n- [ ] Detect actual git merge conflicts\n- [ ] Detect potential git conflicts (same file, different branches)\n- [ ] Detect resource contention patterns\n- [ ] Severity classification (info, warning, error, critical)\n- [ ] WebSocket events for all conflict lifecycle stages\n- [ ] Recommended actions for each conflict type\n- [ ] Alert cooldown to prevent spam\n- [ ] Escalation after configurable timeout\n- [ ] REST API for conflict listing and management\n- [ ] Conflict resolution tracking\n- [ ] \u003e90% test coverage\n- [ ] Performance: \u003c100ms detection latency\n\n## WebSocket Event Examples\n\n```typescript\n// Client subscription\nsocket.emit('subscribe', { \n  channel: 'conflicts',\n  projectId: 'project-123'\n});\n\n// Server events\nsocket.on('conflict:detected', (event) =\u003e {\n  console.log('New ' + event.conflict.type + ' conflict detected');\n  console.log('Severity: ' + event.conflict.severity);\n  console.log('Agents involved: ' + event.conflict.involvedAgents.join(', '));\n  console.log('Recommended: ' + event.recommendedActions[0].description);\n});\n\nsocket.on('conflict:resolved', (event) =\u003e {\n  console.log('Conflict ' + event.conflict.id + ' resolved');\n  console.log('Resolution: ' + event.conflict.resolution.method);\n});\n```\n\n## References\n\n- PLAN.md Section 12: Conflict Management\n\n## Dependencies\n\n- `simple-git` - Git operations\n- `socket.io` - WebSocket support\n- `ioredis` - Distributed state\n- `node-cron` - Periodic detection jobs\n\n## Integration Points\n\n1. **Reservation Service**: Receives overlap notifications\n2. **Git Service**: Monitors repository state\n3. **Agent Mail**: Notifies agents of conflicts\n4. **UI Dashboard**: Displays conflict status\n\n## Monitoring Metrics\n\n- `conflicts_detected_total` (counter, by type)\n- `conflict_resolution_time_seconds` (histogram)\n- `active_conflicts` (gauge, by severity)\n- `alert_sent_total` (counter, by channel)\n- `detection_latency_ms` (histogram)\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Conflict detection identifies overlapping file edits and resolves glob matching deterministically\n- [ ] Alert severity and deduping rules prevent repeated spam for the same conflict\n\n### Integration Tests\n- [ ] Simulate overlapping reservations/edits → conflict event emitted over WS and surfaced via REST\n\n### Failure Mode Tests\n- [ ] Conflicts during Agent Mail outage fall back to best-effort local detection with clear warnings\n\n### Logging\n- [ ] Logs include correlationId + conflictId + involvedAgents + filePaths (sanitized) + resolution state\n","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:38:37.331795875-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:09:38.217716372-05:00","dependencies":[{"issue_id":"flywheel_gateway-msz","depends_on_id":"flywheel_gateway-5nm","type":"blocks","created_at":"2026-01-08T14:01:47.989382352-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-o54","title":"ACP Agent Driver","description":"## Background\n\nThe Agent Client Protocol (ACP) driver enables Flywheel Gateway to communicate with external agent processes over JSON-RPC 2.0. Unlike the SDK driver which embeds agent logic directly, the ACP driver treats agents as separate processes that communicate via a standardized protocol.\n\nThis separation provides several critical benefits:\n- Language independence: agents can be written in Python, Rust, Go, etc.\n- Process isolation: agent crashes don't affect the gateway\n- Scalability: agents can run on different machines\n- Development flexibility: agents can be developed and tested independently\n\n## Technical Architecture\n\n### Protocol Design\n- **Transport**: Bidirectional JSON-RPC 2.0 over WebSocket or stdio\n- **Message Types**: Request, Response, Notification\n- **Serialization**: JSON with optional MessagePack for performance\n- **Framing**: Length-prefixed messages for stdio, native WebSocket frames\n\n### Core Methods\n```typescript\n// Gateway -\u003e Agent\nagent.initialize(config: AgentConfig): Promise\u003cvoid\u003e\nagent.executeTask(task: Task): Promise\u003cTaskResult\u003e\nagent.handleMessage(message: AgentMessage): Promise\u003cvoid\u003e\nagent.shutdown(): Promise\u003cvoid\u003e\n\n// Agent -\u003e Gateway (notifications)\ngateway.taskProgress(taskId: string, progress: Progress): void\ngateway.requestTool(toolName: string, params: any): Promise\u003cany\u003e\ngateway.logEvent(event: LogEvent): void\n```\n\n### Connection Lifecycle\n1. Gateway spawns agent process or accepts incoming connection\n2. Handshake with capability negotiation\n3. Agent registers available tools and capabilities\n4. Gateway sends tasks, agent responds\n5. Graceful shutdown with pending task completion\n\n## Implementation Details\n\n### AgentDriver Interface Compliance\nThe ACP driver MUST implement the same `AgentDriver` interface as the SDK driver:\n\n```typescript\ninterface AgentDriver {\n  id: string;\n  name: string;\n  capabilities: DriverCapabilities;\n  \n  connect(): Promise\u003cvoid\u003e;\n  disconnect(): Promise\u003cvoid\u003e;\n  isConnected(): boolean;\n  \n  executeTask(task: Task): Promise\u003cTaskResult\u003e;\n  cancelTask(taskId: string): Promise\u003cvoid\u003e;\n  \n  on(event: DriverEvent, handler: EventHandler): void;\n  off(event: DriverEvent, handler: EventHandler): void;\n}\n```\n\n### Error Handling Strategy\n- Connection errors: exponential backoff with jitter (100ms to 30s)\n- Task timeout: configurable per-task with default 5 minutes\n- Protocol errors: log, notify, attempt recovery\n- Process crashes: detect via exit codes, restart with backoff\n\n### Connection Management\n- Connection pool for multiple agent instances\n- Health checks via ping/pong every 30 seconds\n- Automatic reconnection on disconnect\n- Graceful drain on shutdown\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `packages/agent-drivers/src/acp/index.ts` | Public exports |\n| `packages/agent-drivers/src/acp/acp-driver.ts` | Main driver implementation |\n| `packages/agent-drivers/src/acp/protocol.ts` | JSON-RPC message types and serialization |\n| `packages/agent-drivers/src/acp/connection.ts` | WebSocket/stdio connection handling |\n| `packages/agent-drivers/src/acp/pool.ts` | Connection pool management |\n| `packages/agent-drivers/src/acp/errors.ts` | ACP-specific error classes |\n| `packages/agent-drivers/src/acp/__tests__/` | Unit and integration tests |\n\n## Acceptance Criteria\n\n- [ ] Implements AgentDriver interface identically to SDK driver\n- [ ] Supports both WebSocket and stdio transports\n- [ ] JSON-RPC 2.0 compliant message handling\n- [ ] Connection pool with configurable size (default: 5)\n- [ ] Automatic reconnection with exponential backoff\n- [ ] Health check mechanism with configurable interval\n- [ ] Graceful shutdown drains pending tasks\n- [ ] Comprehensive error handling with typed errors\n- [ ] \u003e90% test coverage for protocol handling\n- [ ] Integration test with mock agent process\n- [ ] Performance: \u003c10ms overhead per message\n\n## References\n\n- PLAN.md Section 5: Agent Driver Architecture\n- PLAN.md Section 6: Protocol Specifications\n- JSON-RPC 2.0 Specification: https://www.jsonrpc.org/specification\n\n## Dependencies\n\n- `ws` - WebSocket client/server\n- `uuid` - Request ID generation\n- Shared types from `@flywheel/types`\n\n## Security Considerations\n\n- Validate all incoming JSON-RPC messages\n- Limit message size (default: 10MB)\n- Rate limit requests per connection\n- Authentication via shared secret in handshake\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] ACP JSON-RPC request/response parsing validates schema and handles out-of-order responses\n- [ ] Event stream parsing handles tool_call/tool_result/text_delta and preserves ordering\n- [ ] Reconnect/resume logic handles transient disconnects without duplicating events\n\n### Integration Tests\n- [ ] Use a stub ACP agent to run a short session and verify output streaming + interrupts\n\n### Failure Mode Tests\n- [ ] Protocol errors/timeouts map to driver error codes and do not crash the gateway\n\n### Logging\n- [ ] Logs include correlationId + agentId + acpRequestId + method; redact any payloads with secrets\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] ACPDriver.spawn: launches process with correct args\n- [ ] ACPDriver.spawn: establishes stdio JSON-RPC connection\n- [ ] ACPDriver.send: formats JSON-RPC request correctly\n- [ ] ACPDriver.send: parses JSON-RPC response\n- [ ] ACPDriver.interrupt: sends interrupt notification\n- [ ] ACPDriver.terminate: sends terminate and waits\n- [ ] ACPDriver.getOutput: returns buffered output\n- [ ] JSON-RPC: request ID incrementing\n- [ ] JSON-RPC: error response parsing\n- [ ] JSON-RPC: notification handling (no response expected)\n- [ ] State machine: all transitions valid\n- [ ] Protocol negotiation: version check\n- [ ] Protocol negotiation: capability exchange\n- [ ] Adapter: Claude Code mapped correctly\n- [ ] Adapter: Codex mapped correctly\n- [ ] Adapter: Gemini mapped correctly\n\n### Integration Tests\n- [ ] Spawn Claude Code via ACP\n- [ ] Send message and receive response\n- [ ] Streaming events received\n- [ ] Interrupt running command\n- [ ] Graceful termination\n- [ ] Process crash detection\n- [ ] Protocol error handling\n- [ ] Reconnection after disconnect\n\n### E2E Tests\n- [ ] Full agent lifecycle via ACP\n- [ ] Multiple ACP agents concurrently\n- [ ] Mixed SDK and ACP agents\n- [ ] IDE-style interaction pattern\n\n### Performance Tests\n- [ ] Spawn time \u003c3s for ACP agent\n- [ ] Message round-trip \u003c200ms\n- [ ] Streaming latency \u003c100ms\n- [ ] Memory per agent \u003c150MB\n\n### Failure Mode Tests\n- [ ] Invalid JSON-RPC: error response\n- [ ] Process crash: agent terminated with error\n- [ ] Protocol version mismatch: clear error\n- [ ] Timeout on response: retry or fail\n- [ ] Stdio buffer overflow: handled","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:38:36.810068822-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:09:50.722443454-05:00","dependencies":[{"issue_id":"flywheel_gateway-o54","depends_on_id":"flywheel_gateway-w55","type":"blocks","created_at":"2026-01-08T14:01:43.521828371-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-ogy","title":"EPIC: Phase 4 - Production Ready","description":"## Overview\nPhase 4 polishes the system for production deployment with advanced analytics, comprehensive observability, performance optimization, and thorough testing.\n\n## Phase 4 Goal\nPolish, performance, reliability, and advanced analytics\n\n## Key Deliverables\n\n### Observability\n- Metrics and alerts system\n  - OpenTelemetry integration\n  - Prometheus metrics export\n  - Grafana dashboards\n  - Alert rules and notification routing\n\n### Analytics Dashboards\n- Agent Performance Analytics\n  - Model comparison (Claude vs Codex vs Gemini)\n  - Productivity trends over time\n  - Token usage patterns\n  - Success/failure rates\n  - AI-powered recommendations\n- Cost Analytics \u0026 Optimization\n  - Budget tracking per team/project\n  - Forecasting based on trends\n  - Cost optimization suggestions\n  - Token usage breakdown\n- Flywheel Velocity Dashboard\n  - Ecosystem health metrics\n  - Learning rate tracking\n  - Cross-repo activity\n  - Bottleneck identification\n- Custom Dashboard Builder\n  - Drag-and-drop widget placement\n  - Personalized views per user\n  - Saved layouts\n  - Widget gallery\n\n### Notifications\n- Comprehensive Notification System\n  - Multi-channel delivery (email, Slack, webhooks)\n  - User preferences management\n  - Smart digests\n  - Notification batching\n  - Do-not-disturb schedules\n\n### Reliability\n- Audit trail hardening\n  - Tamper-evident logging\n  - Exportable audit reports\n  - Configurable retention\n  - Full-text search\n- Pipeline engine\n  - Multi-step workflows\n  - Conditional execution\n  - Retry policies\n  - Pipeline templates\n\n### User Experience\n- Mobile optimization\n  - Responsive design\n  - Touch-friendly interactions\n  - Progressive Web App (PWA)\n  - Offline mode for viewing\n\n### Performance\n- Performance optimization\n  - WebSocket backpressure handling\n  - Output virtualization for long streams\n  - Database query optimization\n  - Caching strategies\n\n### Quality Assurance\n- Comprehensive testing\n  - Unit tests (\u003e80% coverage)\n  - Integration tests\n  - Contract tests (OpenAPI)\n  - E2E tests (Playwright)\n  - Load tests (k6)\n  - Visual regression tests\n\n### Documentation\n- Complete documentation\n  - API reference (from OpenAPI)\n  - User guides\n  - Developer guides\n  - Deployment guides\n  - Runbooks\n\n## Phase Completion Criteria\n- [ ] OpenTelemetry metrics exported to Prometheus\n- [ ] Grafana dashboards configured and working\n- [ ] Agent Performance Analytics shows model comparison\n- [ ] Cost Analytics tracks and forecasts usage\n- [ ] Velocity Dashboard shows ecosystem health\n- [ ] Custom dashboards can be created and saved\n- [ ] Notifications delivered via all channels\n- [ ] Audit exports generate compliance reports\n- [ ] Pipeline engine runs multi-step workflows\n- [ ] Mobile UI is fully functional\n- [ ] All performance targets met (see non-functional requirements)\n- [ ] All test suites passing in CI\n- [ ] Documentation complete and published\n\n## Testing Requirements\n- Full test coverage at all levels\n- Load testing passes all performance targets\n- Security audit completed\n- Accessibility audit (WCAG AA)\n- Cross-browser testing (Chrome, Firefox, Safari, Edge)\n- Mobile device testing (iOS, Android)\n\n\n## Success Criteria\n\n- [ ] Observability complete: metrics + alerts + dashboards + durable audit export with redaction\n- [ ] Performance targets met for core paths (WS backpressure, output virtualization, query latency)\n- [ ] Mobile UX and accessibility targets met for critical workflows\n- [ ] Pipeline engine production-ready: validate/execute/resume workflows with approvals and rich diagnostics\n- [ ] Test suite is comprehensive and automated (unit + integration + contract + E2E + load) with artifact capture and structured test logging per `flywheel_gateway-d8b`\n\n","notes":"## Constituent Beads\n\nThis EPIC encompasses the following beads:\n\n### Observability \u0026 Analytics\n- flywheel_gateway-f9d: Metrics and Alerts System [P2]\n- flywheel_gateway-6wp: Agent Performance Analytics [P2]\n- flywheel_gateway-rgx: Cost Analytics and Optimization [P2]\n- flywheel_gateway-66n: Flywheel Velocity Dashboard [P2]\n- flywheel_gateway-i6c: Custom Dashboard Builder [P2]\n\n### Notifications\n- flywheel_gateway-59c: Comprehensive Notification System [P2]\n\n### Security \u0026 Compliance\n- flywheel_gateway-7ek: Audit Trail Hardening [P2]\n\n### Advanced Features\n- flywheel_gateway-6ld: Pipeline Engine [P2]\n- flywheel_gateway-0wr: Mobile Optimization [P2]\n\n### Performance \u0026 Quality\n- flywheel_gateway-mag: Performance Optimization [P2]\n- flywheel_gateway-tz4: Comprehensive Testing Suite [P2]\n\n### Documentation\n- flywheel_gateway-35p: Documentation [P2]\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-08T13:50:20.267179998-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:31:27.725675631-05:00","dependencies":[{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-f8f","type":"blocks","created_at":"2026-01-08T14:01:42.858324628-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T18:23:02.712471401-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-6wp","type":"blocks","created_at":"2026-01-08T18:23:07.745743709-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-rgx","type":"blocks","created_at":"2026-01-08T18:23:12.779258113-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-66n","type":"blocks","created_at":"2026-01-08T18:23:17.811241302-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-i6c","type":"blocks","created_at":"2026-01-08T18:23:22.845498696-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-59c","type":"blocks","created_at":"2026-01-08T18:23:27.87833924-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-7ek","type":"blocks","created_at":"2026-01-08T18:23:32.910986781-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-6ld","type":"blocks","created_at":"2026-01-08T18:23:37.94418537-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-0wr","type":"blocks","created_at":"2026-01-08T18:23:42.977816143-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-mag","type":"blocks","created_at":"2026-01-08T18:23:48.010994234-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-tz4","type":"blocks","created_at":"2026-01-08T18:23:53.04421281-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-ogy","depends_on_id":"flywheel_gateway-35p","type":"blocks","created_at":"2026-01-08T18:23:58.07666854-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-p0l","title":"FEAT: SLB Safety Guardrails","description":"## Overview\n\nConfigurable safety limits and approval workflows for the Session Lock Broker (SLB). Safety Guardrails provide multi-layered protection against runaway agents, resource abuse, and potentially dangerous operations through declarative rules, rate limiting, and human-in-the-loop approval workflows.\n\n## Background \u0026 Reasoning\n\nAutonomous agents operating with tool access pose inherent risks:\n\n- **Runaway Agents**: An agent stuck in a loop can consume unlimited resources or make endless API calls\n- **Resource Abuse**: Without limits, agents can exhaust disk space, network bandwidth, or compute time\n- **Dangerous Operations**: Some operations (forced pushes, recursive deletion, production deployments) require human oversight\n- **Cost Overruns**: LLM token usage and external API calls can generate unexpected expenses\n- **Data Exfiltration**: Agents with network access could potentially leak sensitive information\n\nSafety Guardrails transform these risks into manageable, auditable controls with clear escalation paths.\n\n## Technical Architecture\n\n### Safety Categories\n\n| Category | Scope | Examples |\n|----------|-------|----------|\n| `filesystem` | File and directory operations | Path restrictions, write limits, deletion controls |\n| `git` | Version control operations | Branch protections, forced push blocking, commit limits |\n| `network` | External communication | URL allowlists, request rate limits, data transfer caps |\n| `execution` | Command and script execution | Command blocking, timeout enforcement, process limits |\n| `resources` | System resource usage | Memory caps, CPU limits, disk quotas |\n| `content` | Generated content validation | PII detection, secret scanning, policy compliance |\n\n### Path Allowlists and Denylists\n\n```typescript\ninterface PathRule {\n  pattern: string;      // Glob pattern (e.g., '/workspace/**', '!**/node_modules/**')\n  action: 'allow' | 'deny';\n  operations: ('read' | 'write' | 'delete' | 'execute')[];\n  reason?: string;      // Displayed to agent when blocked\n}\n\n// Evaluation order: deny rules checked first, then allow rules\n// Default: deny if no matching allow rule\n```\n\n### Command Blocking Rules\n\n```typescript\ninterface CommandRule {\n  pattern: string;           // Regex pattern for command matching\n  severity: 'block' | 'warn' | 'approve';\n  category: SafetyCategory;\n  reason: string;\n  alternatives?: string[];   // Suggested safer alternatives\n}\n\n// Example rules:\n// - block: recursive forced deletion from root\n// - approve: forced git push (requires approval)\n// - warn: piping curl output to shell\n```\n\n### Rate Limiting\n\n```typescript\ninterface RateLimitConfig {\n  scope: 'agent' | 'workspace' | 'session';\n  limits: {\n    tokensPerMinute: number;\n    requestsPerMinute: number;\n    fileWritesPerMinute: number;\n    networkRequestsPerMinute: number;\n    commandsPerMinute: number;\n  };\n  burstAllowance: number;    // Percentage above limit for short bursts\n  cooldownSeconds: number;   // Wait time after limit exceeded\n}\n```\n\n### Approval Queue\n\n```typescript\ninterface ApprovalRequest {\n  id: string;\n  agentId: string;\n  sessionId: string;\n  operation: {\n    type: SafetyCategory;\n    command?: string;\n    path?: string;\n    description: string;\n  };\n  rule: SafetyRule;          // Rule that triggered approval\n  context: {\n    recentActions: Action[]; // Last 10 agent actions for context\n    taskDescription?: string;\n  };\n  status: 'pending' | 'approved' | 'denied' | 'expired';\n  requestedAt: Date;\n  expiresAt: Date;           // Auto-deny after timeout\n  decidedBy?: string;        // User who approved/denied\n  decidedAt?: Date;\n  decisionReason?: string;\n}\n```\n\n### Cost Limits and Budget Enforcement\n\n```typescript\ninterface BudgetConfig {\n  scope: 'agent' | 'workspace' | 'session';\n  limits: {\n    totalTokens: number;\n    totalDollars: number;\n    perRequestDollars: number;\n  };\n  alertThresholds: number[]; // e.g., [0.5, 0.8, 0.95] for 50%, 80%, 95%\n  action: 'warn' | 'pause' | 'terminate';\n}\n```\n\n## Key Interfaces\n\n```typescript\ninterface SafetyConfig {\n  id: string;\n  workspaceId: string;\n  name: string;\n  description?: string;\n  enabled: boolean;\n  categories: {\n    [K in SafetyCategory]: {\n      enabled: boolean;\n      rules: SafetyRule[];\n    };\n  };\n  rateLimits: RateLimitConfig;\n  budget: BudgetConfig;\n  approvalWorkflow: {\n    enabled: boolean;\n    approvers: string[];      // User IDs who can approve\n    timeoutMinutes: number;\n    defaultAction: 'deny' | 'allow';\n  };\n}\n\ninterface SafetyRule {\n  id: string;\n  name: string;\n  description: string;\n  category: SafetyCategory;\n  condition: RuleCondition;   // Pattern matching logic\n  action: 'allow' | 'deny' | 'warn' | 'approve';\n  severity: 'low' | 'medium' | 'high' | 'critical';\n  message: string;            // Shown to agent/user\n  enabled: boolean;\n}\n\ninterface SafetyViolation {\n  id: string;\n  timestamp: Date;\n  agentId: string;\n  sessionId: string;\n  rule: SafetyRule;\n  operation: {\n    type: string;\n    details: Record\u003cstring, unknown\u003e;\n  };\n  action: 'blocked' | 'warned' | 'pending_approval';\n  context: {\n    taskDescription?: string;\n    recentHistory: string[];\n  };\n}\n```\n\n## File Locations\n\n| Component | Path |\n|-----------|------|\n| Safety service | `apps/gateway/src/services/safety.service.ts` |\n| Safety rules engine | `apps/gateway/src/services/safety-rules.engine.ts` |\n| Rate limiter | `apps/gateway/src/services/rate-limiter.service.ts` |\n| Approval service | `apps/gateway/src/services/approval.service.ts` |\n| Safety config API | `apps/gateway/src/routes/safety.routes.ts` |\n| Safety config UI | `apps/web/src/components/safety/SafetyConfigEditor.tsx` |\n| Approval queue UI | `apps/web/src/components/safety/ApprovalQueue.tsx` |\n| Violation log UI | `apps/web/src/components/safety/ViolationLog.tsx` |\n| Safety tests | `apps/gateway/src/services/__tests__/safety.*.test.ts` |\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] Rule matching engine correctly evaluates glob patterns\n- [ ] Rule matching engine correctly evaluates regex patterns\n- [ ] Rule precedence (deny before allow) works correctly\n- [ ] Rate limiter tracks counts per scope accurately\n- [ ] Rate limiter resets after cooldown period\n- [ ] Budget calculations handle currency precision\n- [ ] Approval expiration triggers correct action\n\n### Integration Tests\n- [ ] Approval workflow sends notifications to approvers\n- [ ] Approved operations execute successfully\n- [ ] Denied operations return appropriate error to agent\n- [ ] Rate limit exceeded pauses agent correctly\n- [ ] Budget alert triggers at configured thresholds\n- [ ] Config changes apply to active sessions\n\n### E2E Tests\n- [ ] Blocked command shows user-friendly error message\n- [ ] Approval request appears in queue within 1 second\n- [ ] Approver can approve/deny from queue UI\n- [ ] Agent receives approval result and continues\n- [ ] Violation log shows all blocked operations\n- [ ] Safety config changes persist across restarts\n\n### Security Tests\n- [ ] Path traversal attempts blocked (../../etc/passwd)\n- [ ] Glob pattern injection prevented\n- [ ] Regex ReDoS patterns detected and rejected\n- [ ] Approval bypass attempts logged and blocked\n- [ ] Rate limit bypass attempts (clock manipulation) fail\n- [ ] Budget manipulation attempts fail\n\n## Logging Requirements\n\n### Safety Decisions\n```typescript\nlogger.info('safety.decision', {\n  agentId,\n  operation,\n  rule: rule.id,\n  action: 'blocked' | 'allowed' | 'pending',\n  reason: rule.message,\n  context: { taskDescription, recentActions }\n});\n```\n\n### Approval Audit Trail\n```typescript\nlogger.info('safety.approval.requested', { requestId, agentId, operation });\nlogger.info('safety.approval.decided', { \n  requestId, \n  decision: 'approved' | 'denied',\n  decidedBy,\n  reason \n});\nlogger.warn('safety.approval.expired', { requestId, operation });\n```\n\n### Violation Metrics\n```typescript\n// Emitted for dashboards and alerting\nmetrics.increment('safety.violations', { \n  category, \n  severity, \n  action,\n  workspaceId \n});\nmetrics.gauge('safety.approval_queue_depth', queueSize, { workspaceId });\nmetrics.histogram('safety.approval_latency', latencyMs, { decision });\n```\n\n## Acceptance Criteria\n\n- [ ] Default safety config blocks known dangerous operations\n- [ ] Custom rules can be added via UI without code changes\n- [ ] Path allowlist/denylist supports standard glob patterns\n- [ ] Rate limiting pauses agent without losing context\n- [ ] Budget alerts notify workspace admins at thresholds\n- [ ] Approval queue shows pending requests with full context\n- [ ] Approvals complete within configured timeout\n- [ ] All safety decisions logged with complete audit trail\n- [ ] Violation dashboard shows trends and top blocked operations\n- [ ] Safety config can be exported/imported for environment parity\n- [ ] Emergency kill switch terminates agent immediately\n- [ ] Safety rules evaluated in \u003c 5ms per operation\n\n## Reference\n\nPLAN.md §17 - SLB Safety Guardrails\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] PreFlightCheck: runs all validators\n- [ ] PreFlightCheck: aggregates results\n- [ ] Validator: file pattern matcher\n- [ ] Validator: command pattern matcher\n- [ ] Validator: resource limit checker\n- [ ] ApprovalWorkflow: creates approval request\n- [ ] ApprovalWorkflow: routes to correct approver\n- [ ] ApprovalWorkflow: enforces timeout\n- [ ] Escalation: triggers on repeated blocks\n- [ ] Escalation: notifies appropriate party\n- [ ] Policy: parses rule definitions\n- [ ] Policy: evaluates conditions\n\n### Integration Tests\n- [ ] Dangerous command triggers pre-flight\n- [ ] Pre-flight failure blocks execution\n- [ ] Approval request created for risky ops\n- [ ] Approved request allows execution\n- [ ] Denied request blocks execution\n- [ ] Timeout denies request\n- [ ] Escalation alerts sent\n\n### E2E Tests\n- [ ] Agent blocked by SLB shows reason\n- [ ] User approves in UI\n- [ ] Agent continues after approval\n- [ ] Audit shows SLB interactions\n\n### Performance Tests\n- [ ] Pre-flight check \u003c50ms\n- [ ] Approval routing \u003c100ms\n- [ ] Policy evaluation \u003c10ms\n- [ ] Many concurrent checks scale\n\n### Failure Mode Tests\n- [ ] SLB service unavailable: fail-closed\n- [ ] Invalid policy: startup error\n- [ ] Circular escalation: detected\n- [ ] Approver unavailable: escalate","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:48:15.850431776-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:56:21.627692867-05:00","dependencies":[{"issue_id":"flywheel_gateway-p0l","depends_on_id":"flywheel_gateway-41h","type":"blocks","created_at":"2026-01-08T14:02:00.315942206-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-p8j","title":"FEAT: Beads/BV Integration","description":"## Background\n\nThe Beads Viewer (BV) is the central intelligence layer of the Flywheel ecosystem, managing the dependency graph of all work items (beads). This integration enables Flywheel Gateway to leverage BV's graph-aware capabilities for intelligent work prioritization and bottleneck detection.\n\n## Reasoning\n\nCurrent task management systems treat work items as independent entities, leading to:\n- Developers picking up blocked work they cannot complete\n- Critical path items languishing while non-blocking work proceeds\n- No visibility into which completions would unblock the most downstream work\n- Manual effort to determine work dependencies\n\nBV solves this by maintaining a directed acyclic graph (DAG) of beads and their dependencies, enabling queries like \"what can I work on right now?\" and \"what's blocking the most work?\"\n\n## Technical Considerations\n\n### Client Architecture\n- Use flywheel-clients package pattern for consistency\n- Implement retry logic with exponential backoff\n- Cache dependency graph locally with invalidation strategy\n- Support both REST and potential WebSocket for real-time updates\n\n### API Design\n```typescript\ninterface BVClient {\n  // CRUD Operations\n  createBead(bead: BeadCreate): Promise\u003cBead\u003e;\n  getBead(id: string): Promise\u003cBead\u003e;\n  updateBead(id: string, updates: BeadUpdate): Promise\u003cBead\u003e;\n  deleteBead(id: string): Promise\u003cvoid\u003e;\n  \n  // Triage Operations\n  getReadyBeads(filters?: TriageFilters): Promise\u003cBead[]\u003e;\n  getBlockedBeads(filters?: TriageFilters): Promise\u003cBlockedBead[]\u003e;\n  triageWork(context: TriageContext): Promise\u003cPrioritizedWork\u003e;\n  \n  // Insights\n  getBottlenecks(limit?: number): Promise\u003cBottleneck[]\u003e;\n  getKeystones(limit?: number): Promise\u003cKeystone[]\u003e;\n  getDependencyGraph(rootId?: string): Promise\u003cDependencyGraph\u003e;\n  \n  // Dependency Management\n  addDependency(beadId: string, dependsOn: string): Promise\u003cvoid\u003e;\n  removeDependency(beadId: string, dependsOn: string): Promise\u003cvoid\u003e;\n  getBloeckers(beadId: string): Promise\u003cBead[]\u003e;\n  getDependents(beadId: string): Promise\u003cBead[]\u003e;\n}\n```\n\n### Galaxy View (Dependency Visualization)\nThe Galaxy View renders the dependency graph as an interactive visualization:\n- Nodes represent beads, sized by downstream impact\n- Edges show dependency relationships\n- Color coding: ready (green), blocked (red), in-progress (yellow)\n- Zoom/pan for large graphs\n- Click to drill into bead details\n- Filter by project, tag, assignee\n\n### Performance Requirements\n- Triage queries must return in \u003c100ms for responsive UI\n- Graph rendering must handle 1000+ nodes smoothly\n- Use WebGL (via react-force-graph or similar) for large graphs\n\n## Acceptance Criteria\n\n1. **BV Client Implementation**\n   - [ ] BVClient class with full TypeScript typing\n   - [ ] All CRUD operations functional\n   - [ ] Error handling with typed exceptions\n   - [ ] Request/response logging for debugging\n   - [ ] Unit tests with \u003e80% coverage\n\n2. **Triage API Integration**\n   - [ ] getReadyBeads returns beads with no unresolved blockers\n   - [ ] getBlockedBeads includes blocker information\n   - [ ] triageWork returns prioritized list considering:\n     - User skills/preferences\n     - Bead priority\n     - Downstream impact (keystone score)\n     - Time estimates\n\n3. **Insights API Integration**\n   - [ ] Bottleneck detection working (beads blocking most downstream work)\n   - [ ] Keystone identification (highest-impact completions)\n   - [ ] Metrics include: blocked count, estimated unblock value\n\n4. **Dependency Management**\n   - [ ] Add/remove dependencies with cycle detection\n   - [ ] Bulk dependency operations\n   - [ ] Dependency validation (no self-references, no cycles)\n\n5. **Galaxy View Component**\n   - [ ] Interactive graph rendering\n   - [ ] Node click shows bead details sidebar\n   - [ ] Filter controls (status, project, assignee)\n   - [ ] Legend explaining visual encoding\n   - [ ] Export graph as image/SVG\n   - [ ] Responsive design for different screen sizes\n\n6. **Integration Tests**\n   - [ ] End-to-end flow: create bead -\u003e add dependency -\u003e triage -\u003e complete\n   - [ ] Graph updates reflect in Galaxy View within 2 seconds\n\n## File Locations\n\n### Client Package\n- `packages/flywheel-clients/src/bv/index.ts` - Main exports\n- `packages/flywheel-clients/src/bv/client.ts` - BVClient implementation\n- `packages/flywheel-clients/src/bv/types.ts` - TypeScript interfaces\n- `packages/flywheel-clients/src/bv/errors.ts` - Error classes\n- `packages/flywheel-clients/src/bv/__tests__/` - Unit tests\n\n### Web Components\n- `apps/web/src/components/beads/GalaxyView.tsx` - Main graph visualization\n- `apps/web/src/components/beads/BeadNode.tsx` - Individual node component\n- `apps/web/src/components/beads/BeadSidebar.tsx` - Detail sidebar\n- `apps/web/src/components/beads/TriagePanel.tsx` - Triage interface\n- `apps/web/src/components/beads/InsightsPanel.tsx` - Bottlenecks/keystones display\n- `apps/web/src/components/beads/DependencyEditor.tsx` - Manage dependencies\n- `apps/web/src/hooks/useBVClient.ts` - React hook for BV operations\n- `apps/web/src/hooks/useTriageData.ts` - Hook for triage queries\n\n## References\n\n- PLAN.md §13: Beads/BV Integration specifications\n- BV API documentation (internal)\n- react-force-graph library for visualization\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] BV adapter parses `--robot-*` JSON output into validated schemas\n- [ ] Cache TTL and invalidation behavior is correct (e.g., after `bd sync`)\n\n### Integration Tests\n- [ ] When bv is installed (or mocked): triage/plan/priority endpoints return expected structure\n\n### Failure Mode Tests\n- [ ] bv missing / no baseline / timeout → actionable errors and degraded UI state\n\n### Logging\n- [ ] Logs include correlationId + bvCommand + dataHash + latencyMs\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] BVClient.createBead: sends correct request\n- [ ] BVClient.getBead: parses response correctly\n- [ ] BVClient.updateBead: sends PATCH request\n- [ ] BVClient.deleteBead: sends DELETE request\n- [ ] BVClient.getReadyBeads: applies filters\n- [ ] BVClient.getBlockedBeads: includes blocker info\n- [ ] BVClient.triageWork: returns prioritized list\n- [ ] BVClient.getBottlenecks: returns blocking beads\n- [ ] BVClient.getKeystones: returns high-impact beads\n- [ ] BVClient.getDependencyGraph: builds graph structure\n- [ ] BVClient.addDependency: validates no cycles\n- [ ] BVClient.removeDependency: removes edge\n- [ ] Retry logic: exponential backoff\n- [ ] Cache: stores graph with TTL\n- [ ] Cache: invalidates on mutation\n\n### Integration Tests\n- [ ] Create bead via client\n- [ ] Get ready beads filters correctly\n- [ ] Add dependency creates edge\n- [ ] Cycle detection prevents invalid dependency\n- [ ] Triage returns scored recommendations\n- [ ] Bottleneck detection finds blocking beads\n- [ ] Graph endpoint returns valid structure\n\n### E2E Tests\n- [ ] Full flow: create -\u003e add dep -\u003e triage -\u003e complete\n- [ ] Galaxy View renders graph from API\n- [ ] Node click shows bead details\n- [ ] Filter controls update view\n- [ ] Graph updates within 2 seconds of change\n\n### Performance Tests\n- [ ] Triage query \u003c100ms\n- [ ] Graph render 1000 nodes smooth (60fps)\n- [ ] Graph render 5000 nodes acceptable (30fps)\n- [ ] Cache hit \u003c10ms\n\n### Failure Mode Tests\n- [ ] BV unavailable: graceful degradation\n- [ ] Invalid bead ID: 404 response\n- [ ] Cycle in dependency: rejected with explanation\n- [ ] Large graph: progressive loading","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:45:58.967402792-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:10:03.61902224-05:00","dependencies":[{"issue_id":"flywheel_gateway-p8j","depends_on_id":"flywheel_gateway-45c","type":"blocks","created_at":"2026-01-08T14:01:46.338132749-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-r3p","title":"FEAT: Basic Web UI Shell with Mock-Data Mode","description":"## Background\n\nThe Web UI Shell provides the foundational application container for the Flywheel Gateway dashboard. It establishes the visual framework, routing infrastructure, global state management, and component library that all features build upon.\n\n### Why Phase 1 Foundation?\n- **Validates Stack**: Proves Vite + React 19 + TanStack + Tailwind 4 work together\n- **Mock-Data Mode**: Allows frontend development without backend dependency\n- **Design System**: Establishes patterns that all future components follow\n- **Integration Points**: Sets up WebSocket provider, query client, error boundaries\n\n## Technical Architecture\n\n### Technology Stack\n- **Build**: Vite 7.3+ with React Compiler plugin\n- **Framework**: React 19.2+ with Suspense boundaries\n- **Routing**: TanStack Router 1.145+ (type-safe, file-based)\n- **Data**: TanStack Query 5.90+ for server state\n- **State**: Zustand for client state\n- **Styling**: Tailwind CSS 4.1+ (CSS-based config)\n- **Animation**: Framer Motion for transitions\n- **Icons**: Lucide React (consistent iconography)\n\n### Application Shell Structure\n\n```typescript\n// apps/web/src/App.tsx\nfunction App() {\n  return (\n    \u003cQueryClientProvider client={queryClient}\u003e\n      \u003cRouterProvider router={router} /\u003e\n      \u003cWebSocketProvider\u003e\n        \u003cToaster /\u003e\n      \u003c/WebSocketProvider\u003e\n    \u003c/QueryClientProvider\u003e\n  );\n}\n\n// Layout structure\nfunction RootLayout({ children }: { children: React.ReactNode }) {\n  return (\n    \u003cdiv className=\"flex h-screen\"\u003e\n      \u003cSidebar /\u003e\n      \u003cdiv className=\"flex flex-col flex-1\"\u003e\n        \u003cTopbar /\u003e\n        \u003cmain className=\"flex-1 overflow-auto p-6\"\u003e\n          \u003cSuspense fallback={\u003cPageSkeleton /\u003e}\u003e\n            {children}\n          \u003c/Suspense\u003e\n        \u003c/main\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Design System Foundation\n\n#### CSS Custom Properties\n```css\n/* apps/web/src/styles/design-tokens.css */\n:root {\n  /* Colors - Semantic */\n  --color-background: 0 0% 100%;\n  --color-foreground: 222.2 84% 4.9%;\n  --color-primary: 222.2 47.4% 11.2%;\n  --color-primary-foreground: 210 40% 98%;\n  --color-muted: 210 40% 96.1%;\n  --color-muted-foreground: 215.4 16.3% 46.9%;\n  --color-accent: 210 40% 96.1%;\n  --color-destructive: 0 84.2% 60.2%;\n  --color-border: 214.3 31.8% 91.4%;\n  --color-ring: 222.2 84% 4.9%;\n  \n  /* Agent Status Colors */\n  --color-agent-spawning: 38 92% 50%;\n  --color-agent-ready: 142 76% 36%;\n  --color-agent-executing: 217 91% 60%;\n  --color-agent-paused: 38 92% 50%;\n  --color-agent-terminated: 0 0% 45%;\n  --color-agent-failed: 0 84% 60%;\n  \n  /* Spacing */\n  --spacing-xs: 0.25rem;\n  --spacing-sm: 0.5rem;\n  --spacing-md: 1rem;\n  --spacing-lg: 1.5rem;\n  --spacing-xl: 2rem;\n  \n  /* Radii */\n  --radius-sm: 0.25rem;\n  --radius-md: 0.375rem;\n  --radius-lg: 0.5rem;\n  \n  /* Shadows */\n  --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1);\n  --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1);\n}\n\n.dark {\n  --color-background: 222.2 84% 4.9%;\n  --color-foreground: 210 40% 98%;\n  /* ... dark mode overrides */\n}\n```\n\n### Core Components\n\n#### Sidebar Navigation\n```typescript\ninterface NavItem {\n  label: string;\n  icon: LucideIcon;\n  href: string;\n  badge?: number;\n  children?: NavItem[];\n}\n\nconst navigation: NavItem[] = [\n  { label: 'Dashboard', icon: LayoutDashboard, href: '/' },\n  { label: 'Agents', icon: Bot, href: '/agents', badge: activeAgentCount },\n  { label: 'Pipelines', icon: GitBranch, href: '/pipelines' },\n  { label: 'Beads', icon: CircleDot, href: '/beads' },\n  { label: 'Memory', icon: Brain, href: '/memory' },\n  { label: 'Fleet', icon: Server, href: '/fleet' },\n  { label: 'Settings', icon: Settings, href: '/settings' },\n];\n```\n\n#### Command Palette (Cmd+K)\n```typescript\ninterface CommandPaletteAction {\n  id: string;\n  label: string;\n  icon?: LucideIcon;\n  shortcut?: string;\n  action: () =\u003e void | Promise\u003cvoid\u003e;\n  group: 'navigation' | 'agents' | 'actions' | 'settings';\n}\n```\n\n### Mock-Data Mode\n\n```typescript\n// apps/web/src/lib/mock-data.ts\nexport const MOCK_MODE = import.meta.env.VITE_MOCK_DATA === 'true';\n\n// TanStack Query with mock interceptor\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      queryFn: MOCK_MODE ? mockQueryFn : undefined,\n      staleTime: MOCK_MODE ? Infinity : 5000,\n    },\n  },\n});\n\n// Mock data fixtures\nexport const mockAgents: Agent[] = [\n  { id: 'agent-1', name: 'Claude', status: 'ready', ... },\n  { id: 'agent-2', name: 'Codex', status: 'executing', ... },\n];\n\nexport const mockBeads: Bead[] = [...];\nexport const mockPipelines: Pipeline[] = [...];\n```\n\n### Error Boundaries\n\n```typescript\n// Global error boundary with correlation ID preservation\nfunction ErrorBoundary({ error }: { error: Error }) {\n  const correlationId = error.cause?.correlationId;\n  \n  return (\n    \u003cdiv className=\"error-container\"\u003e\n      \u003ch2\u003eSomething went wrong\u003c/h2\u003e\n      \u003cp\u003e{error.message}\u003c/p\u003e\n      {correlationId \u0026\u0026 (\n        \u003cp className=\"text-muted-foreground\"\u003e\n          Reference: {correlationId}\n        \u003c/p\u003e\n      )}\n      \u003cButton onClick={() =\u003e window.location.reload()}\u003e\n        Reload Page\n      \u003c/Button\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Responsive Design\n\n```typescript\n// Breakpoint constants\nconst breakpoints = {\n  sm: '640px',\n  md: '768px',\n  lg: '1024px',\n  xl: '1280px',\n  '2xl': '1536px',\n};\n\n// useMediaQuery hook\nfunction useMediaQuery(query: string): boolean {\n  const [matches, setMatches] = useState(false);\n  \n  useEffect(() =\u003e {\n    const media = window.matchMedia(query);\n    setMatches(media.matches);\n    const listener = () =\u003e setMatches(media.matches);\n    media.addEventListener('change', listener);\n    return () =\u003e media.removeEventListener('change', listener);\n  }, [query]);\n  \n  return matches;\n}\n\n// Mobile sidebar collapses to hamburger menu\n// Tablet shows collapsed icon-only sidebar\n// Desktop shows full sidebar with labels\n```\n\n## File Locations\n\n| File | Purpose |\n|------|---------|\n| `apps/web/src/App.tsx` | Root application component |\n| `apps/web/src/components/layout/` | Shell components (Sidebar, Topbar, etc.) |\n| `apps/web/src/components/ui/` | Design system primitives |\n| `apps/web/src/lib/mock-data.ts` | Mock data fixtures |\n| `apps/web/src/hooks/` | Shared hooks (useMediaQuery, useDarkMode) |\n| `apps/web/src/styles/` | CSS files including design tokens |\n| `apps/web/src/routes/` | TanStack Router route definitions |\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] AppShell renders correctly with sidebar and topbar\n- [ ] Navigation links highlight correctly based on route\n- [ ] Mock data mode returns expected fixtures\n- [ ] Dark mode toggle persists preference\n- [ ] Responsive breakpoint hooks return correct values\n\n### Component Tests\n- [ ] Button variants render with correct styles\n- [ ] Modal opens/closes with animation\n- [ ] Toast notifications appear and dismiss\n- [ ] Command palette opens with Cmd+K\n\n### E2E Tests (Playwright)\n- [ ] User can navigate between all main routes\n- [ ] Page loads within 2 seconds (Core Web Vitals)\n- [ ] Mobile navigation works correctly\n- [ ] Error boundary catches and displays errors gracefully\n- [ ] Mock data mode shows all screens correctly\n- [ ] Dark mode toggle switches theme without flash\n\n### Accessibility Tests\n- [ ] All interactive elements are keyboard accessible\n- [ ] Color contrast meets WCAG AA standards\n- [ ] Screen reader announces page changes\n\n### Visual Regression Tests\n- [ ] All pages match baseline screenshots (desktop + mobile)\n- [ ] Component library matches design system\n\n## Acceptance Criteria\n\n- [ ] Application shell exists with navigation, routing, and global providers (TanStack Router/Query + WS provider + Zustand)\n- [ ] Mock-data mode is first-class (toggleable) and exercises all core screens without backend\n- [ ] UI components follow the design system tokens and are accessible (keyboard + ARIA + contrast)\n- [ ] Global error boundaries/toasts render actionable messages and preserve correlation IDs when present\n- [ ] Responsive layout works on desktop and mobile breakpoints (no horizontal scroll)\n- [ ] Command palette (Cmd+K) provides quick navigation\n- [ ] Dark mode toggle works with smooth transition\n\n## Reference\n\n- PLAN.md §22 - Web UI Layer\n- PLAN.md §22.1 - Design System\n- PLAN.md §22.3 - Application Shell\n- Tailwind CSS 4.1 documentation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:32:01.691657558-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:31:53.957393728-05:00","dependencies":[{"issue_id":"flywheel_gateway-r3p","depends_on_id":"flywheel_gateway-hnv","type":"blocks","created_at":"2026-01-08T18:06:08.250404419-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-rgx","title":"FEAT: Cost Analytics and Optimization","description":"## Background\n\nAI agent operations represent a significant and growing cost center for organizations. Without proper cost visibility and optimization, expenses can spiral unexpectedly. This bead implements comprehensive cost analytics that provide real-time visibility into AI usage, predictive forecasting to prevent budget overruns, and AI-powered optimization recommendations to reduce costs while maintaining quality.\n\n## Reasoning\n\nCost management for AI agents is uniquely challenging because:\n- **Variable Rates**: Different models have vastly different costs (GPT-4 vs Claude Haiku)\n- **Usage Patterns**: Costs vary by time of day, task type, and agent behavior\n- **Hidden Costs**: Retries, context overflow, and inefficient prompts inflate costs\n- **Rapid Growth**: Agent fleets can scale quickly, multiplying costs\n\nThe solution must provide:\n- Granular cost attribution to understand where resources goes\n- Proactive alerts before budgets are exhausted\n- Actionable recommendations with quantified savings\n- Historical analysis to identify cost trends and anomalies\n\n## Technical Considerations\n\n### Cost Tracking Architecture\n\n**Cost Attribution Dimensions:**\n```typescript\ninterface CostRecord {\n  timestamp: Date;\n  organization_id: string;\n  project_id: string;\n  agent_id: string;\n  task_id: string;\n  model: string;\n  provider: 'anthropic' | 'openai' | 'google' | 'local';\n  \n  // Token breakdown\n  prompt_tokens: number;\n  completion_tokens: number;\n  cached_tokens: number;\n  \n  // Cost calculation\n  prompt_cost_units: number;\n  completion_cost_units: number;\n  total_cost_units: number;\n  \n  // Context\n  task_type: string;\n  complexity_tier: 'simple' | 'moderate' | 'complex';\n  success: boolean;\n}\n```\n\n**Real-time Cost Aggregation:**\n- Per-minute cost accumulation for real-time dashboards\n- Hourly rollups for trend analysis\n- Daily aggregates for reporting\n- Monthly summaries for reporting\n\n**Cost by Model:**\n```typescript\ninterface ModelCostBreakdown {\n  model: string;\n  total_cost_units: number;\n  percentage_of_total: number;\n  request_count: number;\n  avg_cost_per_request: number;\n  total_tokens: number;\n  cost_per_1k_tokens: number;\n  trend: CostTrend;\n}\n```\n\n**Cost by Agent:**\n- Individual agent cost tracking\n- Agent cost ranking (top spenders)\n- Cost per successful task by agent\n- Agent efficiency comparison\n\n**Cost by Task Type:**\n- Task classification for cost attribution\n- Cost benchmarks by task type\n- Anomaly detection for expensive tasks\n- Task type optimization opportunities\n\n### Budget Status Visualization\n\n**Budget Configuration:**\n```typescript\ninterface Budget {\n  id: string;\n  organization_id: string;\n  period: 'daily' | 'weekly' | 'monthly';\n  amount_units: number;\n  alert_thresholds: number[]; // e.g., [50, 75, 90, 100]\n  action_on_exceed: 'alert' | 'throttle' | 'block';\n  rollover: boolean;\n  effective_date: Date;\n}\n```\n\n**Visual Progress Indicators:**\n- Circular progress gauge (0-100%)\n- Color coding: green (\u003c50%), yellow (50-80%), orange (80-95%), red (\u003e95%)\n- Burn rate indicator (current vs expected)\n- Days remaining at current rate\n- Comparison to previous period\n\n**Budget Alerts:**\n- Threshold-based notifications\n- Predictive alerts (\"Will exceed budget in 3 days\")\n- Spike detection (\"Cost increased 300% in last hour\")\n- Recovery notification when usage normalizes\n\n### 30-Day Cost Forecasting\n\n**Forecasting Model:**\n```typescript\ninterface CostForecast {\n  forecast_date: Date;\n  horizon_days: 30;\n  daily_forecasts: DailyForecast[];\n  total_forecast_units: number;\n  confidence_interval_95: {\n    lower: number;\n    upper: number;\n  };\n  methodology: 'arima' | 'prophet' | 'linear' | 'ensemble';\n  accuracy_metrics: {\n    mape: number; // Mean Absolute Percentage Error\n    rmse: number; // Root Mean Square Error\n  };\n}\n\ninterface DailyForecast {\n  date: Date;\n  predicted_cost_units: number;\n  lower_bound_units: number;\n  upper_bound_units: number;\n  confidence: number;\n}\n```\n\n**Forecasting Methodology:**\n1. **Historical Analysis**: Use 90 days of historical data\n2. **Seasonality Detection**: Weekly and monthly patterns\n3. **Trend Extraction**: Linear and exponential trends\n4. **Anomaly Handling**: Exclude outliers from training\n5. **Ensemble Approach**: Combine multiple models for robustness\n\n**Confidence Intervals:**\n- 95% confidence intervals for each day\n- Widening intervals for further predictions\n- Scenario modeling (optimistic, expected, pessimistic)\n- Sensitivity analysis for key drivers\n\n### AI-Powered Optimization Recommendations\n\n**Recommendation Categories:**\n\n1. **Model Optimization:**\n```typescript\n{\n  category: 'model_optimization',\n  title: 'Switch documentation tasks to Claude Haiku',\n  description: 'Analysis shows 847 documentation tasks last month used Claude Sonnet. These tasks have 98% success rate with Haiku at 1/10th the cost.',\n  current_cost: 423.50,\n  optimized_cost: 42.35,\n  estimated_savings: 381.15,\n  confidence: 0.92,\n  implementation: 'Update agent configuration to route doc tasks to haiku',\n  risk: 'low'\n}\n```\n\n2. **Caching Optimization:**\n```typescript\n{\n  category: 'caching',\n  title: 'Enable prompt caching for repetitive system prompts',\n  description: 'Detected 12,847 requests with identical 4k token system prompts. Prompt caching would reduce costs by 75% for these tokens.',\n  estimated_savings: 156.32,\n  implementation: 'Enable cache_control in API calls'\n}\n```\n\n3. **Batching Optimization:**\n```typescript\n{\n  category: 'batching',\n  title: 'Batch code review requests during off-peak hours',\n  description: 'Non-urgent code reviews can be batched and processed at 50% discount using batch API.',\n  estimated_savings: 89.50,\n  implementation: 'Configure batch queue for code review tasks'\n}\n```\n\n4. **Context Optimization:**\n```typescript\n{\n  category: 'context_optimization',\n  title: 'Reduce context size for simple queries',\n  description: 'Simple queries averaging 2k completion tokens include 50k context. Reducing to 10k relevant context saves tokens.',\n  estimated_savings: 234.00,\n  implementation: 'Improve context selection algorithm'\n}\n```\n\n5. **Agent Consolidation:**\n```typescript\n{\n  category: 'consolidation',\n  title: 'Consolidate low-utilization agents',\n  description: '5 agents have \u003c10% utilization. Consolidating to 2 agents reduces fixed overhead costs.',\n  estimated_savings: 45.00,\n  implementation: 'Migrate workloads and retire agents'\n}\n```\n\n**Savings Estimation:**\n- Historical data analysis for accuracy\n- Conservative estimates (lower bound of range)\n- Quality impact assessment\n- Implementation effort consideration\n- ROI calculation with payback period\n\n## Acceptance Criteria\n\n1. **Cost Tracking**\n   - [ ] All API calls tracked with full cost attribution\n   - [ ] Real-time cost aggregation (\u003c 1 minute delay)\n   - [ ] Cost breakdown by model, agent, task type available\n   - [ ] Historical cost data retained for 13 months\n\n2. **Budget Management**\n   - [ ] Budget configuration per organization/project\n   - [ ] Visual progress with color-coded thresholds\n   - [ ] Alert notifications at configured thresholds\n   - [ ] Budget enforcement actions (throttle/block)\n\n3. **Forecasting**\n   - [ ] 30-day forecast with daily granularity\n   - [ ] 95% confidence intervals displayed\n   - [ ] Forecast accuracy tracking (MAPE \u003c 15%)\n   - [ ] Scenario analysis available\n\n4. **Optimization Recommendations**\n   - [ ] Automated recommendation generation weekly\n   - [ ] Savings estimates with confidence levels\n   - [ ] Implementation guidance provided\n   - [ ] Recommendation outcome tracking\n\n5. **Dashboard UI**\n   - [ ] Cost overview with key metrics\n   - [ ] Interactive charts with drill-down\n   - [ ] Budget gauges with status indicators\n   - [ ] Recommendation cards with actions\n\n## File Locations\n\n### Backend Services\n- `apps/gateway/src/services/cost-analytics.service.ts` - Core cost analytics\n- `apps/gateway/src/services/cost-tracker.service.ts` - Real-time cost tracking\n- `apps/gateway/src/services/budget.service.ts` - Budget management\n- `apps/gateway/src/services/cost-forecast.service.ts` - Forecasting engine\n- `apps/gateway/src/services/cost-optimization.service.ts` - Recommendation generation\n- `apps/gateway/src/controllers/cost-analytics.controller.ts` - Cost API endpoints\n\n### Database\n- `packages/database/prisma/migrations/xxx_add_cost_analytics.sql` - Schema\n- Tables: `cost_records`, `cost_aggregates_hourly`, `cost_aggregates_daily`, `budgets`, `cost_forecasts`, `optimization_recommendations`\n\n### Frontend Components\n- `apps/web/src/components/analytics/CostDashboard.tsx` - Main cost dashboard\n- `apps/web/src/components/analytics/CostBreakdownChart.tsx` - Cost by dimension\n- `apps/web/src/components/analytics/BudgetGauge.tsx` - Budget progress indicator\n- `apps/web/src/components/analytics/CostForecastChart.tsx` - Forecast visualization\n- `apps/web/src/components/analytics/OptimizationRecommendations.tsx` - Savings suggestions\n- `apps/web/src/components/analytics/CostTrendChart.tsx` - Historical trends\n\n### Configuration\n- `apps/gateway/src/config/cost-model.config.ts` - Model cost coefficients\n- `apps/gateway/src/config/cost-thresholds.config.ts` - Alert thresholds\n\n## References\n\n- PLAN.md §21.6 - Cost Analytics and Optimization\n- Model rate coefficients are configured externally (do not embed provider rate tables in this repo).\n- Time Series Forecasting: ARIMA, Prophet methodologies\n\n\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Cost/usage unit aggregation from token records is correct and stable\n- [ ] Budget threshold evaluation triggers alerts/actions deterministically\n- [ ] Forecasting component produces schema-valid outputs and handles sparse data\n\n### Integration Tests\n- [ ] Analytics endpoints return validated responses and handle empty datasets gracefully\n\n### Failure Mode Tests\n- [ ] Missing rate coefficients/config → actionable error and safe fallback (no crash)\n\n### Logging\n- [ ] Logs include correlationId + window + recordCount + computeTimeMs; individual prompts are never logged\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] CostCalculator: computes from tokens\n- [ ] CostCalculator: applies rate card\n- [ ] CostCalculator: aggregates by project\n- [ ] CostCalculator: aggregates by team\n- [ ] BudgetTracker: tracks against limit\n- [ ] BudgetTracker: calculates burn rate\n- [ ] Forecaster: projects from trend\n- [ ] Forecaster: estimates end-of-period\n- [ ] Optimizer: identifies waste\n- [ ] Optimizer: suggests model switches\n- [ ] Optimizer: recommends caching\n- [ ] TokenBreakdown: by prompt/response\n\n### Integration Tests\n- [ ] GET /analytics/cost returns data\n- [ ] Budget threshold alerts fire\n- [ ] Forecast updates with new data\n- [ ] Optimization suggestions generated\n- [ ] Cost by project breakdown works\n- [ ] Historical cost trends queryable\n\n### E2E Tests\n- [ ] Dashboard shows spend summary\n- [ ] Budget warning appears at threshold\n- [ ] Optimization applied reduces cost\n- [ ] Export cost report\n\n### Performance Tests\n- [ ] Cost calculation \u003c100ms\n- [ ] Forecast \u003c500ms\n- [ ] Large history aggregation \u003c2s\n- [ ] Real-time cost updates\n\n### Failure Mode Tests\n- [ ] Missing rate card: default rates\n- [ ] Incomplete data: partial calculation\n- [ ] Budget exceeded: notification sent\n- [ ] Forecast divergence: warning shown","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:56:40.58141357-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:10:16.554933938-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-rgx","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T14:01:46.731671758-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-rgx","depends_on_id":"flywheel_gateway-41h","type":"blocks","created_at":"2026-01-08T14:01:47.518995829-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-rkc","title":"feat","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:46:51.69997118-05:00","created_by":"ubuntu","updated_at":"2026-01-08T14:00:25.43885811-05:00","closed_at":"2026-01-08T14:00:25.43885811-05:00","close_reason":"Empty placeholder beads created in error"}
{"id":"flywheel_gateway-toe","title":"Git Coordination Service","description":"## Overview\n\nThe Git Coordination Service provides centralized management of git operations across multiple agents working in the same repository. This is critical for Phase 3 Flywheel Integration where multiple AI agents may be simultaneously modifying code.\n\n## Background \u0026 Reasoning\n\nWhen multiple agents operate on a shared codebase, git coordination becomes essential to prevent:\n- Merge conflicts from overlapping changes\n- Lost work from force pushes\n- Branch naming collisions\n- Inconsistent repository state\n\nThe Git Coordination Service acts as a single source of truth for branch assignments and provides predictive conflict detection before agents begin work.\n\n## Technical Architecture\n\n### Core Components\n\n1. **Branch Assignment Manager**\n   - Maintains registry of agent-to-branch mappings\n   - Enforces exclusive branch ownership\n   - Supports branch reservation with TTL\n   - Handles branch release on agent completion/timeout\n\n2. **Conflict Prediction Engine**\n   - Analyzes pending changes across all active branches\n   - Detects overlapping file modifications before they occur\n   - Uses git diff-tree for file-level conflict detection\n   - Provides semantic conflict hints (same function modified)\n\n3. **Sync Operations Manager**\n   - Coordinates pull operations with conflict checking\n   - Manages commit sequencing for dependent changes\n   - Handles push operations with retry logic\n   - Supports atomic multi-branch operations\n\n4. **Merge Base Analyzer**\n   - Tracks merge base for all active branches\n   - Calculates branch divergence metrics\n   - Recommends rebase timing\n   - Detects stale branches requiring attention\n\n### Frontend Components\n\n1. **BranchVisualization.tsx**\n   - D3.js-based git graph rendering\n   - Real-time branch status updates via WebSocket\n   - Interactive branch selection and comparison\n   - Commit history timeline\n\n2. **ConflictPredictor.tsx**\n   - Visual file overlap detection\n   - Agent workspace comparison\n   - Suggested resolution strategies\n\n3. **SyncStatusPanel.tsx**\n   - Per-agent sync status indicators\n   - Push/pull operation progress\n   - Error state visualization\n\n## API Design\n\n```typescript\ninterface GitCoordinationService {\n  // Branch Management\n  assignBranch(agentId: string, branchName: string): Promise\u003cBranchAssignment\u003e;\n  releaseBranch(agentId: string): Promise\u003cvoid\u003e;\n  getBranchAssignments(): Promise\u003cBranchAssignment[]\u003e;\n  \n  // Conflict Prediction\n  predictConflicts(branchA: string, branchB: string): Promise\u003cConflictPrediction\u003e;\n  getOverlappingFiles(branches: string[]): Promise\u003cFileOverlapReport\u003e;\n  \n  // Sync Operations\n  syncBranch(agentId: string, operation: SyncOperation): Promise\u003cSyncResult\u003e;\n  getMergeBase(branch: string, target: string): Promise\u003cMergeBaseInfo\u003e;\n  \n  // Visualization Data\n  getGitGraph(options: GraphOptions): Promise\u003cGitGraphData\u003e;\n}\n\ninterface BranchAssignment {\n  agentId: string;\n  branchName: string;\n  assignedAt: Date;\n  expiresAt?: Date;\n  status: 'active' | 'stale' | 'merged';\n}\n\ninterface ConflictPrediction {\n  hasConflicts: boolean;\n  conflictingFiles: string[];\n  severity: 'none' | 'low' | 'medium' | 'high';\n  recommendation: string;\n}\n```\n\n## File Locations\n\n- `apps/gateway/src/services/git.service.ts` - Core coordination service\n- `apps/gateway/src/services/git-conflict.service.ts` - Conflict prediction logic\n- `apps/gateway/src/services/git-sync.service.ts` - Sync operations\n- `apps/web/src/components/git/BranchVisualization.tsx` - Git graph component\n- `apps/web/src/components/git/ConflictPredictor.tsx` - Conflict UI\n- `apps/web/src/components/git/SyncStatusPanel.tsx` - Sync status display\n- `apps/web/src/components/git/BranchAssignmentList.tsx` - Agent-branch mapping UI\n\n## Database Schema\n\n```sql\nCREATE TABLE branch_assignments (\n  id UUID PRIMARY KEY,\n  agent_id UUID REFERENCES agents(id),\n  branch_name VARCHAR(255) NOT NULL,\n  repository_id UUID REFERENCES repositories(id),\n  assigned_at TIMESTAMP DEFAULT NOW(),\n  expires_at TIMESTAMP,\n  status VARCHAR(50) DEFAULT 'active',\n  UNIQUE(repository_id, branch_name)\n);\n\nCREATE TABLE conflict_predictions (\n  id UUID PRIMARY KEY,\n  branch_a VARCHAR(255),\n  branch_b VARCHAR(255),\n  conflicting_files JSONB,\n  severity VARCHAR(50),\n  predicted_at TIMESTAMP DEFAULT NOW()\n);\n```\n\n## Acceptance Criteria\n\n- [ ] Agents can request and receive exclusive branch assignments\n- [ ] Branch assignments expire after configurable TTL\n- [ ] Conflict prediction identifies overlapping file changes with \u003e95% accuracy\n- [ ] Real-time git graph updates within 500ms of changes\n- [ ] Sync operations handle transient failures with exponential backoff\n- [ ] Branch visualization supports repositories with 1000+ commits\n- [ ] All git operations are logged for audit trail\n- [ ] WebSocket events notify clients of branch status changes\n\n## Testing Requirements\n\n- Unit tests for conflict prediction algorithms\n- Integration tests for git operations (using test repositories)\n- E2E tests for branch assignment workflow\n- Performance tests for large repository handling\n- Chaos testing for concurrent agent operations\n\n## Security Considerations\n\n- Branch assignments scoped to authenticated agents only\n- Git credentials managed via secure credential store\n- Audit logging for all git write operations\n- Rate limiting on sync operations\n\n## References\n\n- PLAN.md §18 - Git Coordination Architecture\n- Git merge-base documentation\n- libgit2 bindings for Node.js","notes":"## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Conflict prediction algorithm identifies overlapping file changes with deterministic results\n- [ ] Branch assignment TTL expiry transitions state correctly\n- [ ] Git graph construction handles merge commits and rebases accurately\n- [ ] Sync retry logic respects exponential backoff configuration\n\n### Integration Tests\n- [ ] Branch assignment → conflict prediction → notification flow works end-to-end\n- [ ] Git graph updates within 500ms of commits (using test repositories)\n- [ ] Concurrent agent operations on same repo serialize correctly\n\n### E2E Tests\n- [ ] Complete branch assignment workflow via REST API + WebSocket events\n- [ ] Large repository (1000+ commits) visualization performs within SLA\n\n### Failure Mode Tests\n- [ ] Git remote unavailable → graceful degradation with actionable error\n- [ ] Credential expiry → clear error message with refresh hint\n- [ ] Concurrent assignment conflicts → deterministic winner selection\n\n### Performance Tests\n- [ ] Branch sync under 2s for typical repository\n- [ ] Conflict prediction under 500ms for 100 file changes\n- [ ] Memory usage bounded for large repositories\n\n### Logging\n- [ ] Logs include correlationId + repoId + branchName + agentId + operation; credentials are never logged","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:49:42.477444189-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:38:15.125932952-05:00","dependencies":[{"issue_id":"flywheel_gateway-toe","depends_on_id":"flywheel_gateway-5nm","type":"blocks","created_at":"2026-01-08T14:02:00.938933183-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-tz4","title":"Comprehensive Testing Suite","description":"## Background\n\nA production-ready application requires comprehensive testing at multiple levels to ensure reliability, catch regressions, and enable confident deployments. The Flywheel Gateway, with its real-time WebSocket communication, database interactions, and complex UI, needs a robust testing strategy covering unit, integration, contract, E2E, load, and visual regression testing.\n\n## Reasoning\n\nEach testing layer serves a specific purpose:\n\n1. **Unit Tests**: Fast feedback on individual functions/components (seconds)\n2. **Integration Tests**: Verify components work together correctly\n3. **Contract Tests**: Ensure API matches OpenAPI specification\n4. **E2E Tests**: Validate critical user journeys end-to-end\n5. **Load Tests**: Verify system handles expected and peak loads\n6. **Visual Regression**: Catch unintended UI changes\n\nThe combination provides defense in depth - if one layer misses a bug, another should catch it.\n\n## Technical Considerations\n\n### Unit Tests (Bun Test)\n\n```typescript\n// tests/unit/lib/auth.test.ts\nimport { describe, it, expect, beforeEach, mock } from 'bun:test';\nimport { validateToken, generateToken, TokenPayload } from '@/lib/auth';\n\ndescribe('Auth Library', () =\u003e {\n  describe('validateToken', () =\u003e {\n    it('should validate a correctly signed token', async () =\u003e {\n      const payload: TokenPayload = { userId: '123', role: 'admin', exp: Date.now() + 3600000 };\n      const token = await generateToken(payload);\n      \n      const result = await validateToken(token);\n      \n      expect(result.valid).toBe(true);\n      expect(result.payload?.userId).toBe('123');\n    });\n    \n    it('should reject an expired token', async () =\u003e {\n      const payload: TokenPayload = { userId: '123', role: 'admin', exp: Date.now() - 1000 };\n      const token = await generateToken(payload);\n      \n      const result = await validateToken(token);\n      \n      expect(result.valid).toBe(false);\n      expect(result.error).toBe('TOKEN_EXPIRED');\n    });\n    \n    it('should reject a tampered token', async () =\u003e {\n      const token = 'invalid.token.signature';\n      \n      const result = await validateToken(token);\n      \n      expect(result.valid).toBe(false);\n      expect(result.error).toBe('INVALID_SIGNATURE');\n    });\n  });\n});\n\n// tests/unit/components/AgentCard.test.tsx\nimport { describe, it, expect } from 'bun:test';\nimport { render, screen, fireEvent } from '@testing-library/react';\nimport { AgentCard } from '@/components/AgentCard';\n\ndescribe('AgentCard', () =\u003e {\n  const mockAgent = {\n    id: 'agent-1',\n    name: 'Test Agent',\n    status: 'running',\n    uptime: 3600,\n    sessionCount: 5\n  };\n  \n  it('should display agent information', () =\u003e {\n    render(\u003cAgentCard agent={mockAgent} /\u003e);\n    \n    expect(screen.getByText('Test Agent')).toBeInTheDocument();\n    expect(screen.getByText('running')).toBeInTheDocument();\n    expect(screen.getByText('5 sessions')).toBeInTheDocument();\n  });\n  \n  it('should call onSelect when clicked', () =\u003e {\n    const onSelect = mock(() =\u003e {});\n    render(\u003cAgentCard agent={mockAgent} onSelect={onSelect} /\u003e);\n    \n    fireEvent.click(screen.getByRole('button'));\n    \n    expect(onSelect).toHaveBeenCalledWith('agent-1');\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\n// tests/integration/api/agents.test.ts\nimport { describe, it, expect, beforeAll, afterAll } from 'bun:test';\nimport { createTestApp, createTestDatabase, TestContext } from '../helpers';\n\ndescribe('Agents API Integration', () =\u003e {\n  let ctx: TestContext;\n  \n  beforeAll(async () =\u003e {\n    ctx = await createTestContext();\n    // Seed test data\n    await ctx.db.agents.insert([\n      { id: 'agent-1', name: 'Agent One', status: 'running' },\n      { id: 'agent-2', name: 'Agent Two', status: 'stopped' }\n    ]);\n  });\n  \n  afterAll(async () =\u003e {\n    await ctx.cleanup();\n  });\n  \n  describe('GET /api/agents', () =\u003e {\n    it('should return all agents', async () =\u003e {\n      const response = await ctx.app.request('/api/agents', {\n        headers: { Authorization: `Bearer ${ctx.authToken}` }\n      });\n      \n      expect(response.status).toBe(200);\n      const body = await response.json();\n      expect(body.agents).toHaveLength(2);\n      expect(body.agents[0]).toMatchObject({\n        id: expect.any(String),\n        name: expect.any(String),\n        status: expect.stringMatching(/running|stopped|error/)\n      });\n    });\n    \n    it('should filter by status', async () =\u003e {\n      const response = await ctx.app.request('/api/agents?status=running', {\n        headers: { Authorization: `Bearer ${ctx.authToken}` }\n      });\n      \n      const body = await response.json();\n      expect(body.agents).toHaveLength(1);\n      expect(body.agents[0].status).toBe('running');\n    });\n  });\n  \n  describe('POST /api/agents/:id/restart', () =\u003e {\n    it('should restart agent and persist new state', async () =\u003e {\n      const response = await ctx.app.request('/api/agents/agent-1/restart', {\n        method: 'POST',\n        headers: { Authorization: `Bearer ${ctx.authToken}` }\n      });\n      \n      expect(response.status).toBe(200);\n      \n      // Verify database was updated\n      const agent = await ctx.db.agents.findOne({ id: 'agent-1' });\n      expect(agent.restartCount).toBe(1);\n      expect(agent.lastRestartAt).toBeDefined();\n    });\n  });\n});\n```\n\n### Contract Tests (OpenAPI Compliance)\n\n```typescript\n// tests/contract/openapi.test.ts\nimport { describe, it, expect } from 'bun:test';\nimport OpenAPISchemaValidator from 'openapi-schema-validator';\nimport { loadOpenAPISpec } from '../helpers';\nimport { app } from '@/app';\n\ndescribe('OpenAPI Contract Tests', () =\u003e {\n  const spec = loadOpenAPISpec('openapi.yaml');\n  const validator = new OpenAPISchemaValidator({ version: 3.1 });\n  \n  it('should have valid OpenAPI spec', () =\u003e {\n    const result = validator.validate(spec);\n    expect(result.errors).toHaveLength(0);\n  });\n  \n  describe('Response Schema Validation', () =\u003e {\n    for (const [path, methods] of Object.entries(spec.paths)) {\n      for (const [method, operation] of Object.entries(methods)) {\n        if (method === 'parameters') continue;\n        \n        it(`${method.toUpperCase()} ${path} should match schema`, async () =\u003e {\n          const response = await app.request(path, {\n            method: method.toUpperCase(),\n            headers: { Authorization: 'Bearer test-token' }\n          });\n          \n          const expectedSchema = operation.responses[response.status]?.content?.['application/json']?.schema;\n          \n          if (expectedSchema) {\n            const body = await response.json();\n            const valid = validateAgainstSchema(body, expectedSchema);\n            expect(valid.errors).toHaveLength(0);\n          }\n        });\n      }\n    }\n  });\n});\n```\n\n### E2E Tests (Playwright)\n\n```typescript\n// tests/e2e/critical-paths/agent-management.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Agent Management Critical Path', () =\u003e {\n  test.beforeEach(async ({ page }) =\u003e {\n    await page.goto('/');\n    // Login\n    await page.fill('[data-testid=\"email\"]', 'test@example.com');\n    await page.fill('[data-testid=\"password\"]', 'testpassword');\n    await page.click('[data-testid=\"login-button\"]');\n    await page.waitForURL('/dashboard');\n  });\n  \n  test('should create, view, and restart an agent', async ({ page }) =\u003e {\n    // Navigate to agents\n    await page.click('[data-testid=\"nav-agents\"]');\n    await expect(page).toHaveURL('/agents');\n    \n    // Create new agent\n    await page.click('[data-testid=\"create-agent\"]');\n    await page.fill('[data-testid=\"agent-name\"]', 'E2E Test Agent');\n    await page.selectOption('[data-testid=\"agent-type\"]', 'assistant');\n    await page.click('[data-testid=\"submit-agent\"]');\n    \n    // Verify agent appears in list\n    await expect(page.locator('[data-testid=\"agent-card\"]').filter({ hasText: 'E2E Test Agent' })).toBeVisible();\n    \n    // View agent details\n    await page.click('[data-testid=\"agent-card\"]', { hasText: 'E2E Test Agent' });\n    await expect(page.locator('h1')).toHaveText('E2E Test Agent');\n    \n    // Restart agent\n    await page.click('[data-testid=\"restart-agent\"]');\n    await expect(page.locator('[data-testid=\"agent-status\"]')).toHaveText('restarting');\n    \n    // Wait for agent to be running again\n    await expect(page.locator('[data-testid=\"agent-status\"]')).toHaveText('running', { timeout: 30000 });\n  });\n  \n  test('should view real-time session output', async ({ page }) =\u003e {\n    await page.goto('/sessions/test-session');\n    \n    // Verify WebSocket connection\n    await expect(page.locator('[data-testid=\"connection-status\"]')).toHaveText('connected');\n    \n    // Verify output is streaming\n    const initialCount = await page.locator('[data-testid=\"output-line\"]').count();\n    await page.waitForTimeout(2000);\n    const newCount = await page.locator('[data-testid=\"output-line\"]').count();\n    expect(newCount).toBeGreaterThan(initialCount);\n  });\n});\n```\n\n### Load Tests (k6)\n\n```javascript\n// tests/load/websocket-load.js\nimport ws from 'k6/ws';\nimport { check, sleep } from 'k6';\nimport { Rate, Trend } from 'k6/metrics';\n\nconst errorRate = new Rate('ws_errors');\nconst messageLatency = new Trend('ws_message_latency');\n\nexport const options = {\n  scenarios: {\n    websocket_load: {\n      executor: 'ramping-vus',\n      startVUs: 0,\n      stages: [\n        { duration: '1m', target: 100 },   // Ramp up to 100 concurrent connections\n        { duration: '5m', target: 100 },   // Hold at 100\n        { duration: '2m', target: 500 },   // Spike to 500\n        { duration: '5m', target: 500 },   // Hold at 500\n        { duration: '2m', target: 0 },     // Ramp down\n      ],\n    },\n  },\n  thresholds: {\n    ws_errors: ['rate\u003c0.01'],           // Less than 1% error rate\n    ws_message_latency: ['p95\u003c200'],    // 95th percentile under 200ms\n  },\n};\n\nexport default function () {\n  const url = `wss://${__ENV.TARGET_HOST}/ws/sessions/test-session`;\n  \n  const res = ws.connect(url, { headers: { Authorization: 'Bearer test-token' } }, function (socket) {\n    socket.on('open', () =\u003e {\n      // Subscribe to session events\n      socket.send(JSON.stringify({ type: 'subscribe', sessionId: 'test-session' }));\n    });\n    \n    socket.on('message', (data) =\u003e {\n      const msg = JSON.parse(data);\n      if (msg.timestamp) {\n        messageLatency.add(Date.now() - msg.timestamp);\n      }\n    });\n    \n    socket.on('error', (e) =\u003e {\n      errorRate.add(1);\n      console.error('WebSocket error:', e);\n    });\n    \n    // Keep connection alive for test duration\n    socket.setTimeout(function () {\n      socket.close();\n    }, 60000);\n  });\n  \n  check(res, { 'WebSocket connected': (r) =\u003e r \u0026\u0026 r.status === 101 });\n}\n\n// tests/load/api-load.js\nimport http from 'k6/http';\nimport { check, group } from 'k6';\n\nexport const options = {\n  scenarios: {\n    api_load: {\n      executor: 'constant-arrival-rate',\n      rate: 1000,           // 1000 requests per second\n      timeUnit: '1s',\n      duration: '5m',\n      preAllocatedVUs: 50,\n      maxVUs: 200,\n    },\n  },\n  thresholds: {\n    http_req_duration: ['p95\u003c100', 'p99\u003c200'],  // 95th \u003c 100ms, 99th \u003c 200ms\n    http_req_failed: ['rate\u003c0.01'],              // Less than 1% failures\n  },\n};\n\nexport default function () {\n  group('API Endpoints', function () {\n    // GET /api/agents - List agents\n    const agentsRes = http.get(`${__ENV.TARGET_URL}/api/agents`);\n    check(agentsRes, {\n      'agents status 200': (r) =\u003e r.status === 200,\n      'agents has data': (r) =\u003e r.json().agents.length \u003e 0,\n    });\n    \n    // GET /api/sessions - List sessions\n    const sessionsRes = http.get(`${__ENV.TARGET_URL}/api/sessions`);\n    check(sessionsRes, {\n      'sessions status 200': (r) =\u003e r.status === 200,\n    });\n  });\n}\n```\n\n### Visual Regression Tests\n\n```typescript\n// tests/visual/components.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Visual Regression Tests', () =\u003e {\n  test('Dashboard should match snapshot', async ({ page }) =\u003e {\n    await page.goto('/dashboard');\n    await page.waitForLoadState('networkidle');\n    \n    // Hide dynamic content for stable snapshots\n    await page.evaluate(() =\u003e {\n      document.querySelectorAll('[data-testid=\"timestamp\"]').forEach(el =\u003e {\n        el.textContent = '2024-01-01 00:00:00';\n      });\n    });\n    \n    await expect(page).toHaveScreenshot('dashboard.png', {\n      maxDiffPixels: 100,\n      threshold: 0.2,\n    });\n  });\n  \n  test('Agent Card states should match snapshots', async ({ page }) =\u003e {\n    await page.goto('/storybook/agent-card');\n    \n    // Test different states\n    for (const state of ['running', 'stopped', 'error', 'starting']) {\n      await page.click(`[data-state=\"${state}\"]`);\n      await expect(page.locator('[data-testid=\"agent-card\"]')).toHaveScreenshot(`agent-card-${state}.png`);\n    }\n  });\n  \n  test('Mobile layout should match snapshot', async ({ page }) =\u003e {\n    await page.setViewportSize({ width: 375, height: 812 }); // iPhone X\n    await page.goto('/dashboard');\n    await page.waitForLoadState('networkidle');\n    \n    await expect(page).toHaveScreenshot('dashboard-mobile.png');\n  });\n});\n```\n\n## File Locations\n\n### Unit Tests\n- `tests/unit/lib/` - Library function tests\n- `tests/unit/components/` - React component tests\n- `tests/unit/hooks/` - Custom hook tests\n- `apps/gateway/tests/unit/` - Gateway-specific unit tests\n\n### Integration Tests\n- `tests/integration/api/` - API integration tests\n- `tests/integration/database/` - Database integration tests\n- `tests/integration/websocket/` - WebSocket integration tests\n- `apps/gateway/tests/integration/` - Gateway integration tests\n\n### Contract Tests\n- `tests/contract/openapi.test.ts` - OpenAPI compliance tests\n- `tests/contract/schemas/` - Schema definitions\n\n### E2E Tests\n- `tests/e2e/critical-paths/` - Critical user journey tests\n- `tests/e2e/fixtures/` - Test fixtures and data\n- `tests/e2e/helpers/` - E2E test utilities\n- `apps/web/tests/e2e/` - Web app E2E tests\n\n### Load Tests\n- `tests/load/websocket-load.js` - WebSocket load tests\n- `tests/load/api-load.js` - API load tests\n- `tests/load/scenarios/` - Complex load scenarios\n\n### Visual Regression\n- `tests/visual/` - Visual regression test specs\n- `tests/visual/snapshots/` - Baseline screenshots\n\n### Configuration\n- `tests/helpers/` - Shared test utilities\n- `tests/fixtures/` - Test data fixtures\n- `playwright.config.ts` - Playwright configuration\n- `bun.test.config.ts` - Bun test configuration\n\n## Acceptance Criteria\n\n### Unit Tests\n- [ ] 80% code coverage across codebase\n- [ ] All utility functions have tests\n- [ ] All React components have basic render tests\n- [ ] Custom hooks tested with renderHook\n- [ ] Mocking strategy documented\n- [ ] Tests run in under 30 seconds\n\n### Integration Tests\n- [ ] 70% coverage of API endpoints\n- [ ] Database transactions tested\n- [ ] WebSocket message flow tested\n- [ ] Authentication/authorization tested\n- [ ] Error handling paths tested\n- [ ] Test isolation (no shared state)\n\n### Contract Tests\n- [ ] OpenAPI spec validated as syntactically correct\n- [ ] All documented endpoints respond with matching schemas\n- [ ] Error responses match documented formats\n- [ ] Request validation matches spec\n- [ ] Spec auto-generated or manually maintained\n\n### E2E Tests\n- [ ] Critical user journeys covered:\n  - [ ] Login/logout flow\n  - [ ] Agent creation and management\n  - [ ] Session viewing with real-time output\n  - [ ] Settings modification\n  - [ ] Error recovery scenarios\n- [ ] Tests run on multiple browsers (Chrome, Firefox, Safari)\n- [ ] Mobile viewport testing included\n- [ ] Tests complete in under 5 minutes\n\n### Load Tests\n- [ ] WebSocket handles 500 concurrent connections\n- [ ] API handles 1000 req/s with p95 \u003c 100ms\n- [ ] No memory leaks under sustained load\n- [ ] Graceful degradation under overload\n- [ ] Load test results tracked over time\n\n### Visual Regression\n- [ ] All major pages have baseline screenshots\n- [ ] Component states captured\n- [ ] Mobile layouts captured\n- [ ] Dark/light mode variants\n- [ ] Diff threshold configured appropriately\n- [ ] CI integration for PR checks\n\n### CI Integration\n- [ ] Unit/integration tests run on every PR\n- [ ] E2E tests run on every PR to main\n- [ ] Load tests run nightly\n- [ ] Visual regression on every PR\n- [ ] Coverage reports generated\n- [ ] Test failure notifications\n\n## Reference\n\nPLAN.md §25 - Comprehensive Testing Suite\n\n\n## Testing Requirements\n\nThis bead *creates/expands* test infrastructure; verify it with meta-tests.\n\n### Meta/Infrastructure Tests\n- [ ] CI can run unit, integration, contract, and E2E suites with deterministic exit codes\n- [ ] Failures capture artifacts (logs, screenshots/traces, fixtures) and keep them discoverable\n- [ ] Coverage reporting works (and fails the build when below configured thresholds)\n\n### Logging\n- [ ] Test runs emit structured summaries (suite duration, slow tests, flakes) and preserve correlation IDs\n","notes":"## Relationship to flywheel_gateway-d8b\n\nThis bead (tz4) implements the **actual test suite** based on the infrastructure and standards established in d8b.\n\n- **d8b (Testing Infrastructure and Standards)**: Establishes the testing framework, utilities, patterns, and standards that ALL feature beads must follow\n- **tz4 (Comprehensive Testing Suite)**: Implements the full test coverage using d8b's infrastructure\n\nd8b answers: HOW do we test? (frameworks, utilities, patterns)\ntz4 answers: WHAT do we test? (specific tests, coverage)\n\nAll feature beads include their own testing requirements which reference d8b standards. tz4 ensures these are actually implemented and tracks overall coverage metrics.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T13:57:53.624078971-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:30:24.552207085-05:00","labels":["phase-4","production-ready"],"dependencies":[{"issue_id":"flywheel_gateway-tz4","depends_on_id":"flywheel_gateway-f9d","type":"blocks","created_at":"2026-01-08T14:01:56.803040983-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-tz4","depends_on_id":"flywheel_gateway-d8b","type":"blocks","created_at":"2026-01-08T17:23:43.007696106-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-w4g","title":"FEAT: Basic REST API (Spawn, Terminate, List, Send)","description":"## Background\n\nThe REST API is the primary interface for clients to interact with the Flywheel Gateway. It exposes agent lifecycle operations (spawn, terminate, list) and communication endpoints (send messages, get output).\n\nThe API design follows REST conventions while accommodating the unique needs of agent orchestration - long-running operations, streaming responses, and event-driven state changes.\n\n## Technical Rationale\n\n### Why Hono?\n- **Performance**: Built on Web Standards (Request/Response), extremely fast\n- **TypeScript First**: Excellent type inference and validation\n- **Middleware Ecosystem**: Easy to compose with auth, logging, validation\n- **Edge Ready**: Works in Node, Deno, Bun, and edge runtimes\n- **Small Footprint**: Minimal dependencies, fast cold starts\n\n### Command Registry Pattern\nRoutes are generated from a declarative command registry:\n- Single source of truth for all commands\n- Automatic OpenAPI schema generation\n- Consistent validation and error handling\n- Easy to extend with new commands\n\n### Correlation IDs\nEvery request gets a correlation ID that flows through:\n- API logs\n- Agent driver calls\n- WebSocket messages\n- Error responses\n\nThis enables end-to-end request tracing.\n\n## Scope \u0026 Requirements\n\n### Core Endpoints\n\n```typescript\n// Agent Lifecycle\nPOST   /agents                    // Spawn new agent\nGET    /agents                    // List agents (with filters)\nGET    /agents/:agentId           // Get agent details\nDELETE /agents/:agentId           // Terminate agent\n\n// Agent Communication\nPOST   /agents/:agentId/send      // Send message to agent\nPOST   /agents/:agentId/interrupt // Send interrupt signal\nGET    /agents/:agentId/output    // Get output (polling, with cursor)\n\n// Health \u0026 Info\nGET    /health                    // Health check\nGET    /health/ready              // Readiness probe\nGET    /info                      // API version and capabilities\n```\n\n### Request/Response Schemas\n\n**POST /agents - Spawn Agent**\n\n```typescript\n// Request\ninterface SpawnRequest {\n  // Required\n  workingDirectory: string;\n  \n  // Optional\n  agentId?: string;              // Auto-generated if not provided\n  systemPrompt?: string;\n  environment?: Record\u003cstring, string\u003e;\n  timeout?: number;              // Default: 3600000 (1 hour)\n  maxTokens?: number;            // Default: 100000\n  driver?: 'sdk' | 'docker';     // Default: 'sdk'\n  \n  // PTY configuration\n  pty?: {\n    enabled: boolean;\n    cols?: number;               // Default: 80\n    rows?: number;               // Default: 24\n  };\n  \n  // Tool configuration\n  tools?: {\n    enabled: string[];           // Tool names to enable\n    disabled: string[];          // Tool names to disable\n    custom?: ToolDefinition[];   // Custom tool definitions\n  };\n  \n  // MCP servers\n  mcpServers?: McpServerConfig[];\n}\n\n// Response (201 Created)\ninterface SpawnResponse {\n  agentId: string;\n  state: 'spawning' | 'ready';\n  createdAt: string;\n  driver: string;\n  \n  links: {\n    self: string;\n    output: string;\n    ws: string;\n  };\n}\n```\n\n**GET /agents - List Agents**\n\n```typescript\n// Query Parameters\ninterface ListAgentsQuery {\n  state?: AgentState[];          // Filter by state\n  driver?: string[];             // Filter by driver\n  createdAfter?: string;         // ISO timestamp\n  createdBefore?: string;\n  limit?: number;                // Default: 50, max: 200\n  cursor?: string;               // Pagination cursor\n}\n\n// Response (200 OK)\ninterface ListAgentsResponse {\n  agents: AgentSummary[];\n  pagination: {\n    cursor?: string;             // Next page cursor\n    hasMore: boolean;\n    total?: number;              // If countable\n  };\n}\n\ninterface AgentSummary {\n  agentId: string;\n  state: AgentState;\n  driver: string;\n  createdAt: string;\n  lastActivityAt: string;\n  \n  links: {\n    self: string;\n  };\n}\n```\n\n**GET /agents/:agentId - Get Agent**\n\n```typescript\n// Response (200 OK)\ninterface GetAgentResponse {\n  agentId: string;\n  state: AgentState;\n  driver: string;\n  createdAt: string;\n  lastActivityAt: string;\n  \n  config: {\n    workingDirectory: string;\n    timeout: number;\n    maxTokens: number;\n    pty: boolean;\n  };\n  \n  stats: {\n    messagesReceived: number;\n    messagesSent: number;\n    tokensUsed: number;\n    toolCalls: number;\n  };\n  \n  links: {\n    self: string;\n    output: string;\n    ws: string;\n    terminate: string;\n  };\n}\n```\n\n**DELETE /agents/:agentId - Terminate Agent**\n\n```typescript\n// Query Parameters\ninterface TerminateQuery {\n  graceful?: boolean;            // Default: true\n  timeout?: number;              // Graceful shutdown timeout\n}\n\n// Response (202 Accepted)\ninterface TerminateResponse {\n  agentId: string;\n  state: 'terminating';\n  terminatedAt?: string;         // Set when complete\n}\n```\n\n**POST /agents/:agentId/send - Send Message**\n\n```typescript\n// Request\ninterface SendMessageRequest {\n  type: 'user' | 'system';\n  content: string;\n  \n  // Optional streaming config\n  stream?: boolean;              // Return streaming response\n  \n  // Optional context\n  attachments?: Attachment[];\n}\n\n// Response (200 OK) - Non-streaming\ninterface SendMessageResponse {\n  messageId: string;\n  receivedAt: string;\n  state: 'queued' | 'processing';\n}\n\n// Response (200 OK) - Streaming\n// Server-Sent Events stream\n// event: output\n// data: {\"type\": \"text\", \"content\": \"...\"}\n```\n\n**POST /agents/:agentId/interrupt - Interrupt Agent**\n\n```typescript\n// Request\ninterface InterruptRequest {\n  signal?: 'SIGINT' | 'SIGTSTP' | 'SIGCONT';  // Default: 'SIGINT'\n}\n\n// Response (200 OK)\ninterface InterruptResponse {\n  agentId: string;\n  signal: string;\n  sentAt: string;\n  previousState: AgentState;\n}\n```\n\n**GET /agents/:agentId/output - Get Output**\n\n```typescript\n// Query Parameters\ninterface GetOutputQuery {\n  cursor?: string;               // Resume from cursor\n  limit?: number;                // Max chunks (default: 100)\n  types?: OutputType[];          // Filter by type\n  wait?: number;                 // Long-poll timeout ms\n}\n\n// Response (200 OK)\ninterface GetOutputResponse {\n  chunks: OutputChunk[];\n  pagination: {\n    cursor: string;              // Next cursor\n    hasMore: boolean;\n  };\n}\n```\n\n### Middleware Stack\n\n```typescript\n// Applied to all routes\napp.use(correlationId());        // Inject/propagate correlation ID\napp.use(requestLogger());        // Log all requests\napp.use(errorHandler());         // Convert errors to GatewayError responses\n\n// Applied to authenticated routes\napp.use('/agents/*', authenticate());  // Validate auth token\napp.use('/agents/*', authorize());     // Check permissions\napp.use('/agents/*', rateLimit());     // Per-workspace rate limiting\n\n// Applied to specific routes\napp.use('/agents', validateBody(SpawnRequestSchema));\n```\n\n### Correlation ID Middleware\n\n```typescript\ninterface CorrelationIdConfig {\n  header: string;                // Default: 'x-correlation-id'\n  generator: () =\u003e string;       // Default: nanoid()\n}\n\n// Middleware injects correlationId into context\n// Available via c.get('correlationId')\n// Automatically added to all response headers\n```\n\n### Zod Schemas\n\n```typescript\n// packages/shared/src/schemas/api.ts\n\nexport const SpawnRequestSchema = z.object({\n  workingDirectory: z.string().min(1),\n  agentId: z.string().optional(),\n  systemPrompt: z.string().optional(),\n  environment: z.record(z.string()).optional(),\n  timeout: z.number().min(1000).max(86400000).optional(),\n  maxTokens: z.number().min(1000).max(1000000).optional(),\n  driver: z.enum(['sdk', 'docker']).optional(),\n  pty: z.object({\n    enabled: z.boolean(),\n    cols: z.number().min(1).max(500).optional(),\n    rows: z.number().min(1).max(500).optional(),\n  }).optional(),\n  tools: z.object({\n    enabled: z.array(z.string()).optional(),\n    disabled: z.array(z.string()).optional(),\n    custom: z.array(ToolDefinitionSchema).optional(),\n  }).optional(),\n  mcpServers: z.array(McpServerConfigSchema).optional(),\n});\n\n// Validation middleware\nfunction validateBody\u003cT\u003e(schema: z.ZodSchema\u003cT\u003e) {\n  return async (c: Context, next: Next) =\u003e {\n    const result = schema.safeParse(await c.req.json());\n    if (!result.success) {\n      throw new ValidationError(result.error);\n    }\n    c.set('body', result.data);\n    await next();\n  };\n}\n```\n\n### Error Responses\n\nAll errors follow the GatewayError format:\n\n```typescript\n// 4xx/5xx Response\ninterface ErrorResponse {\n  error: {\n    code: ErrorCode;\n    message: string;\n    httpStatus: number;\n    aiHint: AiHint;\n    correlationId: string;\n    timestamp: string;\n    context?: Record\u003cstring, unknown\u003e;\n  };\n}\n\n// Example 404\n{\n  \"error\": {\n    \"code\": \"AGENT_NOT_FOUND\",\n    \"message\": \"Agent 'agent-xyz' does not exist or has been terminated\",\n    \"httpStatus\": 404,\n    \"aiHint\": {\n      \"severity\": \"terminal\",\n      \"suggestedAction\": \"List available agents with GET /agents\"\n    },\n    \"correlationId\": \"req-abc123\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n### Health Endpoints\n\n```typescript\n// GET /health - Liveness probe (always 200 if server running)\ninterface HealthResponse {\n  status: 'healthy';\n  timestamp: string;\n}\n\n// GET /health/ready - Readiness probe (checks dependencies)\ninterface ReadyResponse {\n  status: 'ready' | 'degraded' | 'unhealthy';\n  checks: {\n    database: CheckResult;\n    drivers: Record\u003cstring, CheckResult\u003e;\n    websocket: CheckResult;\n  };\n  timestamp: string;\n}\n\ninterface CheckResult {\n  status: 'pass' | 'fail' | 'warn';\n  message?: string;\n  latencyMs?: number;\n}\n```\n\n## File Structure\n\n```\napps/gateway/src/routes/\n├── index.ts                 # Route aggregation and app setup\n├── agents/\n│   ├── index.ts             # /agents routes\n│   ├── spawn.ts             # POST /agents\n│   ├── list.ts              # GET /agents\n│   ├── get.ts               # GET /agents/:agentId\n│   ├── terminate.ts         # DELETE /agents/:agentId\n│   ├── send.ts              # POST /agents/:agentId/send\n│   ├── interrupt.ts         # POST /agents/:agentId/interrupt\n│   └── output.ts            # GET /agents/:agentId/output\n├── health/\n│   ├── index.ts             # Health routes\n│   ├── liveness.ts          # GET /health\n│   └── readiness.ts         # GET /health/ready\n├── middleware/\n│   ├── correlation-id.ts\n│   ├── request-logger.ts\n│   ├── error-handler.ts\n│   ├── authenticate.ts\n│   ├── authorize.ts\n│   ├── rate-limit.ts\n│   └── validate.ts\n└── __tests__/\n    ├── agents.test.ts\n    ├── health.test.ts\n    └── middleware.test.ts\n```\n\n## References\n\n- PLAN.md §8 - REST API Specification\n- PLAN.md §8.1 - Endpoint Definitions\n- PLAN.md §8.2 - Request/Response Schemas\n- PLAN.md §8.3 - Middleware Pipeline\n- PLAN.md §8.5 - Error Response Format\n- OpenAPI 3.1 Specification\n\n## Acceptance Criteria\n\n- [ ] All core endpoints implemented and returning correct status codes\n- [ ] Request validation with Zod schemas on all endpoints\n- [ ] Correlation ID middleware injects/propagates IDs\n- [ ] Error responses match GatewayError format with AI hints\n- [ ] Health endpoints report service status accurately\n- [ ] Readiness probe checks all dependencies\n- [ ] Request logging captures method, path, status, duration\n- [ ] Rate limiting enforced per-workspace\n- [ ] OpenAPI schema generated from route definitions\n- [ ] Unit tests for all route handlers\n- [ ] Integration tests for full request/response cycles\n- [ ] Streaming response works for send endpoint\n- [ ] Pagination works correctly for list endpoint\n- [ ] Long-polling works for output endpoint\n\n\n## Testing Requirements\n\nReference: `flywheel_gateway-d8b`.\n\n### Unit Tests\n- [ ] Middleware: correlation ID injection, error handler mapping, auth stubs, and validation behavior\n- [ ] Route handlers return correct status codes and response envelopes\n\n### Integration Tests\n- [ ] Core lifecycle endpoints (spawn/list/get/terminate) with realistic state transitions\n- [ ] Send/interrupt/output endpoints handle busy/terminated/not-found states correctly\n- [ ] Health endpoints reflect dependency status accurately\n\n### Contract Tests\n- [ ] Responses validate against OpenAPI schemas (success + error envelopes)\n\n### Failure Mode Tests\n- [ ] Invalid payloads → validation errors with field-level hints\n- [ ] Dependency failures (driver/db/ws) → correct error codes and no partial writes\n\n### Logging\n- [ ] Request logs include method/path/status/duration + correlationId; sensitive headers are redacted\n","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] SpawnController: validates required fields (workingDirectory)\n- [ ] SpawnController: generates agentId when not provided\n- [ ] ListController: applies state filters correctly\n- [ ] ListController: applies driver filters correctly\n- [ ] ListController: pagination cursor encoding/decoding\n- [ ] GetController: returns 404 for non-existent agent\n- [ ] TerminateController: graceful shutdown sends SIGTERM first\n- [ ] TerminateController: forced shutdown after timeout\n- [ ] SendController: validates message type (user/system)\n- [ ] InterruptController: maps signal names to codes\n- [ ] OutputController: cursor-based pagination\n- [ ] OutputController: long-poll timeout behavior\n- [ ] HealthController: liveness always returns 200\n- [ ] ReadinessController: checks all dependencies\n- [ ] Correlation ID middleware: generates ID if missing\n- [ ] Correlation ID middleware: propagates existing ID\n- [ ] Error handler middleware: formats GatewayError correctly\n- [ ] Error handler middleware: includes AI hints in response\n- [ ] Rate limit middleware: enforces per-workspace limits\n- [ ] Validation middleware: Zod schema parsing\n\n### Integration Tests\n- [ ] POST /agents spawns agent and returns 201 with links\n- [ ] GET /agents returns paginated list with correct totals\n- [ ] GET /agents?state=running filters correctly\n- [ ] GET /agents/:id returns full agent details\n- [ ] DELETE /agents/:id terminates agent and returns 202\n- [ ] POST /agents/:id/send queues message for agent\n- [ ] POST /agents/:id/send?stream=true returns SSE stream\n- [ ] POST /agents/:id/interrupt sends signal to agent\n- [ ] GET /agents/:id/output returns chunks with cursor\n- [ ] GET /agents/:id/output?wait=5000 long-polls correctly\n- [ ] GET /health returns 200 with timestamp\n- [ ] GET /health/ready checks all service dependencies\n- [ ] Error response includes correlationId from request\n- [ ] Rate limiting returns 429 after threshold exceeded\n\n### E2E Tests\n- [ ] Full lifecycle: spawn -\u003e send message -\u003e get output -\u003e terminate\n- [ ] Streaming: spawn -\u003e send -\u003e receive SSE output chunks\n- [ ] Reconnection: output cursor resumes after disconnect\n\n### Performance Tests\n- [ ] GET /agents list returns \u003c50ms for 100 agents\n- [ ] POST /agents spawns in \u003c500ms\n- [ ] GET /health returns \u003c5ms\n- [ ] Long-poll holds connection for specified timeout\n\n### Failure Mode Tests\n- [ ] Spawn with invalid workingDirectory returns 400\n- [ ] Send to terminated agent returns 410 AGENT_TERMINATED\n- [ ] Database unavailable: readiness returns degraded\n- [ ] SDK driver unavailable: spawn returns appropriate error","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:33:00.267805921-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:11:02.313191899-05:00","labels":["api","foundation","phase-1"],"dependencies":[{"issue_id":"flywheel_gateway-w4g","depends_on_id":"flywheel_gateway-2kf","type":"blocks","created_at":"2026-01-08T14:01:45.816125568-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-w4g","depends_on_id":"flywheel_gateway-6mn","type":"blocks","created_at":"2026-01-08T14:01:46.596589598-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-w4g","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T14:01:48.98288201-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-w55","title":"FEAT: SDK Agent Driver Implementation","description":"## Background\n\nThe SDK Agent Driver is the primary mechanism for spawning and managing Claude Code agents within the Flywheel Gateway. It wraps the official `@anthropic-ai/claude-agent-sdk` package, providing a consistent interface that can be extended with alternative drivers (Docker, remote, mock) in the future.\n\nThis driver is the heart of agent lifecycle management - it must handle the full spectrum of agent states, gracefully manage failures, and provide clean abstractions for the gateway layer above.\n\n## Technical Rationale\n\n### Why an AgentDriver Interface?\n- **Pluggability**: Different environments need different agent backends (local SDK, Docker containers, remote clusters)\n- **Testability**: Mock drivers enable gateway testing without spawning real agents\n- **Future-Proofing**: New agent types (Claude 4, custom models) plug in via new drivers\n\n### State Machine Design\nAgents have complex lifecycles. A formal state machine prevents invalid transitions and makes behavior predictable:\n\n```\n                    ┌─────────────────────────────────────────┐\n                    │                                         │\n                    ▼                                         │\n┌─────────┐    ┌──────────┐    ┌─────────┐    ┌───────────┐  │\n│ pending │───▶│ spawning │───▶│  ready  │◀──▶│ executing │──┤\n└─────────┘    └──────────┘    └─────────┘    └───────────┘  │\n                    │               │              │          │\n                    │               │              │          │\n                    ▼               ▼              ▼          │\n               ┌─────────────────────────────────────────┐   │\n               │              terminated                  │◀──┘\n               └─────────────────────────────────────────┘\n```\n\nValid transitions:\n- `pending → spawning`: Driver begins spawn process\n- `spawning → ready`: Agent process started, SDK connected\n- `spawning → terminated`: Spawn failed\n- `ready → executing`: Command sent to agent\n- `executing → ready`: Command completed\n- `executing → paused`: Interrupt received (SIGTSTP equivalent)\n- `paused → executing`: Resume command sent\n- `* → terminated`: Terminate called or fatal error\n\n### PTY Integration\nAgents need terminal I/O for:\n- Interactive tool use (editors, REPLs)\n- Proper signal handling (Ctrl+C, Ctrl+Z)\n- Terminal resize events\n- Raw mode for special characters\n\n## Scope \u0026 Requirements\n\n### AgentDriver Interface\n\n```typescript\ninterface AgentDriver {\n  readonly driverId: string;\n  readonly driverType: 'sdk' | 'docker' | 'remote' | 'mock';\n  \n  // Lifecycle\n  spawn(config: SpawnConfig): Promise\u003cAgentHandle\u003e;\n  terminate(agentId: string, options?: TerminateOptions): Promise\u003cvoid\u003e;\n  \n  // Communication\n  send(agentId: string, message: AgentMessage): Promise\u003cvoid\u003e;\n  interrupt(agentId: string, signal?: InterruptSignal): Promise\u003cvoid\u003e;\n  \n  // State\n  getState(agentId: string): AgentState;\n  getOutput(agentId: string, cursor?: string): AsyncIterable\u003cOutputChunk\u003e;\n  \n  // Events\n  on(event: DriverEvent, handler: DriverEventHandler): void;\n  off(event: DriverEvent, handler: DriverEventHandler): void;\n}\n\ninterface SpawnConfig {\n  agentId: string;\n  workingDirectory: string;\n  environment?: Record\u003cstring, string\u003e;\n  pty?: PtyConfig;\n  timeout?: number;\n  maxTokens?: number;\n  systemPrompt?: string;\n  tools?: ToolDefinition[];\n  mcpServers?: McpServerConfig[];\n}\n\ninterface AgentHandle {\n  agentId: string;\n  state: AgentState;\n  createdAt: Date;\n  pid?: number;\n  ptyFd?: number;\n}\n\ninterface TerminateOptions {\n  graceful?: boolean;      // Try SIGTERM before SIGKILL\n  timeoutMs?: number;      // Max time to wait for graceful shutdown\n  preserveOutput?: boolean; // Keep output in buffer after termination\n}\n\ntype InterruptSignal = 'SIGINT' | 'SIGTSTP' | 'SIGCONT' | 'SIGHUP';\n```\n\n### SDK Driver Specifics\n\nThe SDK driver wraps `@anthropic-ai/claude-agent-sdk`:\n\n```typescript\nclass SdkAgentDriver implements AgentDriver {\n  readonly driverId = 'sdk-primary';\n  readonly driverType = 'sdk';\n  \n  private agents: Map\u003cstring, SdkAgentContext\u003e;\n  private eventEmitter: EventEmitter;\n  \n  constructor(private config: SdkDriverConfig) {}\n  \n  async spawn(config: SpawnConfig): Promise\u003cAgentHandle\u003e {\n    // 1. Validate config\n    // 2. Create PTY if requested\n    // 3. Initialize SDK agent\n    // 4. Set up message handlers\n    // 5. Transition to ready state\n    // 6. Return handle\n  }\n}\n\ninterface SdkDriverConfig {\n  apiKey: string;\n  model?: string;           // Default: claude-sonnet-4-20250514\n  maxConcurrentAgents: number;\n  defaultTimeout: number;\n  ptyEnabled: boolean;\n}\n```\n\n### PTY Management\n\n```typescript\ninterface PtyConfig {\n  cols: number;\n  rows: number;\n  term?: string;          // Default: 'xterm-256color'\n  cwd?: string;\n  env?: Record\u003cstring, string\u003e;\n}\n\ninterface PtyHandle {\n  fd: number;\n  pid: number;\n  \n  write(data: string | Buffer): void;\n  resize(cols: number, rows: number): void;\n  kill(signal?: string): void;\n  \n  onData(callback: (data: Buffer) =\u003e void): void;\n  onExit(callback: (code: number, signal?: string) =\u003e void): void;\n}\n```\n\n### Output Streaming\n\nOutput is streamed via async iterables with cursor support for replay:\n\n```typescript\ninterface OutputChunk {\n  cursor: string;           // Opaque cursor for resumption\n  timestamp: Date;\n  type: 'stdout' | 'stderr' | 'system' | 'tool_use' | 'tool_result';\n  content: string | ToolUseContent | ToolResultContent;\n  metadata?: {\n    tokenCount?: number;\n    toolName?: string;\n    executionMs?: number;\n  };\n}\n\n// Usage\nfor await (const chunk of driver.getOutput(agentId, lastCursor)) {\n  // Process chunk\n  lastCursor = chunk.cursor;\n}\n```\n\n### Event System\n\n```typescript\ntype DriverEvent = \n  | 'agent:spawning'\n  | 'agent:ready'\n  | 'agent:executing'\n  | 'agent:paused'\n  | 'agent:terminated'\n  | 'agent:error'\n  | 'output:chunk'\n  | 'driver:health';\n\ninterface DriverEventPayload {\n  agentId: string;\n  timestamp: Date;\n  previousState?: AgentState;\n  newState?: AgentState;\n  error?: GatewayError;\n  chunk?: OutputChunk;\n}\n```\n\n## File Structure\n\n```\npackages/agent-drivers/src/sdk/\n├── index.ts                 # Public exports\n├── driver.ts                # SdkAgentDriver implementation\n├── types.ts                 # TypeScript interfaces\n├── state-machine.ts         # Agent state machine\n├── pty-manager.ts           # PTY creation and management\n├── output-buffer.ts         # Cursor-based output buffering\n├── message-handler.ts       # SDK message processing\n├── health-check.ts          # Driver health monitoring\n└── __tests__/\n    ├── driver.test.ts\n    ├── state-machine.test.ts\n    └── pty-manager.test.ts\n```\n\n## References\n\n- PLAN.md §5 - Agent Driver Architecture\n- PLAN.md §6 - Agent Lifecycle States\n- PLAN.md §7 - PTY Integration Requirements\n- @anthropic-ai/claude-agent-sdk documentation\n\n## Acceptance Criteria\n\n- [ ] AgentDriver interface defined with full TypeScript types\n- [ ] SdkAgentDriver implements all interface methods\n- [ ] State machine enforces valid transitions only\n- [ ] PTY manager creates and manages pseudo-terminals\n- [ ] Output buffer supports cursor-based iteration\n- [ ] Events emitted on all state transitions\n- [ ] Graceful termination with configurable timeout\n- [ ] Health check endpoint for driver status\n- [ ] Unit tests for state machine transitions\n- [ ] Integration tests with mock SDK (no real API calls in tests)\n- [ ] Memory cleanup on agent termination\n- [ ] Error handling maps SDK errors to GatewayError\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] SDKDriver.spawn: creates session with correct config\n- [ ] SDKDriver.spawn: returns Agent with spawning state\n- [ ] SDKDriver.send: forwards message to SDK session\n- [ ] SDKDriver.interrupt: sends interrupt signal to session\n- [ ] SDKDriver.getOutput: returns output lines since cursor\n- [ ] SDKDriver.subscribe: yields events from session\n- [ ] SDKDriver.terminate: gracefully terminates session\n- [ ] SDKDriver.getCapabilities: returns correct capabilities\n- [ ] State machine: pending -\u003e spawning transition valid\n- [ ] State machine: spawning -\u003e ready transition on success\n- [ ] State machine: spawning -\u003e terminated on spawn failure\n- [ ] State machine: ready -\u003e executing on command send\n- [ ] State machine: executing -\u003e ready on command complete\n- [ ] State machine: invalid transitions throw error\n- [ ] PTY configuration: cols/rows passed to session\n- [ ] PTY resize: updates session dimensions\n- [ ] Model selection: claude uses ClaudeClient\n- [ ] Model selection: codex uses CodexClient\n- [ ] Model selection: gemini uses GeminiClient\n- [ ] Event mapping: SDK events to AgentEvents\n\n### Integration Tests\n- [ ] Spawn Claude agent with mock credentials\n- [ ] Send message and receive output stream\n- [ ] Interrupt running agent\n- [ ] Terminate agent gracefully\n- [ ] State transitions emit correct WebSocket events\n- [ ] Error recovery: reconnect on transient failure\n- [ ] Context window tracking: reports token usage\n\n### E2E Tests\n- [ ] Full agent lifecycle with real SDK (if credentials available)\n- [ ] Mock driver: spawn -\u003e send -\u003e output -\u003e terminate\n- [ ] Multiple agents running concurrently\n- [ ] Agent rotation on context window limit\n\n### Performance Tests\n- [ ] Spawn time \u003c2s for Claude agent\n- [ ] Event streaming latency \u003c100ms\n- [ ] Output buffer doesn't grow unbounded\n- [ ] Memory usage per agent \u003c100MB\n\n### Failure Mode Tests\n- [ ] Invalid credentials: spawn returns error with hint\n- [ ] SDK timeout: spawn fails gracefully\n- [ ] Session crash: agent transitions to terminated\n- [ ] Network disconnect: reconnect or fail gracefully\n- [ ] Rate limit from provider: appropriate error returned\n\n### Logging\n- [ ] Driver tests log agentId + state transitions + correlationId (never secrets)\n- [ ] Mock-SDK integration tests log emitted events and output cursors for diagnosis\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-08T13:32:57.205606459-05:00","created_by":"ubuntu","updated_at":"2026-01-08T18:32:41.594843795-05:00","labels":["drivers","foundation","phase-1"],"dependencies":[{"issue_id":"flywheel_gateway-w55","depends_on_id":"flywheel_gateway-ls4","type":"blocks","created_at":"2026-01-08T14:01:42.493730547-05:00","created_by":"ubuntu"}]}
{"id":"flywheel_gateway-xs1","title":"feat","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:46:51.506885719-05:00","created_by":"ubuntu","updated_at":"2026-01-08T14:00:25.446266954-05:00","closed_at":"2026-01-08T14:00:25.446266954-05:00","close_reason":"Empty placeholder beads created in error"}
{"id":"flywheel_gateway-zno","title":"RU (Repo Updater) Integration","description":"## Overview\n\nRU (Repo Updater) Integration brings fleet management capabilities to Flywheel Gateway, enabling synchronized operations across multiple repositories. This is essential for organizations managing microservices architectures or monorepo ecosystems where changes must propagate consistently.\n\n## Background \u0026 Reasoning\n\nModern software organizations often manage dozens or hundreds of repositories. When making cross-cutting changes (dependency updates, security patches, API migrations), manual coordination becomes impractical. RU provides:\n\n- Centralized visibility into repository health across the fleet\n- Automated synchronization with intelligent conflict handling\n- Agent-sweep orchestration for bulk operations\n- Approval workflows for safe execution\n\nThe integration with Flywheel Gateway allows AI agents to participate in fleet-wide operations under human supervision.\n\n## Repository Status Model\n\nEach repository in the fleet can be in one of six states:\n\n```typescript\ntype RepositoryStatus = \n  | 'current'   // Up-to-date with upstream, clean working tree\n  | 'behind'    // Local is behind upstream, no local changes\n  | 'ahead'     // Local has unpushed commits\n  | 'diverged'  // Both local and upstream have new commits\n  | 'dirty'     // Uncommitted local changes\n  | 'conflict'; // Merge conflicts present\n```\n\n## Agent-Sweep Orchestration\n\nThe three-phase agent-sweep model ensures safe bulk operations:\n\n### Phase 1: Analyze\n- Scan all fleet repositories for status\n- Identify candidates for operation (e.g., repos with outdated dependency)\n- Generate impact assessment report\n- No modifications made\n\n### Phase 2: Plan\n- Generate specific changes for each repository\n- Create preview branches with proposed changes\n- Run CI validation on preview branches\n- Produce human-readable diff summaries\n\n### Phase 3: Execute\n- **REQUIRES HUMAN APPROVAL**\n- Apply planned changes to target branches\n- Create PRs or direct commits as configured\n- Report success/failure per repository\n- Rollback support for failed operations\n\n## Technical Architecture\n\n### Fleet Service\n\n```typescript\ninterface FleetService {\n  // Fleet Discovery\n  discoverRepositories(config: DiscoveryConfig): Promise\u003cRepository[]\u003e;\n  addRepository(repo: RepositoryConfig): Promise\u003cRepository\u003e;\n  removeRepository(repoId: string): Promise\u003cvoid\u003e;\n  \n  // Status Tracking\n  getFleetStatus(): Promise\u003cFleetStatusReport\u003e;\n  getRepositoryStatus(repoId: string): Promise\u003cRepositoryStatus\u003e;\n  watchFleetStatus(callback: StatusCallback): Unsubscribe;\n  \n  // Sync Operations\n  syncRepository(repoId: string, options: SyncOptions): Promise\u003cSyncResult\u003e;\n  syncFleet(options: FleetSyncOptions): Promise\u003cFleetSyncResult\u003e;\n  \n  // Agent-Sweep\n  startSweep(config: SweepConfig): Promise\u003cSweep\u003e;\n  advanceSweepPhase(sweepId: string): Promise\u003cSweep\u003e;\n  approveSweepExecution(sweepId: string, approver: User): Promise\u003cSweep\u003e;\n  cancelSweep(sweepId: string): Promise\u003cvoid\u003e;\n}\n\ninterface Sweep {\n  id: string;\n  phase: 'analyze' | 'plan' | 'execute' | 'complete' | 'cancelled';\n  repositories: SweepRepository[];\n  createdAt: Date;\n  approvedBy?: User;\n  approvedAt?: Date;\n  results?: SweepResults;\n}\n\ninterface SweepRepository {\n  repository: Repository;\n  status: 'pending' | 'in-progress' | 'success' | 'failed' | 'skipped';\n  analysis?: AnalysisResult;\n  plan?: PlanResult;\n  execution?: ExecutionResult;\n}\n```\n\n### Approval Workflow\n\nPhase 3 execution requires explicit human approval:\n\n1. Sweep reaches 'plan' phase completion\n2. System generates approval request with:\n   - Summary of all planned changes\n   - Risk assessment score\n   - Affected repository list\n   - Rollback procedure\n3. Authorized user reviews and approves/rejects\n4. Approval recorded with user identity and timestamp\n5. Execution proceeds or sweep cancelled\n\n## Frontend Components\n\n### FleetDashboard.tsx\n- Grid view of all fleet repositories\n- Status indicators with color coding\n- Quick filters (by status, by tag, by team)\n- Bulk action controls\n\n### SweepWizard.tsx\n- Step-by-step sweep configuration\n- Phase progress visualization\n- Approval interface for Phase 3\n- Results summary view\n\n### RepositoryCard.tsx\n- Individual repository status display\n- Quick sync actions\n- Recent operation history\n- Link to repository details\n\n### FleetStatusChart.tsx\n- Aggregate fleet health visualization\n- Trend graphs for sync status over time\n- Alert indicators for attention-needed repos\n\n## File Locations\n\n- `apps/gateway/src/services/fleet.service.ts` - Core fleet management\n- `apps/gateway/src/services/sweep.service.ts` - Agent-sweep orchestration\n- `apps/gateway/src/services/approval.service.ts` - Approval workflow\n- `apps/gateway/src/controllers/fleet.controller.ts` - REST API endpoints\n- `apps/web/src/components/fleet/FleetDashboard.tsx` - Main dashboard\n- `apps/web/src/components/fleet/SweepWizard.tsx` - Sweep configuration UI\n- `apps/web/src/components/fleet/RepositoryCard.tsx` - Repository display\n- `apps/web/src/components/fleet/FleetStatusChart.tsx` - Status visualization\n- `apps/web/src/components/fleet/ApprovalDialog.tsx` - Phase 3 approval UI\n\n## Database Schema\n\n```sql\nCREATE TABLE fleet_repositories (\n  id UUID PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  url VARCHAR(500) NOT NULL,\n  status VARCHAR(50) DEFAULT 'unknown',\n  last_sync TIMESTAMP,\n  last_status_check TIMESTAMP,\n  metadata JSONB,\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE sweeps (\n  id UUID PRIMARY KEY,\n  phase VARCHAR(50) NOT NULL,\n  config JSONB NOT NULL,\n  created_by UUID REFERENCES users(id),\n  approved_by UUID REFERENCES users(id),\n  approved_at TIMESTAMP,\n  completed_at TIMESTAMP,\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE sweep_repositories (\n  id UUID PRIMARY KEY,\n  sweep_id UUID REFERENCES sweeps(id),\n  repository_id UUID REFERENCES fleet_repositories(id),\n  status VARCHAR(50) DEFAULT 'pending',\n  analysis JSONB,\n  plan JSONB,\n  execution JSONB,\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE approval_requests (\n  id UUID PRIMARY KEY,\n  sweep_id UUID REFERENCES sweeps(id),\n  requested_at TIMESTAMP DEFAULT NOW(),\n  decision VARCHAR(50),\n  decided_by UUID REFERENCES users(id),\n  decided_at TIMESTAMP,\n  notes TEXT\n);\n```\n\n## Acceptance Criteria\n\n- [ ] Fleet discovery scans and catalogs repositories from configured sources\n- [ ] Repository status updates within 60 seconds of changes\n- [ ] Fleet dashboard displays 100+ repositories without performance degradation\n- [ ] Agent-sweep Phase 1 (analyze) completes for 50 repos in \u003c5 minutes\n- [ ] Agent-sweep Phase 2 (plan) creates preview branches with validated changes\n- [ ] Phase 3 execution blocked until explicit human approval received\n- [ ] Approval audit trail captures approver identity and timestamp\n- [ ] Failed operations trigger automatic rollback where possible\n- [ ] WebSocket updates push status changes to connected clients\n- [ ] Fleet sync handles network failures with retry logic\n\n## Testing Requirements\n\n- Unit tests for status calculation logic\n- Integration tests for sweep phase transitions\n- E2E tests for complete sweep workflow including approval\n- Load tests for fleet operations at scale (500+ repos)\n- Security tests for approval workflow bypass attempts\n\n## Security Considerations\n\n- Phase 3 approval requires elevated permissions\n- All sweep operations logged with actor identity\n- Repository credentials encrypted at rest\n- Network operations use TLS\n- Rate limiting on bulk operations\n\n## References\n\n- PLAN.md §17.5 - RU Integration Architecture\n- Repository fleet management patterns\n- GitOps workflow documentation","notes":"## Testing Requirements\n\n### Unit Tests\n- [ ] RUClient.sync: calls ru sync correctly\n- [ ] RUClient.status: parses repo status\n- [ ] RUClient.agentSweep: initiates sweep\n- [ ] RepoStatus: maps status codes\n- [ ] RepoStatus: detects behind/ahead\n- [ ] RepoStatus: detects conflicts\n- [ ] SweepPhase: tracks phase progress\n- [ ] SweepPhase: stores phase results\n- [ ] SweepPlan: parses JSON plan\n- [ ] SweepPlan: validates plan schema\n- [ ] Approval: routes phase 3 plans\n- [ ] Approval: applies approved plans\n\n### Integration Tests\n- [ ] GET /fleet/repos returns list\n- [ ] GET /fleet/repos/:id/status returns state\n- [ ] POST /fleet/sync triggers sync\n- [ ] POST /fleet/repos/:id/sweep starts sweep\n- [ ] Sweep phases progress correctly\n- [ ] Phase 3 requires approval\n- [ ] Approved sweep executes\n- [ ] Results archived to CASS\n\n### E2E Tests\n- [ ] Fleet dashboard shows repos\n- [ ] Sync updates all repos\n- [ ] Agent-sweep runs three phases\n- [ ] User approves phase 3 plan\n\n### Performance Tests\n- [ ] Status check \u003c100ms per repo\n- [ ] Parallel sync scales\n- [ ] Sweep phase 1 \u003c300s\n- [ ] Sweep phase 2 \u003c600s\n\n### Failure Mode Tests\n- [ ] Repo unavailable: marked error\n- [ ] Sync conflict: flagged for resolution\n- [ ] Sweep timeout: phase retried\n- [ ] Invalid plan: rejected with reason","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:49:44.197985905-05:00","created_by":"ubuntu","updated_at":"2026-01-08T17:50:02.483736575-05:00","dependencies":[{"issue_id":"flywheel_gateway-zno","depends_on_id":"flywheel_gateway-toe","type":"blocks","created_at":"2026-01-08T14:02:01.619146218-05:00","created_by":"ubuntu"},{"issue_id":"flywheel_gateway-zno","depends_on_id":"flywheel_gateway-p0l","type":"blocks","created_at":"2026-01-08T14:02:02.236461184-05:00","created_by":"ubuntu"}]}
